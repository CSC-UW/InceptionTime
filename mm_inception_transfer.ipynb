{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/apps/software/TensorFlow/2.2.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "#sys.path = [p for p in sys.path if p.find('/opt/apps/software/') == -1]\n",
    "from glob import glob\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
    "from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
    "from utils.utils import read_all_datasets, transform_labels, create_directory, run_length_xps, generate_results_csv, plot_epochs_metric\n",
    "from utils.data_loading import get_multiple_data, predict, shifted_zscore, zscore, print_metric, tf_rmse, tf_pmse, rmse\n",
    "import utils\n",
    "from classifiers import inception\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "def tf_pmse_DA(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=0)\n",
    "\n",
    "def tf_pmse_5HT(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=1)\n",
    "\n",
    "def tf_pmse_pH(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=2)\n",
    "\n",
    "def tf_pmse_NE(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=3)\n",
    "\n",
    "# import keras\n",
    "# keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hold probe : MMA024W01R04\n",
      "validation probe : MMA003W01R04\n",
      "Leaving out probe MMA024W01R04\n",
      "Validation probe MMA003W01R04\n",
      "Loading data\n",
      "No 500ohms\n",
      "number of voltammograms files 36\n",
      "after filter 36\n",
      "after removing bad probes 36\n",
      "number of holdout files 4\n",
      "(52800, 999)\n",
      "(52800, 4)\n",
      "validation probe: MMA003W01R04\n",
      "number of validation files 4\n",
      "(52800, 999)\n",
      "(52800, 4)\n",
      "number of train files 28\n",
      "(369600, 999)\n",
      "(369600, 4)\n",
      "adding singleton\n"
     ]
    }
   ],
   "source": [
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "# data_prefix = '/mnt/nfs/proj/in-vitro/iterate/results_014/model_style_008/training-A-RBE-97Hz/'\n",
    "data_prefix = '/mnt/nfs/proj/in-vitro/iterate/results_014/model_style_008/training-B-RBE025-97Hz/'\n",
    "voltammograms = glob(data_prefix + '/*MMA*/voltammograms.mat')\n",
    "probes = ['MMA003W01R04', 'MMA004W01R04', 'MMA013W01R04', 'MMA018W01R04', 'MMA019W01R04', 'MMA022W01R04', 'MMA023W01R04', 'MMA024W01R04', 'MMA025W01R04']\n",
    "# probes = ['MMA003W01R04', 'MMA004W01R04', 'MMA013W01R04', 'MMA019W01R04', 'MMA022W01R04', 'MMA024W01R04', 'MMA025W01R04']\n",
    "good_probes = probes\n",
    "\n",
    "hold_probe = probes[7]\n",
    "# hold_probe=None\n",
    "print('hold probe :', hold_probe)\n",
    "\n",
    "# jitter = None\n",
    "jitter = 500\n",
    "\n",
    "output_directory = f'/mnt/nfs/proj/in-vitro/Leonardo/inception/results/mm/jitter/{hold_probe}/'\n",
    "\n",
    "if not (os.path.exists(output_directory)):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# val_probe=None\n",
    "val_probe=probes[0]\n",
    "print('validation probe :', val_probe)\n",
    "\n",
    "print(f'Leaving out probe {hold_probe}', flush=True)\n",
    "print(f'Validation probe {val_probe}', flush=True)\n",
    "print(f'Loading data', flush=True)\n",
    "\n",
    "filter_files = lambda x : x.find('500kohm') == -1\n",
    "print('No 500ohms')\n",
    "\n",
    "# filter_files = lambda x : x.find('500kohm') > -1\n",
    "# print('ONLY 500ohms')\n",
    "\n",
    "# normalize_data = minmax\n",
    "# revert_data = lambda x: minmax(x, inverse=True)\n",
    "\n",
    "normalize_data = shifted_zscore\n",
    "revert_data = lambda x: shifted_zscore(x, inverse=True)\n",
    "\n",
    "# normalize_data = zscore\n",
    "# revert_data = lambda x: zscore(x, inverse=True)\n",
    "\n",
    "# normalize_data = lambda x: x\n",
    "# revert_data = lambda x: x\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_multiple_data(data_prefix,\n",
    "                                                                    probes=good_probes,\n",
    "                                                                    holdout=hold_probe,\n",
    "                                                                    val_probe=val_probe,\n",
    "                                                                    number_of_minibatches=20,\n",
    "                                                                    normalize_data=normalize_data,\n",
    "                                                                    filter_files=filter_files,\n",
    "#                                                                     nrecords_per_session=1,\n",
    "                                                                    nrecords_per_session=400,\n",
    "                                                                    jitter=jitter)\n",
    "# print('Data loaded')\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    print('adding singleton')\n",
    "    # add a dimension to make it multivariate with one dimension\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "output_shape = y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/proj/in-vitro/Leonardo/inception/results/mm/jitter/MMA024W01R04/\n"
     ]
    }
   ],
   "source": [
    "print(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a658cf5599fe4f10bba2e6f006ca3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probe_x, probe_y = x_train, y_train\n",
    "# probe_x, probe_y = x_val, y_val\n",
    "# probe_x, probe_y = x_test, y_test\n",
    "\n",
    "ul, ulidx = np.unique(probe_y, return_index=True, axis=0)\n",
    "\n",
    "fig, axs = plt.subplots(tight_layout=True, figsize=(12, 5))\n",
    "\n",
    "for idx in ulidx:\n",
    "    axs.plot(probe_x[idx,:])\n",
    "#     axs[iprobe].set_ylim(-50, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre model\n",
    "\n",
    "import keras \n",
    "\n",
    "# cf_model_path = '/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/CF082/best_model.hdf5'\n",
    "\n",
    "# # NOTE: tf_pmse* is different for CF (different mean/std). In theory it doesn't matter since we are just loading the model to get the weights, so running this model with \n",
    "# # MM data will produce wrong metrics\n",
    "# cf_model = keras.models.load_model(cf_model_path, \n",
    "#                                    custom_objects={\"tf_pmse_DA\": tf_pmse_DA, \"tf_pmse_5HT\": tf_pmse_5HT, \"tf_pmse_pH\": tf_pmse_pH, \"tf_pmse_NE\": tf_pmse_NE})\n",
    "\n",
    "cf_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0',)\n",
      "starting model from scratch...\n",
      "Compiling with Adam and metrics:  ['tf_pmse_DA', 'tf_pmse_5HT', 'tf_pmse_pH', 'tf_pmse_NE']\n",
      "Model not fit yet\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "classifier = inception.Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=100,\n",
    "                                            metrics=[tf_pmse_DA, tf_pmse_5HT, tf_pmse_pH, tf_pmse_NE], pre_model=cf_model,\n",
    "                                            revert_data=revert_data)\n",
    "\n",
    "model_path = classifier.output_directory + 'best_model.hdf5'\n",
    "if os.path.isfile(model_path):\n",
    "    print('Best model already fit: %s'%model_path)\n",
    "    best_model = classifier.get_best_model()\n",
    "else:\n",
    "    print('Model not fit yet')\n",
    "    best_model = None\n",
    "\n",
    "# Epoch 1/1\n",
    "# 369600/369600 [==============================] - 330s 894us/step - \n",
    "# loss: 1.4710 - tf_pmse_DA: 995.1803 - tf_pmse_5HT: 1049.4110 - tf_pmse_pH: 0.3064 - tf_pmse_NE: 973.5949 - \n",
    "# val_loss: 1.1462 - val_tf_pmse_DA: 680.6979 - val_tf_pmse_5HT: 671.7536 - val_tf_pmse_pH: 0.3898 - val_tf_pmse_NE: 678.4900\n",
    "                                        \n",
    "# 369600/369600 [==============================] - 338s 913us/step - \n",
    "# loss: 1.3524 - tf_pmse_DA: 963.2611 - tf_pmse_5HT: 989.8214 - tf_pmse_pH: 0.2679 - tf_pmse_NE: 911.7079 - \n",
    "# val_loss: 1.8146 - val_tf_pmse_DA: 973.9214 - val_tf_pmse_5HT: 1004.9336 - val_tf_pmse_pH: 0.5226 - val_tf_pmse_NE: 884.2783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting new model...\n",
      "mini batch size: 64\n",
      "Train on 369600 samples, validate on 52800 samples\n",
      "Epoch 1/100\n",
      "369600/369600 [==============================] - 329s 891us/step - loss: 1.1876 - tf_pmse_DA: 979.0491 - tf_pmse_5HT: 972.5685 - tf_pmse_pH: 0.2991 - tf_pmse_NE: 920.1286 - val_loss: 3.0808 - val_tf_pmse_DA: 1201.5206 - val_tf_pmse_5HT: 1221.2851 - val_tf_pmse_pH: 0.6562 - val_tf_pmse_NE: 2403.6211\n",
      "Epoch 2/100\n",
      "369600/369600 [==============================] - 320s 867us/step - loss: 0.5302 - tf_pmse_DA: 768.2197 - tf_pmse_5HT: 800.7112 - tf_pmse_pH: 0.2160 - tf_pmse_NE: 729.5282 - val_loss: 2.7314 - val_tf_pmse_DA: 1193.7570 - val_tf_pmse_5HT: 2011.2347 - val_tf_pmse_pH: 0.4545 - val_tf_pmse_NE: 2023.8267\n",
      "Epoch 3/100\n",
      "369600/369600 [==============================] - 321s 868us/step - loss: 0.3591 - tf_pmse_DA: 637.8481 - tf_pmse_5HT: 661.3910 - tf_pmse_pH: 0.1707 - tf_pmse_NE: 612.0892 - val_loss: 1.9072 - val_tf_pmse_DA: 1325.7907 - val_tf_pmse_5HT: 1412.5620 - val_tf_pmse_pH: 0.3916 - val_tf_pmse_NE: 1676.3304\n",
      "Epoch 4/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.2689 - tf_pmse_DA: 550.7924 - tf_pmse_5HT: 569.8568 - tf_pmse_pH: 0.1452 - tf_pmse_NE: 538.4807 - val_loss: 1.7118 - val_tf_pmse_DA: 1292.4259 - val_tf_pmse_5HT: 1454.8968 - val_tf_pmse_pH: 0.4221 - val_tf_pmse_NE: 1292.1472\n",
      "Epoch 5/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.2188 - tf_pmse_DA: 494.7083 - tf_pmse_5HT: 512.8737 - tf_pmse_pH: 0.1299 - tf_pmse_NE: 489.8608 - val_loss: 1.7860 - val_tf_pmse_DA: 1507.8514 - val_tf_pmse_5HT: 1411.9960 - val_tf_pmse_pH: 0.3868 - val_tf_pmse_NE: 1341.5875\n",
      "Epoch 6/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.1861 - tf_pmse_DA: 455.7987 - tf_pmse_5HT: 472.4986 - tf_pmse_pH: 0.1189 - tf_pmse_NE: 453.7267 - val_loss: 2.2045 - val_tf_pmse_DA: 1272.6977 - val_tf_pmse_5HT: 1862.8015 - val_tf_pmse_pH: 0.3962 - val_tf_pmse_NE: 1649.2372\n",
      "Epoch 7/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.1648 - tf_pmse_DA: 429.2859 - tf_pmse_5HT: 444.1740 - tf_pmse_pH: 0.1115 - tf_pmse_NE: 426.8855 - val_loss: 1.7505 - val_tf_pmse_DA: 1454.9788 - val_tf_pmse_5HT: 1493.2661 - val_tf_pmse_pH: 0.3931 - val_tf_pmse_NE: 1241.3453\n",
      "Epoch 8/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.1487 - tf_pmse_DA: 406.0907 - tf_pmse_5HT: 423.7019 - tf_pmse_pH: 0.1057 - tf_pmse_NE: 404.9245 - val_loss: 1.3978 - val_tf_pmse_DA: 1229.5505 - val_tf_pmse_5HT: 1262.1805 - val_tf_pmse_pH: 0.3594 - val_tf_pmse_NE: 1232.9018\n",
      "Epoch 9/100\n",
      "369600/369600 [==============================] - 320s 865us/step - loss: 0.1363 - tf_pmse_DA: 389.2739 - tf_pmse_5HT: 405.9506 - tf_pmse_pH: 0.1006 - tf_pmse_NE: 387.4699 - val_loss: 1.6735 - val_tf_pmse_DA: 1280.1828 - val_tf_pmse_5HT: 1328.7582 - val_tf_pmse_pH: 0.3960 - val_tf_pmse_NE: 1456.6501\n",
      "Epoch 10/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.1267 - tf_pmse_DA: 375.2254 - tf_pmse_5HT: 391.8793 - tf_pmse_pH: 0.0966 - tf_pmse_NE: 373.2004 - val_loss: 1.5939 - val_tf_pmse_DA: 1386.0671 - val_tf_pmse_5HT: 1340.3004 - val_tf_pmse_pH: 0.3885 - val_tf_pmse_NE: 1233.8862\n",
      "Epoch 11/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.1177 - tf_pmse_DA: 360.7860 - tf_pmse_5HT: 377.9520 - tf_pmse_pH: 0.0933 - tf_pmse_NE: 359.2914 - val_loss: 1.6172 - val_tf_pmse_DA: 1264.7529 - val_tf_pmse_5HT: 1507.9161 - val_tf_pmse_pH: 0.3752 - val_tf_pmse_NE: 1254.3004\n",
      "Epoch 12/100\n",
      "369600/369600 [==============================] - 320s 866us/step - loss: 0.1111 - tf_pmse_DA: 351.3884 - tf_pmse_5HT: 366.6658 - tf_pmse_pH: 0.0902 - tf_pmse_NE: 348.8374 - val_loss: 1.4659 - val_tf_pmse_DA: 1194.0223 - val_tf_pmse_5HT: 1329.4290 - val_tf_pmse_pH: 0.3825 - val_tf_pmse_NE: 1243.8161\n",
      "Epoch 13/100\n",
      "369600/369600 [==============================] - 321s 870us/step - loss: 0.1049 - tf_pmse_DA: 340.3707 - tf_pmse_5HT: 357.4333 - tf_pmse_pH: 0.0872 - tf_pmse_NE: 339.5668 - val_loss: 1.6024 - val_tf_pmse_DA: 1233.1011 - val_tf_pmse_5HT: 1335.9963 - val_tf_pmse_pH: 0.4087 - val_tf_pmse_NE: 1342.6307\n",
      "Epoch 14/100\n",
      "369600/369600 [==============================] - 323s 873us/step - loss: 0.0994 - tf_pmse_DA: 331.4304 - tf_pmse_5HT: 346.6750 - tf_pmse_pH: 0.0851 - tf_pmse_NE: 330.5050 - val_loss: 1.5356 - val_tf_pmse_DA: 1318.9893 - val_tf_pmse_5HT: 1354.0315 - val_tf_pmse_pH: 0.3737 - val_tf_pmse_NE: 1239.3495\n",
      "Epoch 15/100\n",
      "369600/369600 [==============================] - 321s 869us/step - loss: 0.0958 - tf_pmse_DA: 325.0656 - tf_pmse_5HT: 342.0213 - tf_pmse_pH: 0.0832 - tf_pmse_NE: 322.6711 - val_loss: 1.5916 - val_tf_pmse_DA: 1244.7178 - val_tf_pmse_5HT: 1409.9235 - val_tf_pmse_pH: 0.4075 - val_tf_pmse_NE: 1237.6650\n",
      "Epoch 16/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0916 - tf_pmse_DA: 317.4927 - tf_pmse_5HT: 333.8250 - tf_pmse_pH: 0.0815 - tf_pmse_NE: 316.4900 - val_loss: 1.9413 - val_tf_pmse_DA: 1498.6721 - val_tf_pmse_5HT: 1540.3426 - val_tf_pmse_pH: 0.3970 - val_tf_pmse_NE: 1433.6615\n",
      "Epoch 17/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0874 - tf_pmse_DA: 310.1322 - tf_pmse_5HT: 326.9449 - tf_pmse_pH: 0.0793 - tf_pmse_NE: 308.8631 - val_loss: 1.5470 - val_tf_pmse_DA: 1187.4367 - val_tf_pmse_5HT: 1460.3656 - val_tf_pmse_pH: 0.3784 - val_tf_pmse_NE: 1254.7904\n",
      "Epoch 18/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0840 - tf_pmse_DA: 304.3076 - tf_pmse_5HT: 322.1446 - tf_pmse_pH: 0.0775 - tf_pmse_NE: 301.2824 - val_loss: 1.6006 - val_tf_pmse_DA: 1216.5757 - val_tf_pmse_5HT: 1387.7734 - val_tf_pmse_pH: 0.3894 - val_tf_pmse_NE: 1363.0291\n",
      "Epoch 19/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0806 - tf_pmse_DA: 297.2167 - tf_pmse_5HT: 314.2947 - tf_pmse_pH: 0.0759 - tf_pmse_NE: 296.8791 - val_loss: 1.3327 - val_tf_pmse_DA: 1162.0343 - val_tf_pmse_5HT: 1215.7532 - val_tf_pmse_pH: 0.3698 - val_tf_pmse_NE: 1194.8333\n",
      "Epoch 20/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0781 - tf_pmse_DA: 292.7010 - tf_pmse_5HT: 309.5632 - tf_pmse_pH: 0.0748 - tf_pmse_NE: 291.2525 - val_loss: 1.9590 - val_tf_pmse_DA: 1476.0386 - val_tf_pmse_5HT: 1538.7831 - val_tf_pmse_pH: 0.4121 - val_tf_pmse_NE: 1440.3562\n",
      "Epoch 21/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0755 - tf_pmse_DA: 287.1608 - tf_pmse_5HT: 304.6854 - tf_pmse_pH: 0.0736 - tf_pmse_NE: 285.9862 - val_loss: 1.5217 - val_tf_pmse_DA: 1243.9048 - val_tf_pmse_5HT: 1325.8929 - val_tf_pmse_pH: 0.3925 - val_tf_pmse_NE: 1263.3770\n",
      "Epoch 22/100\n",
      "369600/369600 [==============================] - 318s 862us/step - loss: 0.0734 - tf_pmse_DA: 283.4723 - tf_pmse_5HT: 300.3506 - tf_pmse_pH: 0.0724 - tf_pmse_NE: 281.8050 - val_loss: 1.5238 - val_tf_pmse_DA: 1213.5232 - val_tf_pmse_5HT: 1369.5853 - val_tf_pmse_pH: 0.3971 - val_tf_pmse_NE: 1233.0620\n",
      "Epoch 23/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0711 - tf_pmse_DA: 279.1153 - tf_pmse_5HT: 295.4523 - tf_pmse_pH: 0.0714 - tf_pmse_NE: 277.2333 - val_loss: 1.4159 - val_tf_pmse_DA: 1168.0285 - val_tf_pmse_5HT: 1301.1258 - val_tf_pmse_pH: 0.3697 - val_tf_pmse_NE: 1250.5533\n",
      "Epoch 24/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0687 - tf_pmse_DA: 273.8444 - tf_pmse_5HT: 290.3523 - tf_pmse_pH: 0.0700 - tf_pmse_NE: 273.2732 - val_loss: 1.4756 - val_tf_pmse_DA: 1290.2226 - val_tf_pmse_5HT: 1289.5107 - val_tf_pmse_pH: 0.3747 - val_tf_pmse_NE: 1232.4322\n",
      "Epoch 25/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0670 - tf_pmse_DA: 270.7968 - tf_pmse_5HT: 286.9041 - tf_pmse_pH: 0.0692 - tf_pmse_NE: 269.6167 - val_loss: 1.4498 - val_tf_pmse_DA: 1230.9070 - val_tf_pmse_5HT: 1303.6111 - val_tf_pmse_pH: 0.3722 - val_tf_pmse_NE: 1240.3029\n",
      "Epoch 26/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0653 - tf_pmse_DA: 267.5593 - tf_pmse_5HT: 282.8625 - tf_pmse_pH: 0.0682 - tf_pmse_NE: 265.5878 - val_loss: 1.3835 - val_tf_pmse_DA: 1195.3670 - val_tf_pmse_5HT: 1244.3675 - val_tf_pmse_pH: 0.3637 - val_tf_pmse_NE: 1243.8540\n",
      "Epoch 27/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0636 - tf_pmse_DA: 264.4549 - tf_pmse_5HT: 279.7307 - tf_pmse_pH: 0.0671 - tf_pmse_NE: 262.0377 - val_loss: 1.3821 - val_tf_pmse_DA: 1187.6017 - val_tf_pmse_5HT: 1266.0165 - val_tf_pmse_pH: 0.3667 - val_tf_pmse_NE: 1218.1379\n",
      "Epoch 28/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0621 - tf_pmse_DA: 260.7542 - tf_pmse_5HT: 276.7826 - tf_pmse_pH: 0.0665 - tf_pmse_NE: 258.1542 - val_loss: 1.4237 - val_tf_pmse_DA: 1185.0260 - val_tf_pmse_5HT: 1338.3432 - val_tf_pmse_pH: 0.3713 - val_tf_pmse_NE: 1204.9764\n",
      "Epoch 29/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0609 - tf_pmse_DA: 258.6115 - tf_pmse_5HT: 273.2716 - tf_pmse_pH: 0.0656 - tf_pmse_NE: 256.7097 - val_loss: 1.3902 - val_tf_pmse_DA: 1191.1438 - val_tf_pmse_5HT: 1282.9206 - val_tf_pmse_pH: 0.3682 - val_tf_pmse_NE: 1208.3268\n",
      "Epoch 30/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0598 - tf_pmse_DA: 256.0107 - tf_pmse_5HT: 271.8194 - tf_pmse_pH: 0.0648 - tf_pmse_NE: 253.7702 - val_loss: 1.4753 - val_tf_pmse_DA: 1307.7531 - val_tf_pmse_5HT: 1312.9666 - val_tf_pmse_pH: 0.3692 - val_tf_pmse_NE: 1206.8832\n",
      "Epoch 31/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0581 - tf_pmse_DA: 252.2775 - tf_pmse_5HT: 267.6869 - tf_pmse_pH: 0.0638 - tf_pmse_NE: 250.4019 - val_loss: 1.4969 - val_tf_pmse_DA: 1215.1757 - val_tf_pmse_5HT: 1238.0335 - val_tf_pmse_pH: 0.4189 - val_tf_pmse_NE: 1245.8973\n",
      "Epoch 32/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0569 - tf_pmse_DA: 249.8056 - tf_pmse_5HT: 265.2569 - tf_pmse_pH: 0.0632 - tf_pmse_NE: 247.1544 - val_loss: 1.3694 - val_tf_pmse_DA: 1193.1376 - val_tf_pmse_5HT: 1250.6721 - val_tf_pmse_pH: 0.3635 - val_tf_pmse_NE: 1216.3195\n",
      "Epoch 33/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0560 - tf_pmse_DA: 248.0792 - tf_pmse_5HT: 262.1159 - tf_pmse_pH: 0.0631 - tf_pmse_NE: 245.5291 - val_loss: 1.3346 - val_tf_pmse_DA: 1171.8679 - val_tf_pmse_5HT: 1201.2448 - val_tf_pmse_pH: 0.3700 - val_tf_pmse_NE: 1201.8773\n",
      "Epoch 34/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0549 - tf_pmse_DA: 245.2622 - tf_pmse_5HT: 259.9077 - tf_pmse_pH: 0.0622 - tf_pmse_NE: 242.6298 - val_loss: 1.3584 - val_tf_pmse_DA: 1194.5293 - val_tf_pmse_5HT: 1225.9674 - val_tf_pmse_pH: 0.3678 - val_tf_pmse_NE: 1204.6311\n",
      "Epoch 35/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0539 - tf_pmse_DA: 242.7027 - tf_pmse_5HT: 258.4236 - tf_pmse_pH: 0.0616 - tf_pmse_NE: 240.3699 - val_loss: 1.5402 - val_tf_pmse_DA: 1206.6745 - val_tf_pmse_5HT: 1402.0020 - val_tf_pmse_pH: 0.3798 - val_tf_pmse_NE: 1288.7827\n",
      "Epoch 36/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0529 - tf_pmse_DA: 241.1835 - tf_pmse_5HT: 255.5587 - tf_pmse_pH: 0.0609 - tf_pmse_NE: 237.6918 - val_loss: 1.3912 - val_tf_pmse_DA: 1199.2300 - val_tf_pmse_5HT: 1210.3250 - val_tf_pmse_pH: 0.3861 - val_tf_pmse_NE: 1214.7207\n",
      "Epoch 37/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0519 - tf_pmse_DA: 238.1822 - tf_pmse_5HT: 253.7953 - tf_pmse_pH: 0.0603 - tf_pmse_NE: 235.7637 - val_loss: 1.5231 - val_tf_pmse_DA: 1290.8956 - val_tf_pmse_5HT: 1248.4648 - val_tf_pmse_pH: 0.4142 - val_tf_pmse_NE: 1221.4611\n",
      "Epoch 38/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0510 - tf_pmse_DA: 236.3651 - tf_pmse_5HT: 250.9894 - tf_pmse_pH: 0.0598 - tf_pmse_NE: 234.1321 - val_loss: 1.4268 - val_tf_pmse_DA: 1227.2390 - val_tf_pmse_5HT: 1299.7440 - val_tf_pmse_pH: 0.3709 - val_tf_pmse_NE: 1213.3680\n",
      "Epoch 39/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.0501 - tf_pmse_DA: 233.8200 - tf_pmse_5HT: 248.8495 - tf_pmse_pH: 0.0593 - tf_pmse_NE: 231.7981 - val_loss: 1.3277 - val_tf_pmse_DA: 1170.3400 - val_tf_pmse_5HT: 1217.8568 - val_tf_pmse_pH: 0.3663 - val_tf_pmse_NE: 1189.8415\n",
      "Epoch 40/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0495 - tf_pmse_DA: 232.2704 - tf_pmse_5HT: 247.6506 - tf_pmse_pH: 0.0589 - tf_pmse_NE: 230.1953 - val_loss: 1.4560 - val_tf_pmse_DA: 1196.2902 - val_tf_pmse_5HT: 1268.0145 - val_tf_pmse_pH: 0.4003 - val_tf_pmse_NE: 1226.0135\n",
      "Epoch 41/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0485 - tf_pmse_DA: 230.2433 - tf_pmse_5HT: 245.3746 - tf_pmse_pH: 0.0583 - tf_pmse_NE: 227.0313 - val_loss: 1.5058 - val_tf_pmse_DA: 1229.0869 - val_tf_pmse_5HT: 1376.5461 - val_tf_pmse_pH: 0.3811 - val_tf_pmse_NE: 1231.8125\n",
      "Epoch 42/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0478 - tf_pmse_DA: 228.3721 - tf_pmse_5HT: 243.4495 - tf_pmse_pH: 0.0579 - tf_pmse_NE: 226.3231 - val_loss: 1.4489 - val_tf_pmse_DA: 1207.3306 - val_tf_pmse_5HT: 1258.4886 - val_tf_pmse_pH: 0.3965 - val_tf_pmse_NE: 1229.0629\n",
      "Epoch 43/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0469 - tf_pmse_DA: 226.7796 - tf_pmse_5HT: 241.1823 - tf_pmse_pH: 0.0575 - tf_pmse_NE: 223.0551 - val_loss: 1.3602 - val_tf_pmse_DA: 1197.1887 - val_tf_pmse_5HT: 1204.7345 - val_tf_pmse_pH: 0.3804 - val_tf_pmse_NE: 1189.1680\n",
      "Epoch 44/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0463 - tf_pmse_DA: 225.0136 - tf_pmse_5HT: 239.8312 - tf_pmse_pH: 0.0570 - tf_pmse_NE: 221.6605 - val_loss: 1.4118 - val_tf_pmse_DA: 1213.6710 - val_tf_pmse_5HT: 1234.2803 - val_tf_pmse_pH: 0.3784 - val_tf_pmse_NE: 1239.1544\n",
      "Epoch 45/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0458 - tf_pmse_DA: 224.1705 - tf_pmse_5HT: 238.6900 - tf_pmse_pH: 0.0564 - tf_pmse_NE: 220.9025 - val_loss: 1.3579 - val_tf_pmse_DA: 1171.4565 - val_tf_pmse_5HT: 1221.0675 - val_tf_pmse_pH: 0.3796 - val_tf_pmse_NE: 1195.7742\n",
      "Epoch 46/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0451 - tf_pmse_DA: 222.7524 - tf_pmse_5HT: 236.0718 - tf_pmse_pH: 0.0561 - tf_pmse_NE: 219.3709 - val_loss: 1.3905 - val_tf_pmse_DA: 1225.3951 - val_tf_pmse_5HT: 1260.4636 - val_tf_pmse_pH: 0.3643 - val_tf_pmse_NE: 1211.2330\n",
      "Epoch 47/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.0446 - tf_pmse_DA: 220.5977 - tf_pmse_5HT: 234.9613 - tf_pmse_pH: 0.0558 - tf_pmse_NE: 218.0187 - val_loss: 1.3905 - val_tf_pmse_DA: 1234.3351 - val_tf_pmse_5HT: 1222.8967 - val_tf_pmse_pH: 0.3707 - val_tf_pmse_NE: 1219.0204\n",
      "Epoch 48/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0441 - tf_pmse_DA: 219.2757 - tf_pmse_5HT: 234.3811 - tf_pmse_pH: 0.0554 - tf_pmse_NE: 217.0468 - val_loss: 1.3219 - val_tf_pmse_DA: 1172.7951 - val_tf_pmse_5HT: 1206.0625 - val_tf_pmse_pH: 0.3638 - val_tf_pmse_NE: 1196.2374\n",
      "Epoch 49/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0437 - tf_pmse_DA: 217.7886 - tf_pmse_5HT: 232.6067 - tf_pmse_pH: 0.0554 - tf_pmse_NE: 215.4398 - val_loss: 1.3482 - val_tf_pmse_DA: 1172.8131 - val_tf_pmse_5HT: 1202.6504 - val_tf_pmse_pH: 0.3791 - val_tf_pmse_NE: 1197.1060\n",
      "Epoch 50/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0428 - tf_pmse_DA: 216.0993 - tf_pmse_5HT: 230.5580 - tf_pmse_pH: 0.0546 - tf_pmse_NE: 213.4475 - val_loss: 1.3872 - val_tf_pmse_DA: 1174.4319 - val_tf_pmse_5HT: 1241.7165 - val_tf_pmse_pH: 0.3683 - val_tf_pmse_NE: 1261.5192\n",
      "Epoch 51/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0424 - tf_pmse_DA: 215.1241 - tf_pmse_5HT: 229.7329 - tf_pmse_pH: 0.0542 - tf_pmse_NE: 212.2041 - val_loss: 1.3723 - val_tf_pmse_DA: 1212.7669 - val_tf_pmse_5HT: 1200.1997 - val_tf_pmse_pH: 0.3734 - val_tf_pmse_NE: 1221.2681\n",
      "Epoch 52/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0418 - tf_pmse_DA: 213.6903 - tf_pmse_5HT: 227.8986 - tf_pmse_pH: 0.0539 - tf_pmse_NE: 210.3638 - val_loss: 1.3734 - val_tf_pmse_DA: 1204.1424 - val_tf_pmse_5HT: 1230.6889 - val_tf_pmse_pH: 0.3733 - val_tf_pmse_NE: 1203.2519\n",
      "Epoch 53/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0412 - tf_pmse_DA: 211.9628 - tf_pmse_5HT: 226.5137 - tf_pmse_pH: 0.0534 - tf_pmse_NE: 209.5639 - val_loss: 1.4391 - val_tf_pmse_DA: 1219.2796 - val_tf_pmse_5HT: 1282.1024 - val_tf_pmse_pH: 0.3736 - val_tf_pmse_NE: 1252.4310\n",
      "Epoch 54/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0406 - tf_pmse_DA: 210.8932 - tf_pmse_5HT: 224.4971 - tf_pmse_pH: 0.0531 - tf_pmse_NE: 207.6269 - val_loss: 1.3672 - val_tf_pmse_DA: 1174.4166 - val_tf_pmse_5HT: 1206.8975 - val_tf_pmse_pH: 0.3792 - val_tf_pmse_NE: 1224.7349\n",
      "Epoch 55/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0402 - tf_pmse_DA: 209.6041 - tf_pmse_5HT: 223.6745 - tf_pmse_pH: 0.0528 - tf_pmse_NE: 206.2359 - val_loss: 1.3794 - val_tf_pmse_DA: 1207.7256 - val_tf_pmse_5HT: 1216.0342 - val_tf_pmse_pH: 0.3677 - val_tf_pmse_NE: 1240.9743\n",
      "Epoch 56/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0400 - tf_pmse_DA: 209.4701 - tf_pmse_5HT: 222.4050 - tf_pmse_pH: 0.0526 - tf_pmse_NE: 206.6006 - val_loss: 1.4320 - val_tf_pmse_DA: 1239.9345 - val_tf_pmse_5HT: 1273.3603 - val_tf_pmse_pH: 0.3723 - val_tf_pmse_NE: 1231.9430\n",
      "Epoch 57/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0391 - tf_pmse_DA: 206.9813 - tf_pmse_5HT: 220.0178 - tf_pmse_pH: 0.0521 - tf_pmse_NE: 203.7363 - val_loss: 1.3579 - val_tf_pmse_DA: 1218.4930 - val_tf_pmse_5HT: 1185.4194 - val_tf_pmse_pH: 0.3689 - val_tf_pmse_NE: 1220.2141\n",
      "Epoch 58/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0391 - tf_pmse_DA: 206.8747 - tf_pmse_5HT: 220.0148 - tf_pmse_pH: 0.0522 - tf_pmse_NE: 203.8288 - val_loss: 1.3754 - val_tf_pmse_DA: 1208.4966 - val_tf_pmse_5HT: 1247.5800 - val_tf_pmse_pH: 0.3663 - val_tf_pmse_NE: 1210.8718\n",
      "Epoch 59/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.0388 - tf_pmse_DA: 205.2284 - tf_pmse_5HT: 220.2255 - tf_pmse_pH: 0.0517 - tf_pmse_NE: 202.8988 - val_loss: 1.3382 - val_tf_pmse_DA: 1196.9624 - val_tf_pmse_5HT: 1209.9644 - val_tf_pmse_pH: 0.3689 - val_tf_pmse_NE: 1180.9484\n",
      "Epoch 60/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0381 - tf_pmse_DA: 204.1706 - tf_pmse_5HT: 217.5471 - tf_pmse_pH: 0.0515 - tf_pmse_NE: 200.8810 - val_loss: 1.3723 - val_tf_pmse_DA: 1197.7408 - val_tf_pmse_5HT: 1234.6720 - val_tf_pmse_pH: 0.3698 - val_tf_pmse_NE: 1215.2815\n",
      "Epoch 61/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0379 - tf_pmse_DA: 203.6572 - tf_pmse_5HT: 216.8212 - tf_pmse_pH: 0.0513 - tf_pmse_NE: 200.5883 - val_loss: 1.3982 - val_tf_pmse_DA: 1208.8719 - val_tf_pmse_5HT: 1238.0192 - val_tf_pmse_pH: 0.3716 - val_tf_pmse_NE: 1241.9353\n",
      "Epoch 62/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0374 - tf_pmse_DA: 201.6703 - tf_pmse_5HT: 215.2570 - tf_pmse_pH: 0.0511 - tf_pmse_NE: 199.5982 - val_loss: 1.3532 - val_tf_pmse_DA: 1195.4431 - val_tf_pmse_5HT: 1189.5640 - val_tf_pmse_pH: 0.3737 - val_tf_pmse_NE: 1213.1017\n",
      "Epoch 63/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0371 - tf_pmse_DA: 200.8358 - tf_pmse_5HT: 214.3762 - tf_pmse_pH: 0.0505 - tf_pmse_NE: 198.6556 - val_loss: 1.3536 - val_tf_pmse_DA: 1179.7584 - val_tf_pmse_5HT: 1216.3152 - val_tf_pmse_pH: 0.3742 - val_tf_pmse_NE: 1205.5018\n",
      "Epoch 64/100\n",
      "369600/369600 [==============================] - 318s 862us/step - loss: 0.0366 - tf_pmse_DA: 199.0970 - tf_pmse_5HT: 213.4758 - tf_pmse_pH: 0.0504 - tf_pmse_NE: 197.2275 - val_loss: 1.3846 - val_tf_pmse_DA: 1183.5289 - val_tf_pmse_5HT: 1263.4823 - val_tf_pmse_pH: 0.3661 - val_tf_pmse_NE: 1235.3384\n",
      "Epoch 65/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0363 - tf_pmse_DA: 198.8474 - tf_pmse_5HT: 212.6108 - tf_pmse_pH: 0.0500 - tf_pmse_NE: 196.4496 - val_loss: 1.3776 - val_tf_pmse_DA: 1217.9427 - val_tf_pmse_5HT: 1225.6490 - val_tf_pmse_pH: 0.3624 - val_tf_pmse_NE: 1239.1805\n",
      "Epoch 66/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0359 - tf_pmse_DA: 197.8371 - tf_pmse_5HT: 210.7682 - tf_pmse_pH: 0.0497 - tf_pmse_NE: 195.4235 - val_loss: 1.4127 - val_tf_pmse_DA: 1233.8693 - val_tf_pmse_5HT: 1279.7470 - val_tf_pmse_pH: 0.3690 - val_tf_pmse_NE: 1207.5300\n",
      "Epoch 67/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0358 - tf_pmse_DA: 197.1707 - tf_pmse_5HT: 211.3668 - tf_pmse_pH: 0.0495 - tf_pmse_NE: 194.8228 - val_loss: 1.3929 - val_tf_pmse_DA: 1217.7182 - val_tf_pmse_5HT: 1204.2032 - val_tf_pmse_pH: 0.3787 - val_tf_pmse_NE: 1230.0257\n",
      "Epoch 68/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0352 - tf_pmse_DA: 195.3564 - tf_pmse_5HT: 209.2908 - tf_pmse_pH: 0.0492 - tf_pmse_NE: 193.3642 - val_loss: 1.2923 - val_tf_pmse_DA: 1173.3524 - val_tf_pmse_5HT: 1173.0170 - val_tf_pmse_pH: 0.3594 - val_tf_pmse_NE: 1190.3995\n",
      "Epoch 69/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0350 - tf_pmse_DA: 195.2859 - tf_pmse_5HT: 208.3283 - tf_pmse_pH: 0.0491 - tf_pmse_NE: 192.8086 - val_loss: 1.3864 - val_tf_pmse_DA: 1211.4945 - val_tf_pmse_5HT: 1206.0785 - val_tf_pmse_pH: 0.3718 - val_tf_pmse_NE: 1250.1108\n",
      "Epoch 70/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0348 - tf_pmse_DA: 194.2412 - tf_pmse_5HT: 208.1191 - tf_pmse_pH: 0.0489 - tf_pmse_NE: 192.2921 - val_loss: 1.3208 - val_tf_pmse_DA: 1161.7708 - val_tf_pmse_5HT: 1216.2871 - val_tf_pmse_pH: 0.3614 - val_tf_pmse_NE: 1205.2762\n",
      "Epoch 71/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0342 - tf_pmse_DA: 193.7143 - tf_pmse_5HT: 206.3544 - tf_pmse_pH: 0.0484 - tf_pmse_NE: 190.3246 - val_loss: 1.4350 - val_tf_pmse_DA: 1207.9066 - val_tf_pmse_5HT: 1303.2979 - val_tf_pmse_pH: 0.3713 - val_tf_pmse_NE: 1242.3378\n",
      "Epoch 72/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0339 - tf_pmse_DA: 191.5993 - tf_pmse_5HT: 205.4805 - tf_pmse_pH: 0.0483 - tf_pmse_NE: 189.7541 - val_loss: 1.3560 - val_tf_pmse_DA: 1181.3317 - val_tf_pmse_5HT: 1226.2448 - val_tf_pmse_pH: 0.3662 - val_tf_pmse_NE: 1223.4596\n",
      "Epoch 73/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0338 - tf_pmse_DA: 191.1231 - tf_pmse_5HT: 204.5506 - tf_pmse_pH: 0.0483 - tf_pmse_NE: 190.2085 - val_loss: 1.3350 - val_tf_pmse_DA: 1189.7020 - val_tf_pmse_5HT: 1180.7715 - val_tf_pmse_pH: 0.3695 - val_tf_pmse_NE: 1209.6540\n",
      "Epoch 74/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0335 - tf_pmse_DA: 190.6491 - tf_pmse_5HT: 204.7478 - tf_pmse_pH: 0.0480 - tf_pmse_NE: 187.9996 - val_loss: 1.3166 - val_tf_pmse_DA: 1180.6766 - val_tf_pmse_5HT: 1197.1239 - val_tf_pmse_pH: 0.3652 - val_tf_pmse_NE: 1184.0589\n",
      "Epoch 75/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0331 - tf_pmse_DA: 190.2358 - tf_pmse_5HT: 202.8004 - tf_pmse_pH: 0.0478 - tf_pmse_NE: 187.4977 - val_loss: 1.3086 - val_tf_pmse_DA: 1157.3979 - val_tf_pmse_5HT: 1182.6577 - val_tf_pmse_pH: 0.3636 - val_tf_pmse_NE: 1211.6810\n",
      "Epoch 76/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0329 - tf_pmse_DA: 188.8490 - tf_pmse_5HT: 202.3110 - tf_pmse_pH: 0.0476 - tf_pmse_NE: 186.8026 - val_loss: 1.3777 - val_tf_pmse_DA: 1210.3901 - val_tf_pmse_5HT: 1218.5664 - val_tf_pmse_pH: 0.3726 - val_tf_pmse_NE: 1219.8583\n",
      "Epoch 77/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0328 - tf_pmse_DA: 187.9171 - tf_pmse_5HT: 201.7228 - tf_pmse_pH: 0.0476 - tf_pmse_NE: 186.8853 - val_loss: 1.4125 - val_tf_pmse_DA: 1222.7252 - val_tf_pmse_5HT: 1278.8513 - val_tf_pmse_pH: 0.3748 - val_tf_pmse_NE: 1201.7672\n",
      "Epoch 78/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.0326 - tf_pmse_DA: 187.8222 - tf_pmse_5HT: 201.8773 - tf_pmse_pH: 0.0473 - tf_pmse_NE: 186.1124 - val_loss: 1.4343 - val_tf_pmse_DA: 1229.3586 - val_tf_pmse_5HT: 1242.9938 - val_tf_pmse_pH: 0.3824 - val_tf_pmse_NE: 1244.0262\n",
      "Epoch 79/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0320 - tf_pmse_DA: 185.8951 - tf_pmse_5HT: 199.6592 - tf_pmse_pH: 0.0471 - tf_pmse_NE: 184.7366 - val_loss: 1.3307 - val_tf_pmse_DA: 1166.0056 - val_tf_pmse_5HT: 1196.3319 - val_tf_pmse_pH: 0.3692 - val_tf_pmse_NE: 1213.9096\n",
      "Epoch 80/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0319 - tf_pmse_DA: 185.5346 - tf_pmse_5HT: 199.4346 - tf_pmse_pH: 0.0470 - tf_pmse_NE: 184.0863 - val_loss: 1.3629 - val_tf_pmse_DA: 1184.0930 - val_tf_pmse_5HT: 1192.0179 - val_tf_pmse_pH: 0.3852 - val_tf_pmse_NE: 1202.9486\n",
      "Epoch 81/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0316 - tf_pmse_DA: 184.8372 - tf_pmse_5HT: 198.1571 - tf_pmse_pH: 0.0466 - tf_pmse_NE: 183.4049 - val_loss: 1.3913 - val_tf_pmse_DA: 1203.7791 - val_tf_pmse_5HT: 1187.7319 - val_tf_pmse_pH: 0.3900 - val_tf_pmse_NE: 1220.9443\n",
      "Epoch 82/100\n",
      "369600/369600 [==============================] - 317s 859us/step - loss: 0.0315 - tf_pmse_DA: 184.6716 - tf_pmse_5HT: 197.4397 - tf_pmse_pH: 0.0465 - tf_pmse_NE: 183.1459 - val_loss: 1.3877 - val_tf_pmse_DA: 1193.9864 - val_tf_pmse_5HT: 1247.7197 - val_tf_pmse_pH: 0.3665 - val_tf_pmse_NE: 1244.5755\n",
      "Epoch 83/100\n",
      "369600/369600 [==============================] - 320s 865us/step - loss: 0.0311 - tf_pmse_DA: 182.9832 - tf_pmse_5HT: 197.0967 - tf_pmse_pH: 0.0461 - tf_pmse_NE: 182.1294 - val_loss: 1.3712 - val_tf_pmse_DA: 1190.3052 - val_tf_pmse_5HT: 1224.6697 - val_tf_pmse_pH: 0.3746 - val_tf_pmse_NE: 1214.4269\n",
      "Epoch 84/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0309 - tf_pmse_DA: 182.5731 - tf_pmse_5HT: 196.4719 - tf_pmse_pH: 0.0459 - tf_pmse_NE: 181.2693 - val_loss: 1.3557 - val_tf_pmse_DA: 1171.0219 - val_tf_pmse_5HT: 1250.1342 - val_tf_pmse_pH: 0.3691 - val_tf_pmse_NE: 1197.6786\n",
      "Epoch 85/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0307 - tf_pmse_DA: 181.6485 - tf_pmse_5HT: 195.4829 - tf_pmse_pH: 0.0459 - tf_pmse_NE: 180.8124 - val_loss: 1.3376 - val_tf_pmse_DA: 1180.3447 - val_tf_pmse_5HT: 1211.3170 - val_tf_pmse_pH: 0.3671 - val_tf_pmse_NE: 1201.6764\n",
      "Epoch 86/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0304 - tf_pmse_DA: 181.6281 - tf_pmse_5HT: 194.7366 - tf_pmse_pH: 0.0458 - tf_pmse_NE: 179.2538 - val_loss: 1.3374 - val_tf_pmse_DA: 1173.8643 - val_tf_pmse_5HT: 1210.1933 - val_tf_pmse_pH: 0.3696 - val_tf_pmse_NE: 1201.6439\n",
      "Epoch 87/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0303 - tf_pmse_DA: 181.0716 - tf_pmse_5HT: 194.4418 - tf_pmse_pH: 0.0456 - tf_pmse_NE: 178.5419 - val_loss: 1.3541 - val_tf_pmse_DA: 1194.6956 - val_tf_pmse_5HT: 1226.3995 - val_tf_pmse_pH: 0.3709 - val_tf_pmse_NE: 1188.9233\n",
      "Epoch 88/100\n",
      "369600/369600 [==============================] - 318s 862us/step - loss: 0.0300 - tf_pmse_DA: 180.2087 - tf_pmse_5HT: 192.8607 - tf_pmse_pH: 0.0455 - tf_pmse_NE: 178.2004 - val_loss: 1.4009 - val_tf_pmse_DA: 1213.5452 - val_tf_pmse_5HT: 1239.6855 - val_tf_pmse_pH: 0.3701 - val_tf_pmse_NE: 1244.4674\n",
      "Epoch 89/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0297 - tf_pmse_DA: 178.6274 - tf_pmse_5HT: 192.6044 - tf_pmse_pH: 0.0453 - tf_pmse_NE: 177.5459 - val_loss: 1.4219 - val_tf_pmse_DA: 1201.7533 - val_tf_pmse_5HT: 1293.3083 - val_tf_pmse_pH: 0.3784 - val_tf_pmse_NE: 1210.1047\n",
      "Epoch 90/100\n",
      "369600/369600 [==============================] - 318s 859us/step - loss: 0.0296 - tf_pmse_DA: 178.3235 - tf_pmse_5HT: 192.4118 - tf_pmse_pH: 0.0451 - tf_pmse_NE: 177.4658 - val_loss: 1.3983 - val_tf_pmse_DA: 1181.1695 - val_tf_pmse_5HT: 1278.4879 - val_tf_pmse_pH: 0.3723 - val_tf_pmse_NE: 1224.7831\n",
      "Epoch 91/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0296 - tf_pmse_DA: 178.4252 - tf_pmse_5HT: 192.1955 - tf_pmse_pH: 0.0452 - tf_pmse_NE: 176.8342 - val_loss: 1.3754 - val_tf_pmse_DA: 1194.1399 - val_tf_pmse_5HT: 1251.1010 - val_tf_pmse_pH: 0.3681 - val_tf_pmse_NE: 1215.5630\n",
      "Epoch 92/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0292 - tf_pmse_DA: 177.5119 - tf_pmse_5HT: 190.6869 - tf_pmse_pH: 0.0448 - tf_pmse_NE: 176.1023 - val_loss: 1.3554 - val_tf_pmse_DA: 1186.6720 - val_tf_pmse_5HT: 1213.1110 - val_tf_pmse_pH: 0.3802 - val_tf_pmse_NE: 1183.6655\n",
      "Epoch 93/100\n",
      "369600/369600 [==============================] - 317s 858us/step - loss: 0.0291 - tf_pmse_DA: 176.5722 - tf_pmse_5HT: 190.2547 - tf_pmse_pH: 0.0446 - tf_pmse_NE: 176.1774 - val_loss: 1.3896 - val_tf_pmse_DA: 1232.4473 - val_tf_pmse_5HT: 1232.7583 - val_tf_pmse_pH: 0.3756 - val_tf_pmse_NE: 1195.6548\n",
      "Epoch 94/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0288 - tf_pmse_DA: 175.6280 - tf_pmse_5HT: 189.5925 - tf_pmse_pH: 0.0444 - tf_pmse_NE: 175.3271 - val_loss: 1.3306 - val_tf_pmse_DA: 1175.9733 - val_tf_pmse_5HT: 1181.3456 - val_tf_pmse_pH: 0.3695 - val_tf_pmse_NE: 1215.3656\n",
      "Epoch 95/100\n",
      "369600/369600 [==============================] - 320s 865us/step - loss: 0.0287 - tf_pmse_DA: 174.7093 - tf_pmse_5HT: 189.1948 - tf_pmse_pH: 0.0443 - tf_pmse_NE: 174.6857 - val_loss: 1.3276 - val_tf_pmse_DA: 1163.0129 - val_tf_pmse_5HT: 1201.3006 - val_tf_pmse_pH: 0.3715 - val_tf_pmse_NE: 1197.3943\n",
      "Epoch 96/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.0284 - tf_pmse_DA: 174.9403 - tf_pmse_5HT: 187.3616 - tf_pmse_pH: 0.0443 - tf_pmse_NE: 173.7081 - val_loss: 1.3503 - val_tf_pmse_DA: 1164.0044 - val_tf_pmse_5HT: 1226.2689 - val_tf_pmse_pH: 0.3696 - val_tf_pmse_NE: 1215.9840\n",
      "Epoch 97/100\n",
      "369600/369600 [==============================] - 318s 861us/step - loss: 0.0283 - tf_pmse_DA: 174.4065 - tf_pmse_5HT: 188.0361 - tf_pmse_pH: 0.0441 - tf_pmse_NE: 173.9369 - val_loss: 1.3421 - val_tf_pmse_DA: 1180.0415 - val_tf_pmse_5HT: 1198.6896 - val_tf_pmse_pH: 0.3727 - val_tf_pmse_NE: 1205.1635\n",
      "Epoch 98/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0283 - tf_pmse_DA: 174.1192 - tf_pmse_5HT: 188.3857 - tf_pmse_pH: 0.0440 - tf_pmse_NE: 172.6838 - val_loss: 1.4287 - val_tf_pmse_DA: 1205.4690 - val_tf_pmse_5HT: 1270.0565 - val_tf_pmse_pH: 0.3741 - val_tf_pmse_NE: 1258.9162\n",
      "Epoch 99/100\n",
      "369600/369600 [==============================] - 318s 860us/step - loss: 0.0280 - tf_pmse_DA: 173.7015 - tf_pmse_5HT: 186.8221 - tf_pmse_pH: 0.0437 - tf_pmse_NE: 172.5200 - val_loss: 1.3568 - val_tf_pmse_DA: 1205.9446 - val_tf_pmse_5HT: 1196.9905 - val_tf_pmse_pH: 0.3709 - val_tf_pmse_NE: 1212.9327\n",
      "Epoch 100/100\n",
      "369600/369600 [==============================] - 319s 862us/step - loss: 0.0279 - tf_pmse_DA: 173.4041 - tf_pmse_5HT: 186.4032 - tf_pmse_pH: 0.0437 - tf_pmse_NE: 171.9611 - val_loss: 1.3269 - val_tf_pmse_DA: 1182.1327 - val_tf_pmse_5HT: 1201.5477 - val_tf_pmse_pH: 0.3703 - val_tf_pmse_NE: 1179.7224\n",
      "predicting validation set... done.\n",
      "using val_loss to find best metrics\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178.926808</td>\n",
       "      <td>1178.304762</td>\n",
       "      <td>0.360704</td>\n",
       "      <td>1195.165653</td>\n",
       "      <td>31879.162724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit inception time the model\n",
    "\n",
    "if best_model is None:\n",
    "    print('Fitting new model...')\n",
    "    metrics = classifier.fit(x_train, y_train, x_val, y_val, plot_test_acc=True)\n",
    "    best_model = classifier.get_best_model()\n",
    "else:\n",
    "    print('Model alread fit, computing prediction of validation data')\n",
    "    metrics = classifier.predict(x_val, y_val, x_train, y_train, return_df_metrics=True)\n",
    "\n",
    "display(HTML(metrics.to_html()))\n",
    "\n",
    "#  \trmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 0 \t965.848067 \t890.698064 \t0.466687 \t958.003357 \t0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1138.538247</td>\n",
       "      <td>1214.939277</td>\n",
       "      <td>0.317464</td>\n",
       "      <td>1163.510046</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = classifier.predict(x_test, y_test, x_train, y_train, return_df_metrics=True)\n",
    "display(HTML(metrics.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# metrics = pd.DataFrame(data=np.zeros((1, 5), dtype=np.float), index=[0],\n",
    "#                    columns=['rmse_DA', 'rmse_5HT', 'rmse_pH', 'rmse_NE', 'duration'])\n",
    "# metrics['rmse_DA'] = 1200\n",
    "# metrics['rmse_5HT'] = 1100\n",
    "# metrics['rmse_NE'] = 1000\n",
    "# while (int(metrics['rmse_DA'].tolist()[0] > 700) + int(metrics['rmse_5HT'].tolist()[0] > 700) + int(metrics['rmse_NE'].tolist()[0] > 700)) > 1:\n",
    "#     print(int(metrics['rmse_DA'].tolist()[0] > 700) + int(metrics['rmse_5HT'].tolist()[0] > 700) + int(metrics['rmse_NE'].tolist()[0] > 700))\n",
    "#     metrics['rmse_DA'] -= 100 \n",
    "#     metrics['rmse_5HT'] -= 100\n",
    "#     metrics['rmse_NE'] -= 100\n",
    "#     print(metrics)\n",
    "#     time.sleep(.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/proj/in-vitro/Leonardo/inception/results/mm/jitter/MMA024W01R04/best_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1138.538247</td>\n",
       "      <td>1214.939277</td>\n",
       "      <td>0.317464</td>\n",
       "      <td>1163.510046</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = os.path.join(classifier.output_directory, 'best_model.hdf5')\n",
    "# model_path = os.path.join(classifier.output_directory, 'last_model.hdf5')\n",
    "# model_path = os.path.join(classifier.output_directory, 'model_init.hdf5')\n",
    "\n",
    "print(model_path)\n",
    "\n",
    "model = keras.models.load_model(model_path, custom_objects={\"tf_pmse_DA\": tf_pmse_DA, \"tf_pmse_5HT\": tf_pmse_5HT, \"tf_pmse_pH\": tf_pmse_pH, \"tf_pmse_NE\": tf_pmse_NE})\n",
    "\n",
    "xt, yt = x_test, y_test\n",
    "# xt, yt = x_val, y_val\n",
    "\n",
    "yp = model.predict(xt, batch_size=64)\n",
    "\n",
    "yp = np.apply_along_axis(revert_data, axis=1, arr=yp) \n",
    "yt = np.apply_along_axis(revert_data, axis=1, arr=yt) \n",
    "\n",
    "rmse4 = rmse(yt, yp)\n",
    "\n",
    "metrics2 = pd.DataFrame(data=np.zeros((1, 5), dtype=np.float), index=[0], columns=['rmse_DA', 'rmse_5HT', 'rmse_pH', 'rmse_NE', 'duration'])\n",
    "metrics2['rmse_DA'] = rmse4[0]\n",
    "metrics2['rmse_5HT'] = rmse4[1]\n",
    "metrics2['rmse_pH'] = rmse4[2]\n",
    "metrics2['rmse_NE'] = rmse4[3]\n",
    "metrics2['duration'] = 0.0\n",
    "        \n",
    "display(HTML(metrics2.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367baea0159246a5860695525495d0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def plot_concentrations(y):\n",
    "#     fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True)\n",
    "#     for ip in range(0,4):\n",
    "#         axs[np.unravel_index(ip, axs.shape)].hist(y[:,ip])\n",
    "# plot_concentrations(y_test)\n",
    "# plot_concentrations(y_pred)\n",
    "\n",
    "def plot_compare_test_pred(yt, yp):\n",
    "    fig, axs = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "    for ip in range(0,8):\n",
    "        axsidx = np.unravel_index(ip, axs.shape)\n",
    "        if ip < 4:\n",
    "            axs[axsidx].hist(yt[:,ip])\n",
    "        else:\n",
    "            axs[axsidx].hist(yp[:,ip-4])\n",
    "\n",
    "plot_compare_test_pred(yt, yp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1155.750504</td>\n",
       "      <td>1234.179014</td>\n",
       "      <td>0.363365</td>\n",
       "      <td>1222.776316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 999, 128)\n",
      "(128, 4)\n",
      "(1000, 999, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo.barbosa/.conda/envs/inception/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9d8aad914544b69e22680c740e799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo.barbosa/.conda/envs/inception/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5392e741f29e478096f9667176870cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo.barbosa/.conda/envs/inception/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c140f25e084ff388436015efc189d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo.barbosa/.conda/envs/inception/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad003097026f42eab26dc03d54442199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "idxs = np.random.permutation(x_val.shape[0])\n",
    "x_cam = x_val[idxs[:1000],:,:]\n",
    "y_cam = y_val[idxs[:1000], :]\n",
    "\n",
    "# x_cam = x_train[idxs[:1000],:,:]\n",
    "# y_cam = y_train[idxs[:1000], :]\n",
    "\n",
    "w_k_c = model.layers[-1].get_weights()[0] # weights for each filter k for each class c \n",
    "\n",
    "new_input_layer = model.inputs # same input of the original model\n",
    "\n",
    "new_outpu_layer = [model.get_layer(\"conv1d_31\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "# new_outpu_layer = [model.get_layer(\"activation_8\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "\n",
    "new_function = keras.backend.function(new_input_layer,new_outpu_layer)\n",
    "\n",
    "new_feed_forward = new_function\n",
    "\n",
    "[conv_out, y_pred] = new_feed_forward((x_cam,))\n",
    "\n",
    "metrics = classifier._calculate_metrics(y_cam, y_pred, 0.0)\n",
    "display(HTML(metrics.to_html()))\n",
    "print(conv_out.shape)\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "\n",
    "# print(\"original_label: \"+str(encoder.inverse_transform(np.argmax(original_binary_class))))\n",
    "# print(\"original_shape: \"+str(time_series_original.shape))\n",
    "# print(\"predicted_label:\"+str(encoder.inverse_transform(np.argmax(predicted))))\n",
    "# print(\"predicted_shape:\"+str(conv_out.shape))\n",
    "\n",
    "print(w_k_c.shape)\n",
    "print(conv_out.shape)\n",
    "\n",
    "ix=0\n",
    "conv_out_i = conv_out[ix,:,:]\n",
    "# conv_out_i = np.squeeze(np.mean(conv_out, axis=0))\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "for j in range(y_val.shape[1]):\n",
    "    \n",
    "    fig, axs1 = plt.subplots(figsize=(12, 5))\n",
    "#     axsidx = np.unravel_index(j, axs.shape)\n",
    "#     axs1 = axs[axsidx]\n",
    "    \n",
    "    cas = np.zeros(dtype=np.float, shape = (conv_out.shape[1]))\n",
    "    for k,w in enumerate(w_k_c[:,j]):\n",
    "        cas += w * conv_out_i[:,k]\n",
    "    minimum = np.min(cas)\n",
    "    cas = cas - minimum\n",
    "    cas = cas/max(cas)\n",
    "    cas = cas * 100\n",
    "    cas = cas.astype(int)\n",
    "    \n",
    "#     axs[axsidx].plot(cas)\n",
    "\n",
    "    y = np.squeeze(x_cam[ix,:,:])\n",
    "    x = np.array(range(y.shape[0]))\n",
    "    dydx = cas\n",
    "\n",
    "    # Create a set of line segments so that we can color them individually\n",
    "    # This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "    # together easily to get the segments. The segments array for line collection\n",
    "    # needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Create a continuous norm to map from data points to colors\n",
    "    norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "    lc = LineCollection(segments, cmap='jet', norm=norm)\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(dydx)\n",
    "    lc.set_linewidth(3)\n",
    "    line = axs1.add_collection(lc)\n",
    "    fig.colorbar(line, ax=axs1)\n",
    "\n",
    "    # # Use a boundary norm instead\n",
    "    # cmap = ListedColormap(['r', 'g', 'b'])\n",
    "    # norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "    # lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    # lc.set_array(dydx)\n",
    "    # lc.set_linewidth(2)\n",
    "    # line = axs[1].add_collection(lc)\n",
    "    # fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "    axs1.set_xlim(x.min(), x.max())\n",
    "    axs1.set_ylim(y.min(), y.max())\n",
    "    axs1.set_title(names[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
