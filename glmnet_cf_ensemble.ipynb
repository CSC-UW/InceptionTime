{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glmnet_python\n",
    "from glmnet import glmnet\n",
    "\n",
    "# Import relevant modules and setup for calling glmnet\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from itertools import compress\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf # data is in TFRecord format\n",
    "\n",
    "import scipy, importlib, pprint, matplotlib.pyplot as plt, warnings\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import numpy as np\n",
    "from glmnet import glmnet; from glmnetPlot import glmnetPlot\n",
    "from glmnetPrint import glmnetPrint; from glmnetCoef import glmnetCoef; from glmnetPredict import glmnetPredict\n",
    "from cvglmnet import cvglmnet; from cvglmnetCoef import cvglmnetCoef\n",
    "from cvglmnetPlot import cvglmnetPlot; from cvglmnetPredict import cvglmnetPredict\n",
    "\n",
    "# glmnet has many deprecation warnings from using scipy.* instad of numpy.*\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "def plot_distributions(y, y_hat):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 4, sharey=False, sharex=False, tight_layout=True)\n",
    "    fig.set_size_inches(20,10)\n",
    "\n",
    "    for ic in range(0,8):\n",
    "        idx = np.unravel_index(ic, axs.shape)\n",
    "        if ic < 4:\n",
    "            axs[idx].set_title(\"Real %s\"%names[ic])\n",
    "            x = y[:,ic]        \n",
    "        else:\n",
    "            axs[idx].set_title(\"Predicted %s\"%names[ic-4])\n",
    "            x = y_hat[:,ic-4]\n",
    "        axs[idx].hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "ncores = 28 # 56\n",
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "results_prefix = '/mnt/nfs/proj/in-vitro/Leonardo/glmnet/fits/'\n",
    "prefix = os.path.join('/mnt/nfs/proj/in-vitro/Mark/four_analyte/slow/allin')\n",
    "# good_probes = ['CF025']\n",
    "good_probes = ['CF025', 'CF027']\n",
    "# good_probes = ['CF025', 'CF027', 'CF057', 'CF064', 'CF066', 'CF078', 'CF081', 'CF082']\n",
    "# nrecords_per_session = 1 # One is special, loads one sweep per concentration per TFRecord\n",
    "# nrecords_per_session = 2 # Any other number loads that amount of records in sequence from each TFRecord\n",
    "nrecords_per_session = -1 # Loads all records\n",
    "val_ratio = .1\n",
    "hold_probe = 0\n",
    "# hold_probe = -1 # split data randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61650, 999) (61650, 4)\n",
      "(61650, 999) (61650, 4)\n",
      "--- 2.6020078659057617 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    def atoi(text):\n",
    "        return int(text) if text.isdigit() else text\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "def preprocess(serialized_example):\n",
    "    features = tf.io.parse_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'gram': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.string)\n",
    "        })\n",
    "    data = tf.io.decode_raw(features['gram'], tf.float32)\n",
    "    label = tf.io.decode_raw(features['label'], tf.float32)\n",
    "    data.set_shape((None, 999))\n",
    "    label.set_shape((None, 4))\n",
    "    return data, label\n",
    "\n",
    "def merge_datasets(vfiles, projy=lambda x: x, asnumpy=False):\n",
    "    yv = []\n",
    "    yl = []\n",
    "    for filename in vfiles:\n",
    "        ds = tf.data.TFRecordDataset(filename)\n",
    "        ds = ds.batch(batch_size=2**13)\n",
    "        ds = ds.map(map_func=preprocess)\n",
    "        for v,l in ds:\n",
    "            v = np.array(v).astype(np.float64)\n",
    "            l = np.array(l).astype(np.float64)\n",
    "            l = np.apply_along_axis(projy, axis=1, arr=l) \n",
    "            if nrecords_per_session == 1:\n",
    "                _, ulidx = np.unique(l, return_index=True, axis=0)\n",
    "                yv.append(v[ulidx,:])\n",
    "                yl.append(l[ulidx,:])\n",
    "            elif nrecords_per_session > 0:\n",
    "                yv.append(v[:nrecords_per_session,:])\n",
    "                yl.append(l[:nrecords_per_session,:])\n",
    "            else:\n",
    "                yv.append(v)\n",
    "                yl.append(l)\n",
    "#             print(yv[-1].shape)\n",
    "#             print(yl[-1].shape)       \n",
    "    x = np.vstack(yv)\n",
    "    y = np.vstack(yl)\n",
    "\n",
    "    if asnumpy:\n",
    "        return x,y\n",
    "    else:\n",
    "        d = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "        return d\n",
    "\n",
    "if hold_probe < 0:\n",
    "    all_files = sum([\n",
    "        sorted(tf.io.gfile.glob(os.path.join(prefix, probe, 'total_records', '*')),\n",
    "               key=natural_keys) for probe in good_probes\n",
    "    ], [])\n",
    "\n",
    "    x, y = merge_datasets(all_files, asnumpy=True)\n",
    "    \n",
    "    idxs = np.random.permutation(x.shape[0])\n",
    "    lim = int(x.shape[0]*(1-val_ratio))\n",
    "    d1idx = idxs[idxs[:lim]]\n",
    "    d2idx = idxs[idxs[lim:]]\n",
    "    x_train, y_train, x_val, y_val = x[d1idx,:], y[d1idx,:], x[d2idx,:], y[d2idx,:]\n",
    "else:\n",
    "    hold_probe = good_probes.pop(hold_probe)\n",
    "    train_files = sum([\n",
    "        sorted(tf.io.gfile.glob(os.path.join(prefix, probe, 'total_records', '*')),\n",
    "               key=natural_keys) for probe in good_probes\n",
    "    ], [])\n",
    "    x_train, y_train = merge_datasets(train_files, asnumpy=True)\n",
    "    \n",
    "    val_files = sum([\n",
    "        sorted(tf.io.gfile.glob(os.path.join(prefix, probe, 'total_records', '*')),\n",
    "               key=natural_keys) for probe in [hold_probe]\n",
    "    ], [])\n",
    "    x_val, y_val = merge_datasets(val_files, asnumpy=True)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)  \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting training data into cells per concentration...  done.\n"
     ]
    }
   ],
   "source": [
    "print('Spliting training data into cells per concentration... ', end='')\n",
    "\n",
    "# nint = 5\n",
    "nint = 2\n",
    "analytes = [0,1,3]\n",
    "concentrations = [[]]*len(analytes)\n",
    "ranges = [[]]*len(analytes)\n",
    "for ic in range(len(analytes)):\n",
    "    concentrations[ic] = np.linspace(min(y_train[:,analytes[ic]]), max(y_train[:,analytes[ic]]), nint+1)\n",
    "#     print(c[ic])\n",
    "    ranges[ic] = [concentrations[ic][ir] + np.mean(np.diff(concentrations[ic]))/2 for ir in range(len(concentrations[ic])-1)]\n",
    "#     print(r[ic])\n",
    "\n",
    "# use itertools product instead of nested for loops to make it easier to change the number of analytes\n",
    "from itertools import product\n",
    "split_data = {x: np.array([]) for x in product(range(nint), repeat=len(analytes))}\n",
    "error = []\n",
    "# print(len(split_data))\n",
    "for x in split_data:\n",
    "\n",
    "    # build binary mask for this cell\n",
    "    good_data = np.full((y_train.shape[0],), True)\n",
    "#     print(good_data.shape, good_data[0].__class__)\n",
    "    for (ix,nx) in enumerate(x):\n",
    "#         print(sum(good_data))\n",
    "#         print(a[ix], nx)\n",
    "        zeros = y_train[:,analytes[ix]] == 0.0\n",
    "        above = y_train[:,analytes[ix]] > concentrations[ix][nx]\n",
    "#         print(above.shape, above[0].__class__, c[ix][nx])\n",
    "        below = y_train[:,analytes[ix]] < concentrations[ix][nx+1]\n",
    "#         print(below.shape, below[0].__class__, c[ix][nx+1])\n",
    "        interval = np.bitwise_or(np.bitwise_and(above, below), zeros)\n",
    "#         print(interval.shape, interval[0].__class__, sum(interval))\n",
    "        good_data = np.bitwise_and(good_data, interval)\n",
    "\n",
    "#     print(sum(good_data))\n",
    "    # save data\n",
    "    split_data[x] = (x_train[good_data,:], y_train[good_data,:])\n",
    "    \n",
    "    y = split_data[x][1]\n",
    "    means = np.array([np.mean(y[y[:,x]>0, x]) for x in range(4)])\n",
    "#     print(means)\n",
    "    expected_means = np.array([ranges[i][x[i]] for i in range(len(analytes))])\n",
    "#     print(expected_means)\n",
    "    error.append(np.sqrt( (means[np.array(analytes)] - expected_means)**2 ))\n",
    "\n",
    "print(' done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e = np.array(error)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "for idx in range(3):\n",
    "    axs[idx].hist(e[:,idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 10 cross-validations for model 0 of 8 ((0, 0, 0)) ... "
     ]
    }
   ],
   "source": [
    "# fit GLMNET in parallel (ncores) with cross validation to find lambda\n",
    "\n",
    "# alphas = [.9, 1.]\n",
    "alpha = 1.0\n",
    "models = {x: [] for x in split_data}\n",
    "ncross = 10\n",
    "nx = len(split_data)\n",
    "for (ix, x) in enumerate(split_data):\n",
    "    this_x_train, this_y_train = split_data[x]\n",
    "    print(f'Computing {ncross} cross-validations for model {ix} of {nx} ({x}) ... ', end='')\n",
    "    start_time = time.time()\n",
    "    models[x] = cvglmnet(x = this_x_train.copy(), y = this_y_train.copy(), family='mgaussian', parallel=ncores, ptype = 'mse', nfolds = ncross, alpha=alpha)\n",
    "    print(\" took %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(results_prefix, f'cf_alpha_1.0_{nint}x{nint}x{nint}.pickle')\n",
    "print(output_file)\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the model with predictions closest to original range (sum over all analytes) and compute RMSE of each analyte for that model \n",
    "\n",
    "# generate the predictions for each model\n",
    "y_hats = np.zeros((len(models), y_val.shape[0], y_val.shape[1]))\n",
    "for (ix, x) in enumerate(models):\n",
    "    print(f'{ix} of {nx} ({x})')\n",
    "    model = models[x]\n",
    "# #     y_hat = cvglmnetPredict(fit, newx = x_val, s='lambda_min')\n",
    "    y_hat = cvglmnetPredict(model, newx = x_val, s='lambda_1se')\n",
    "#     y_hat = y_val[:,:,None]*(1.+0.1*np.random.randn(y_val.shape[0], y_val.shape[1], 1))\n",
    "    y_hats[ix,:,:] = y_hat[:,:,0]\n",
    "\n",
    "# compute the differences to original intervals\n",
    "diff_y_hats = np.zeros(y_hats[:,:,analytes].shape)\n",
    "for (ix,x) in enumerate(models):\n",
    "    for ia in range(len(analytes)):\n",
    "        diff_y_hats[ix,:,ia] = (y_hats[ix,:,analytes[ia]] - ranges[ia][x[ia]])**2\n",
    "\n",
    "# find the model with sum of predictions closest to original intervals\n",
    "model_e = np.sum(diff_y_hats,axis=2)\n",
    "min_idx = model_e.argmin(axis=0)\n",
    "\n",
    "# compute the RMSE for each sample (there is certainly a more pythonic way to do that, but that works)\n",
    "rmse = np.zeros((4,), dtype=np.float64)\n",
    "for (sample_idx, model_idx) in enumerate(min_idx):\n",
    "    rmse += (y_hats[model_idx, sample_idx, :] - y_val[sample_idx, :])**2/y_val.shape[0]\n",
    "rmse = np.sqrt(rmse) \n",
    "\n",
    "for (armse, name) in zip(rmse,names):\n",
    "    print('%s: %4.5f'%(name,armse), flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [2 1]]\n",
      "[[1 2]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([ [[1,2],[3,4]], [[4,3],[2,1]], [[2,4],[1,4]] ])\n",
    "idx_min = np.argmin(x,axis=0)\n",
    "print(idx_min)\n",
    "print(idx_min.choose(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
