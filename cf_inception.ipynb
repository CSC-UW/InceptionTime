{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/apps/software/TensorFlow/2.2.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "#sys.path = [p for p in sys.path if p.find('/opt/apps/software/') == -1]\n",
    "from glob import glob\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
    "from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
    "from utils.utils import read_all_datasets, transform_labels, create_directory, run_length_xps, generate_results_csv, plot_epochs_metric\n",
    "from utils.data_loading import get_multiple_data_cf, predict, shifted_zscore_cf, zscore, print_metric, tf_rmse, tf_pmse_cf, rmse\n",
    "import utils\n",
    "from classifiers import inception\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "# keras.backend.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def tf_pmse_DA(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=0)\n",
    "\n",
    "def tf_pmse_5HT(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=1)\n",
    "\n",
    "def tf_pmse_pH(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=2)\n",
    "\n",
    "def tf_pmse_NE(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving out probe CF078\n",
      "Validation probe CF025\n",
      "Loading data\n",
      "loading probe CF025\n",
      "loading probe CF027\n",
      "loading probe CF057\n",
      "loading probe CF064\n",
      "loading probe CF066\n",
      "loading probe CF078\n",
      "loading probe CF081\n",
      "loading probe CF082\n",
      "Shuffling training dataset\n",
      "Data loaded\n",
      "adding singleton\n"
     ]
    }
   ],
   "source": [
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "speed = 'slow'\n",
    "data_prefix = '/mnt/nfs/proj/in-vitro/Leonardo/cf_data'\n",
    "\n",
    "probes = [\n",
    "    'CF025', 'CF027', 'CF057', 'CF064', 'CF066', 'CF078', 'CF081', 'CF082'\n",
    "]\n",
    "\n",
    "hold_probe = probes[5]\n",
    "output_directory = f'/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/{hold_probe}/'\n",
    "\n",
    "if not (os.path.exists(output_directory)):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# val_probe=None\n",
    "val_probe=probes[0]\n",
    "\n",
    "print(f'Leaving out probe {hold_probe}', flush=True)\n",
    "print(f'Validation probe {val_probe}', flush=True)\n",
    "print(f'Loading data', flush=True)\n",
    "\n",
    "# normalize_data = minmax\n",
    "# revert_data = lambda x: minmax(x, inverse=True)\n",
    "\n",
    "normalize_data = shifted_zscore_cf\n",
    "revert_data = lambda x: shifted_zscore_cf(x, inverse=True)\n",
    "\n",
    "# normalize_data = lambda x: x\n",
    "# revert_data = lambda x: x\n",
    "\n",
    "# this is actually the number of records per UNIQUE CONCENTRATIONS per probe\n",
    "n_records_per_probe = -1 # all\n",
    "# n_records_per_probe = 1\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_multiple_data_cf(data_prefix,\n",
    "                                                                      probes=probes,\n",
    "                                                                      hold_probe=hold_probe,\n",
    "                                                                      val_probe=val_probe,\n",
    "                                                                      normalize_data=normalize_data,\n",
    "                                                                      n_records_per_probe=n_records_per_probe)\n",
    "\n",
    "print('Data loaded')\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    print('adding singleton')\n",
    "    # add a dimension to make it multivariate with one dimension\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "output_shape = y_train.shape[1]\n",
    "input_shape = x_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369900, 999, 1)\n",
      "(369900, 4)\n",
      "(61650, 999, 1)\n",
      "(61650, 4)\n",
      "(61650, 999, 1)\n",
      "(61650, 4)\n",
      "4\n",
      "(999, 1)\n"
     ]
    }
   ],
   "source": [
    "for x in [x_train, y_train, x_val, y_val, x_test, y_test]:\n",
    "    print(x.shape)\n",
    "print(output_shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:CPU:0',)\n",
      "starting model from scratch...\n",
      "Compiling with Adam and metrics:  ['tf_pmse_DA', 'tf_pmse_5HT', 'tf_pmse_pH', 'tf_pmse_NE']\n",
      "Best model already fit: /mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/CF078/best_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classifier = inception.Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=10, metrics='CF')\n",
    "classifier = inception.Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=100, \n",
    "                                            metrics=[tf_pmse_DA, tf_pmse_5HT, tf_pmse_pH, tf_pmse_NE], revert_data=revert_data)\n",
    "# classifier = Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=100)\n",
    "\n",
    "model_path = classifier.output_directory + 'best_model.hdf5'\n",
    "if os.path.isfile(model_path):\n",
    "    print('Best model already fit: %s'%model_path)\n",
    "    best_model = classifier.get_best_model()\n",
    "else:\n",
    "    print('Model not fit yet')\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model alread fit, computing prediction of validation data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>466.477978</td>\n",
       "      <td>344.976229</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>716.69803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit inception time the model\n",
    "\n",
    "if best_model is None:\n",
    "    print('Fitting new model...')\n",
    "    metrics = classifier.fit(x_train, y_train, x_val, y_val, plot_test_acc=True)\n",
    "    best_model = classifier.get_best_model()\n",
    "else:\n",
    "    print('Model alread fit, computing prediction of validation data')\n",
    "    metrics = classifier.predict(x_val, y_val, x_train, y_train, return_df_metrics=True)\n",
    "\n",
    "display(HTML(metrics.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold CF082, validation CF025, all data, 100 epochs\n",
    "# Epoch 1/100\n",
    "# 369900/369900 [==============================] - 332s 897us/step - loss: 0.3839 - tf_pmse_DA: 488.6883 - tf_pmse_5HT: 418.8771 - tf_pmse_pH: 0.0728 - tf_pmse_NE: 545.8939 - val_loss: 0.9853 - val_tf_pmse_DA: 879.1813 - val_tf_pmse_5HT: 389.8340 - val_tf_pmse_pH: 0.1891 - val_tf_pmse_NE: 1166.5785\n",
    "# Epoch 10/100\n",
    "# 369900/369900 [==============================] - 324s 875us/step - loss: 0.0139 - tf_pmse_DA: 132.5645 - tf_pmse_5HT: 111.5507 - tf_pmse_pH: 0.0200 - tf_pmse_NE: 139.9987 - val_loss: 0.1967 - val_tf_pmse_DA: 340.3430 - val_tf_pmse_5HT: 337.9328 - val_tf_pmse_pH: 0.0613 - val_tf_pmse_NE: 453.8609\n",
    "# Epoch 97/100\n",
    "# 369900/369900 [==============================] - 323s 872us/step - loss: 0.0021 - tf_pmse_DA: 50.4458 - tf_pmse_5HT: 46.5694 - tf_pmse_pH: 0.0077 - tf_pmse_NE: 54.5813 - val_loss: 0.1685 - val_tf_pmse_DA: 356.7854 - val_tf_pmse_5HT: 305.9508 - val_tf_pmse_pH: 0.0534 - val_tf_pmse_NE: 400.9060\n",
    "# Epoch 100/100\n",
    "# 369900/369900 [==============================] - 322s 871us/step - loss: 0.0020 - tf_pmse_DA: 49.6475 - tf_pmse_5HT: 46.6628 - tf_pmse_pH: 0.0076 - tf_pmse_NE: 53.9088 - val_loss: 0.2012 - val_tf_pmse_DA: 375.4945 - val_tf_pmse_5HT: 356.6755 - val_tf_pmse_pH: 0.0558 - val_tf_pmse_NE: 441.8727\n",
    "# predicting validation set... \n",
    "# \trmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 0 \t483.575696 \t504.289784 \t0.072682 \t604.31947 \t32320.917521\n",
    "# Epoch 70/100\n",
    "# 369900/369900 [==============================] - 321s 868us/step - loss: 0.0026 - tf_pmse_DA: 55.4761 - tf_pmse_5HT: 51.8563 - tf_pmse_pH: 0.0084 - tf_pmse_NE: 63.0837 - val_loss: 0.2494 - val_tf_pmse_DA: 403.2530 - val_tf_pmse_5HT: 277.9370 - val_tf_pmse_pH: 0.0658 - val_tf_pmse_NE: 549.2294\n",
    "# Epoch 100/100\n",
    "# 369900/369900 [==============================] - 321s 868us/step - loss: 0.0019 - tf_pmse_DA: 49.0351 - tf_pmse_5HT: 46.0001 - tf_pmse_pH: 0.0072 - tf_pmse_NE: 55.4475 - val_loss: 0.2707 - val_tf_pmse_DA: 410.6053 - val_tf_pmse_5HT: 278.3472 - val_tf_pmse_pH: 0.0673 - val_tf_pmse_NE: 557.2681\n",
    "# rmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 0 \t466.478029 \t344.97594 \t0.094177 \t716.697981 \t32189.755459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>372.568581</td>\n",
       "      <td>143.972704</td>\n",
       "      <td>0.06122</td>\n",
       "      <td>322.67593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = classifier.predict(x_test, y_test, x_train, y_train, return_df_metrics=True)\n",
    "display(HTML(metrics.to_html()))\n",
    "\n",
    "# Hold CF082, validation CF025, all data, 100 epochs\n",
    "# rmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 289.592247 \t148.701677 \t0.082032 \t416.473678 \t0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/CF078/last_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249.979295</td>\n",
       "      <td>117.124644</td>\n",
       "      <td>0.076045</td>\n",
       "      <td>336.884448</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model_path = os.path.join(classifier.output_directory, 'best_model.hdf5')\n",
    "model_path = os.path.join(classifier.output_directory, 'last_model.hdf5')\n",
    "# model_path = os.path.join(classifier.output_directory, 'model_init.hdf5')\n",
    "\n",
    "print(model_path)\n",
    "\n",
    "model = keras.models.load_model(model_path, custom_objects={\"tf_pmse_DA\": tf_pmse_DA, \"tf_pmse_5HT\": tf_pmse_5HT, \"tf_pmse_pH\": tf_pmse_pH, \"tf_pmse_NE\": tf_pmse_NE})\n",
    "\n",
    "xt, yt = x_test, y_test\n",
    "# xt, yt = x_val, y_val\n",
    "\n",
    "yp = model.predict(xt, batch_size=64)\n",
    "\n",
    "yp = np.apply_along_axis(revert_data, axis=1, arr=yp) \n",
    "yt = np.apply_along_axis(revert_data, axis=1, arr=yt) \n",
    "\n",
    "rmse4 = rmse(yt, yp)\n",
    "\n",
    "metrics2 = pd.DataFrame(data=np.zeros((1, 5), dtype=np.float), index=[0], columns=['rmse_DA', 'rmse_5HT', 'rmse_pH', 'rmse_NE', 'duration'])\n",
    "metrics2['rmse_DA'] = rmse4[0]\n",
    "metrics2['rmse_5HT'] = rmse4[1]\n",
    "metrics2['rmse_pH'] = rmse4[2]\n",
    "metrics2['rmse_NE'] = rmse4[3]\n",
    "metrics2['duration'] = 0.0\n",
    "        \n",
    "display(HTML(metrics2.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b57cddb0aa45e29e4318f7e8d3f036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def plot_concentrations(y):\n",
    "#     fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True)\n",
    "#     for ip in range(0,4):\n",
    "#         axs[np.unravel_index(ip, axs.shape)].hist(y[:,ip])\n",
    "# plot_concentrations(y_test)\n",
    "# plot_concentrations(y_pred)\n",
    "\n",
    "def plot_compare_test_pred(yt, yp):\n",
    "    fig, axs = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "    for ip in range(0,8):\n",
    "        axsidx = np.unravel_index(ip, axs.shape)\n",
    "        if ip < 4:\n",
    "            axs[axsidx].hist(yt[:,ip])\n",
    "        else:\n",
    "            axs[axsidx].hist(yp[:,ip-4])\n",
    "\n",
    "plot_compare_test_pred(yt, yp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445.641809</td>\n",
       "      <td>341.767141</td>\n",
       "      <td>0.095284</td>\n",
       "      <td>694.319579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 999, 128)\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "idxs = np.random.permutation(x_val.shape[0])\n",
    "x_cam = x_val[idxs[:1000],:,:]\n",
    "y_cam = y_val[idxs[:1000], :]\n",
    "\n",
    "w_k_c = model.layers[-1].get_weights()[0] # weights for each filter k for each class c \n",
    "\n",
    "new_input_layer = model.inputs # same input of the original model\n",
    "\n",
    "new_outpu_layer = [model.get_layer(\"conv1d_31\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "# new_outpu_layer = [model.get_layer(\"activation_8\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "\n",
    "new_function = keras.backend.function(new_input_layer,new_outpu_layer)\n",
    "\n",
    "new_feed_forward = new_function\n",
    "\n",
    "[conv_out, y_pred] = new_feed_forward((x_cam,))\n",
    "\n",
    "metrics = classifier._calculate_metrics(y_cam, y_pred, 0.0)\n",
    "display(HTML(metrics.to_html()))\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_k_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n",
      "(1000, 999, 128)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfa3c04791046c5b03b2cd6f7e3701e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# print(\"original_label: \"+str(encoder.inverse_transform(np.argmax(original_binary_class))))\n",
    "# print(\"original_shape: \"+str(time_series_original.shape))\n",
    "# print(\"predicted_label:\"+str(encoder.inverse_transform(np.argmax(predicted))))\n",
    "# print(\"predicted_shape:\"+str(conv_out.shape))\n",
    "\n",
    "print(w_k_c.shape)\n",
    "print(conv_out.shape)\n",
    "\n",
    "conv_out_0 = conv_out[0,:,:]\n",
    "# conv_out_0 = np.squeeze(np.mean(conv_out, axis=0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "for j in range(y_val.shape[1]):\n",
    "    \n",
    "    axsidx = np.unravel_index(j, axs.shape)\n",
    "    \n",
    "    cas = np.zeros(dtype=np.float, shape = (conv_out.shape[1]))\n",
    "    for k,w in enumerate(w_k_c[:,j]):\n",
    "        cas += w * conv_out_0[:,k]\n",
    "    minimum = np.min(cas)\n",
    "    cas = cas - minimum\n",
    "    cas = cas/max(cas)\n",
    "    cas = cas * 100\n",
    "    cas = cas.astype(int)\n",
    "    \n",
    "#     axs[axsidx].plot(cas)\n",
    "\n",
    "    y = np.squeeze(np.mean(x_cam, axis=0))\n",
    "    x = np.array(range(y.shape[0]))\n",
    "    dydx = cas\n",
    "\n",
    "    # Create a set of line segments so that we can color them individually\n",
    "    # This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "    # together easily to get the segments. The segments array for line collection\n",
    "    # needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Create a continuous norm to map from data points to colors\n",
    "    norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "    lc = LineCollection(segments, cmap='jet', norm=norm)\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(dydx)\n",
    "    lc.set_linewidth(4)\n",
    "    line = axs[axsidx].add_collection(lc)\n",
    "    fig.colorbar(line, ax=axs[axsidx])\n",
    "\n",
    "    # # Use a boundary norm instead\n",
    "    # cmap = ListedColormap(['r', 'g', 'b'])\n",
    "    # norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "    # lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    # lc.set_array(dydx)\n",
    "    # lc.set_linewidth(2)\n",
    "    # line = axs[1].add_collection(lc)\n",
    "    # fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "    axs[axsidx].set_xlim(x.min(), x.max())\n",
    "    axs[axsidx].set_ylim(y.min(), y.max())\n",
    "    axs[axsidx].set_title(names[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n",
      "(1000, 999, 128)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee29865b901b4d9f8b8df4d5ac2ab247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# print(\"original_label: \"+str(encoder.inverse_transform(np.argmax(original_binary_class))))\n",
    "# print(\"original_shape: \"+str(time_series_original.shape))\n",
    "# print(\"predicted_label:\"+str(encoder.inverse_transform(np.argmax(predicted))))\n",
    "# print(\"predicted_shape:\"+str(conv_out.shape))\n",
    "\n",
    "print(w_k_c.shape)\n",
    "print(conv_out.shape)\n",
    "\n",
    "conv_out_0 = conv_out[0,:,:]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "for j in range(y_val.shape[1]):\n",
    "    \n",
    "    axsidx = np.unravel_index(j, axs.shape)\n",
    "    \n",
    "    cas = np.zeros(dtype=np.float, shape = (conv_out.shape[1]))\n",
    "    for k,w in enumerate(w_k_c[:,j]):\n",
    "        cas += w * conv_out_0[:,k]\n",
    "    minimum = np.min(cas)\n",
    "    cas = cas - minimum\n",
    "    cas = cas/max(cas)\n",
    "    cas = cas * 100\n",
    "    cas = cas.astype(int)\n",
    "    \n",
    "#     axs[axsidx].plot(cas)\n",
    "\n",
    "    y = np.squeeze(np.mean(x_cam, axis=0))\n",
    "    x = np.array(range(y.shape[0]))\n",
    "    dydx = cas\n",
    "\n",
    "    # Create a set of line segments so that we can color them individually\n",
    "    # This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "    # together easily to get the segments. The segments array for line collection\n",
    "    # needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Create a continuous norm to map from data points to colors\n",
    "    norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "    lc = LineCollection(segments, cmap='CMRmap', norm=norm)\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(dydx)\n",
    "    lc.set_linewidth(4)\n",
    "    line = axs[axsidx].add_collection(lc)\n",
    "    fig.colorbar(line, ax=axs[axsidx])\n",
    "\n",
    "    # # Use a boundary norm instead\n",
    "    # cmap = ListedColormap(['r', 'g', 'b'])\n",
    "    # norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "    # lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    # lc.set_array(dydx)\n",
    "    # lc.set_linewidth(2)\n",
    "    # line = axs[1].add_collection(lc)\n",
    "    # fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "    axs[axsidx].set_xlim(x.min(), x.max())\n",
    "    axs[axsidx].set_ylim(y.min(), y.max())\n",
    "    axs[axsidx].set_title(names[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
