{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "#sys.path = [p for p in sys.path if p.find('/opt/apps/software/') == -1]\n",
    "from glob import glob\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
    "from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
    "from utils.utils import read_all_datasets, transform_labels, create_directory, run_length_xps, generate_results_csv, plot_epochs_metric, rmse\n",
    "from utils.data_loading import get_multiple_data_cf, predict, shifted_zscore_cf, zscore, print_metric, tf_rmse, tf_pmse_cf\n",
    "import utils\n",
    "from classifiers import inception\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "# keras.backend.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "def tf_pmse_DA(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=0)\n",
    "\n",
    "def tf_pmse_5HT(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=1)\n",
    "\n",
    "def tf_pmse_pH(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=2)\n",
    "\n",
    "def tf_pmse_NE(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving out probe CF027\n",
      "Validation probe CF025\n",
      "Loading data\n",
      "loading probe CF025\n",
      "loading probe CF027\n",
      "loading probe CF057\n",
      "loading probe CF064\n",
      "loading probe CF066\n",
      "loading probe CF078\n",
      "loading probe CF081\n",
      "loading probe CF082\n",
      "Shuffling training dataset\n",
      "Data loaded\n",
      "adding singleton\n"
     ]
    }
   ],
   "source": [
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "speed = 'slow'\n",
    "data_prefix = '/mnt/nfs/proj/in-vitro/Leonardo/cf_data'\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "probes = [\n",
    "    'CF025', 'CF027', 'CF057', 'CF064', 'CF066', 'CF078', 'CF081', 'CF082'\n",
    "]\n",
    "\n",
    "probe = 1\n",
    "hold_probe = probes[probe]\n",
    "\n",
    "# jitter = None\n",
    "jitter = 500\n",
    "output_directory = f'/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/J{jitter}/E{epochs}/{hold_probe}/'\n",
    "\n",
    "if not (os.path.exists(output_directory)):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# val_probe=None\n",
    "val_probe=probes[probe-1]\n",
    "\n",
    "print(f'Leaving out probe {hold_probe}', flush=True)\n",
    "print(f'Validation probe {val_probe}', flush=True)\n",
    "print(f'Loading data', flush=True)\n",
    "\n",
    "# normalize_data = minmax\n",
    "# revert_data = lambda x: minmax(x, inverse=True)\n",
    "\n",
    "normalize_data = shifted_zscore_cf\n",
    "revert_data = lambda x: shifted_zscore_cf(x, inverse=True)\n",
    "\n",
    "# normalize_data = lambda x: x\n",
    "# revert_data = lambda x: x\n",
    "\n",
    "# this is actually the number of records per UNIQUE CONCENTRATIONS per probe\n",
    "n_records_per_probe = -1 # all\n",
    "# n_records_per_probe = 1\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_multiple_data_cf(data_prefix,\n",
    "                                                                      probes=probes,\n",
    "                                                                      hold_probe=hold_probe,\n",
    "                                                                      val_probe=val_probe,\n",
    "                                                                      normalize_data=lambda x: x,\n",
    "                                                                      n_records_per_probe=n_records_per_probe,\n",
    "                                                                      jitter=jitter)\n",
    "\n",
    "print('Data loaded')\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    print('adding singleton')\n",
    "    # add a dimension to make it multivariate with one dimension\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "output_shape = y_train.shape[1]\n",
    "input_shape = x_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369900, 999, 1)\n",
      "(369900, 4)\n",
      "(61650, 999, 1)\n",
      "(61650, 4)\n",
      "(61650, 999, 1)\n",
      "(61650, 4)\n",
      "4\n",
      "(999, 1)\n"
     ]
    }
   ],
   "source": [
    "for x in [x_train, y_train, x_val, y_val, x_test, y_test]:\n",
    "    print(x.shape)\n",
    "print(output_shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4fd05772d84aa6a73a143dd0423d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probe_x, probe_y = x_train, y_train\n",
    "# probe_x, probe_y = x_val, y_val\n",
    "# probe_x, probe_y = x_test, y_test\n",
    "\n",
    "ul, ulidx = np.unique(probe_y, return_index=True, axis=0)\n",
    "\n",
    "fig, axs = plt.subplots(tight_layout=True, figsize=(12, 5))\n",
    "\n",
    "for idx in ulidx:\n",
    "    axs.plot(probe_x[idx,:])\n",
    "#     axs[iprobe].set_ylim(-50, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/replica:0/task:0/device:GPU:0', '/replica:0/task:0/device:GPU:1')\n",
      "WARNING:tensorflow:From /opt/apps/software/TensorFlow/2.2.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "starting model from scratch...\n",
      "Compiling with Adam and metrics:  ['tf_pmse_DA', 'tf_pmse_5HT', 'tf_pmse_pH', 'tf_pmse_NE']\n",
      "Model not fit yet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = inception.Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=epochs, \n",
    "                                            metrics=[tf_pmse_DA, tf_pmse_5HT, tf_pmse_pH, tf_pmse_NE], normalize_y=(normalize_data, revert_data))\n",
    "\n",
    "model_path = classifier.output_directory + 'best_model.hdf5'\n",
    "if os.path.isfile(model_path):\n",
    "    print('Best model already fit: %s'%model_path)\n",
    "    best_model = classifier.get_best_model()\n",
    "else:\n",
    "    print('Model not fit yet')\n",
    "    best_model = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 999, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 999, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 999, 32)      1280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 999, 32)      640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 999, 32)      320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 999, 32)      32          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 999, 128)     0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 999, 128)     512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 999, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 999, 32)      4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 999, 128)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 999, 32)      40960       conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 999, 32)      20480       conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 999, 32)      10240       conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 999, 32)      4096        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 999, 128)     0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 999, 128)     512         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 999, 128)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 999, 32)      4096        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 999, 128)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 999, 32)      40960       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 999, 32)      20480       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 999, 32)      10240       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 999, 32)      4096        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 999, 128)     0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 999, 128)     128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 999, 128)     512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 999, 128)     512         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 999, 128)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 999, 128)     0           batch_normalization_4[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 999, 128)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 999, 32)      4096        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 999, 128)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 999, 32)      40960       conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 999, 32)      20480       conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 999, 32)      10240       conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 999, 32)      4096        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 999, 128)     0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 999, 128)     512         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 999, 128)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 999, 32)      4096        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 999, 128)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 999, 32)      40960       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 999, 32)      20480       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 999, 32)      10240       conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 999, 32)      4096        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 999, 128)     0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 999, 128)     512         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 999, 128)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 999, 32)      4096        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 999, 128)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 999, 32)      40960       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 999, 32)      20480       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 999, 32)      10240       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 999, 32)      4096        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 999, 128)     0           conv1d_27[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 999, 128)     16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 999, 128)     512         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 999, 128)     512         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 999, 128)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 999, 128)     0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 999, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            516         global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 422,756\n",
      "Trainable params: 420,708\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting new model...\n",
      "mini batch size: 64\n",
      "Train on 369900 samples, validate on 61650 samples\n",
      "Epoch 1/100\n",
      "369900/369900 [==============================] - 333s 899us/step - loss: 0.3234 - tf_pmse_DA: 427.3612 - tf_pmse_5HT: 370.6627 - tf_pmse_pH: 0.0694 - tf_pmse_NE: 492.4610 - val_loss: 2.1375 - val_tf_pmse_DA: 1568.5154 - val_tf_pmse_5HT: 731.9577 - val_tf_pmse_pH: 0.2481 - val_tf_pmse_NE: 1207.4766\n",
      "Epoch 2/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0488 - tf_pmse_DA: 245.9362 - tf_pmse_5HT: 210.8451 - tf_pmse_pH: 0.0370 - tf_pmse_NE: 272.5615 - val_loss: 1.5076 - val_tf_pmse_DA: 1087.5815 - val_tf_pmse_5HT: 646.7528 - val_tf_pmse_pH: 0.1926 - val_tf_pmse_NE: 827.5493\n",
      "Epoch 3/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0337 - tf_pmse_DA: 206.6254 - tf_pmse_5HT: 169.7615 - tf_pmse_pH: 0.0307 - tf_pmse_NE: 225.9519 - val_loss: 2.4003 - val_tf_pmse_DA: 934.0377 - val_tf_pmse_5HT: 606.6266 - val_tf_pmse_pH: 0.3020 - val_tf_pmse_NE: 765.1009\n",
      "Epoch 4/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0261 - tf_pmse_DA: 181.1618 - tf_pmse_5HT: 143.1025 - tf_pmse_pH: 0.0272 - tf_pmse_NE: 200.9728 - val_loss: 1.3999 - val_tf_pmse_DA: 854.2691 - val_tf_pmse_5HT: 648.3142 - val_tf_pmse_pH: 0.1961 - val_tf_pmse_NE: 853.7664\n",
      "Epoch 5/100\n",
      "369900/369900 [==============================] - 322s 870us/step - loss: 0.0211 - tf_pmse_DA: 162.1260 - tf_pmse_5HT: 127.4126 - tf_pmse_pH: 0.0246 - tf_pmse_NE: 179.2958 - val_loss: 1.8741 - val_tf_pmse_DA: 796.5025 - val_tf_pmse_5HT: 616.7762 - val_tf_pmse_pH: 0.2446 - val_tf_pmse_NE: 1012.3786\n",
      "Epoch 6/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0176 - tf_pmse_DA: 145.0104 - tf_pmse_5HT: 115.9260 - tf_pmse_pH: 0.0229 - tf_pmse_NE: 163.0214 - val_loss: 1.5459 - val_tf_pmse_DA: 753.9287 - val_tf_pmse_5HT: 583.3644 - val_tf_pmse_pH: 0.2047 - val_tf_pmse_NE: 821.9525\n",
      "Epoch 7/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0150 - tf_pmse_DA: 133.2428 - tf_pmse_5HT: 106.0631 - tf_pmse_pH: 0.0213 - tf_pmse_NE: 151.1007 - val_loss: 1.3943 - val_tf_pmse_DA: 765.8874 - val_tf_pmse_5HT: 569.2422 - val_tf_pmse_pH: 0.2027 - val_tf_pmse_NE: 842.7044\n",
      "Epoch 8/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0136 - tf_pmse_DA: 123.3042 - tf_pmse_5HT: 99.5250 - tf_pmse_pH: 0.0206 - tf_pmse_NE: 141.8361 - val_loss: 1.6964 - val_tf_pmse_DA: 940.4580 - val_tf_pmse_5HT: 552.0067 - val_tf_pmse_pH: 0.2252 - val_tf_pmse_NE: 840.3894\n",
      "Epoch 9/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0123 - tf_pmse_DA: 116.9746 - tf_pmse_5HT: 95.7114 - tf_pmse_pH: 0.0196 - tf_pmse_NE: 135.3623 - val_loss: 1.5060 - val_tf_pmse_DA: 999.5693 - val_tf_pmse_5HT: 581.0093 - val_tf_pmse_pH: 0.1999 - val_tf_pmse_NE: 968.1384\n",
      "Epoch 10/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0113 - tf_pmse_DA: 111.6188 - tf_pmse_5HT: 91.8428 - tf_pmse_pH: 0.0189 - tf_pmse_NE: 128.6653 - val_loss: 1.7003 - val_tf_pmse_DA: 950.5567 - val_tf_pmse_5HT: 579.1990 - val_tf_pmse_pH: 0.2218 - val_tf_pmse_NE: 856.3263\n",
      "Epoch 11/100\n",
      "369900/369900 [==============================] - 326s 880us/step - loss: 0.0103 - tf_pmse_DA: 106.3582 - tf_pmse_5HT: 88.2623 - tf_pmse_pH: 0.0181 - tf_pmse_NE: 122.7790 - val_loss: 1.5122 - val_tf_pmse_DA: 828.0596 - val_tf_pmse_5HT: 606.3560 - val_tf_pmse_pH: 0.2048 - val_tf_pmse_NE: 883.1418\n",
      "Epoch 12/100\n",
      "369900/369900 [==============================] - 324s 877us/step - loss: 0.0096 - tf_pmse_DA: 102.7969 - tf_pmse_5HT: 84.7789 - tf_pmse_pH: 0.0175 - tf_pmse_NE: 118.4208 - val_loss: 1.4097 - val_tf_pmse_DA: 957.1568 - val_tf_pmse_5HT: 577.9423 - val_tf_pmse_pH: 0.1965 - val_tf_pmse_NE: 842.9739\n",
      "Epoch 13/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0090 - tf_pmse_DA: 99.7697 - tf_pmse_5HT: 81.8370 - tf_pmse_pH: 0.0169 - tf_pmse_NE: 115.3994 - val_loss: 1.4424 - val_tf_pmse_DA: 898.5417 - val_tf_pmse_5HT: 576.6622 - val_tf_pmse_pH: 0.2000 - val_tf_pmse_NE: 914.0617\n",
      "Epoch 14/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0086 - tf_pmse_DA: 96.3284 - tf_pmse_5HT: 80.1903 - tf_pmse_pH: 0.0166 - tf_pmse_NE: 112.3678 - val_loss: 1.4554 - val_tf_pmse_DA: 931.0195 - val_tf_pmse_5HT: 614.0059 - val_tf_pmse_pH: 0.1904 - val_tf_pmse_NE: 941.3574\n",
      "Epoch 15/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0081 - tf_pmse_DA: 92.7883 - tf_pmse_5HT: 78.3147 - tf_pmse_pH: 0.0162 - tf_pmse_NE: 109.4342 - val_loss: 1.6467 - val_tf_pmse_DA: 900.3316 - val_tf_pmse_5HT: 585.8916 - val_tf_pmse_pH: 0.2193 - val_tf_pmse_NE: 870.1509\n",
      "Epoch 16/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0076 - tf_pmse_DA: 89.6911 - tf_pmse_5HT: 76.3591 - tf_pmse_pH: 0.0155 - tf_pmse_NE: 106.8475 - val_loss: 1.3217 - val_tf_pmse_DA: 809.5051 - val_tf_pmse_5HT: 585.6562 - val_tf_pmse_pH: 0.1839 - val_tf_pmse_NE: 856.6397\n",
      "Epoch 17/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0073 - tf_pmse_DA: 89.3684 - tf_pmse_5HT: 74.0827 - tf_pmse_pH: 0.0153 - tf_pmse_NE: 104.0809 - val_loss: 1.5561 - val_tf_pmse_DA: 866.4658 - val_tf_pmse_5HT: 605.5560 - val_tf_pmse_pH: 0.2083 - val_tf_pmse_NE: 872.1524\n",
      "Epoch 18/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0070 - tf_pmse_DA: 86.2697 - tf_pmse_5HT: 73.0833 - tf_pmse_pH: 0.0149 - tf_pmse_NE: 102.6612 - val_loss: 1.3932 - val_tf_pmse_DA: 816.5200 - val_tf_pmse_5HT: 610.4513 - val_tf_pmse_pH: 0.1918 - val_tf_pmse_NE: 906.6758\n",
      "Epoch 19/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0067 - tf_pmse_DA: 84.3700 - tf_pmse_5HT: 71.7785 - tf_pmse_pH: 0.0147 - tf_pmse_NE: 99.7681 - val_loss: 1.4270 - val_tf_pmse_DA: 777.7802 - val_tf_pmse_5HT: 636.0657 - val_tf_pmse_pH: 0.2038 - val_tf_pmse_NE: 860.2640\n",
      "Epoch 20/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0064 - tf_pmse_DA: 83.6553 - tf_pmse_5HT: 69.6895 - tf_pmse_pH: 0.0142 - tf_pmse_NE: 98.6442 - val_loss: 1.4065 - val_tf_pmse_DA: 813.7829 - val_tf_pmse_5HT: 629.0322 - val_tf_pmse_pH: 0.2017 - val_tf_pmse_NE: 872.5571\n",
      "Epoch 21/100\n",
      "369900/369900 [==============================] - 322s 870us/step - loss: 0.0062 - tf_pmse_DA: 81.6116 - tf_pmse_5HT: 68.3236 - tf_pmse_pH: 0.0141 - tf_pmse_NE: 96.4508 - val_loss: 1.3696 - val_tf_pmse_DA: 819.3003 - val_tf_pmse_5HT: 612.0115 - val_tf_pmse_pH: 0.1947 - val_tf_pmse_NE: 875.9479\n",
      "Epoch 22/100\n",
      "369900/369900 [==============================] - 322s 870us/step - loss: 0.0060 - tf_pmse_DA: 79.6077 - tf_pmse_5HT: 68.3382 - tf_pmse_pH: 0.0138 - tf_pmse_NE: 94.2619 - val_loss: 1.5447 - val_tf_pmse_DA: 883.0165 - val_tf_pmse_5HT: 617.0151 - val_tf_pmse_pH: 0.2107 - val_tf_pmse_NE: 894.9990\n",
      "Epoch 23/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0057 - tf_pmse_DA: 78.5817 - tf_pmse_5HT: 66.8124 - tf_pmse_pH: 0.0134 - tf_pmse_NE: 93.0650 - val_loss: 1.5648 - val_tf_pmse_DA: 1031.3197 - val_tf_pmse_5HT: 622.0685 - val_tf_pmse_pH: 0.2047 - val_tf_pmse_NE: 942.6408\n",
      "Epoch 24/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0056 - tf_pmse_DA: 77.8555 - tf_pmse_5HT: 65.7805 - tf_pmse_pH: 0.0132 - tf_pmse_NE: 92.0978 - val_loss: 1.4399 - val_tf_pmse_DA: 807.6442 - val_tf_pmse_5HT: 749.7670 - val_tf_pmse_pH: 0.2097 - val_tf_pmse_NE: 875.9971\n",
      "Epoch 25/100\n",
      "369900/369900 [==============================] - 322s 870us/step - loss: 0.0055 - tf_pmse_DA: 76.7767 - tf_pmse_5HT: 65.6853 - tf_pmse_pH: 0.0131 - tf_pmse_NE: 90.3809 - val_loss: 1.4026 - val_tf_pmse_DA: 754.6244 - val_tf_pmse_5HT: 614.2231 - val_tf_pmse_pH: 0.1990 - val_tf_pmse_NE: 862.6898\n",
      "Epoch 26/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0052 - tf_pmse_DA: 75.7282 - tf_pmse_5HT: 64.2576 - tf_pmse_pH: 0.0127 - tf_pmse_NE: 89.9354 - val_loss: 1.4312 - val_tf_pmse_DA: 868.3899 - val_tf_pmse_5HT: 607.4540 - val_tf_pmse_pH: 0.1983 - val_tf_pmse_NE: 865.2124\n",
      "Epoch 27/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0052 - tf_pmse_DA: 74.7168 - tf_pmse_5HT: 64.0927 - tf_pmse_pH: 0.0127 - tf_pmse_NE: 88.6801 - val_loss: 1.3337 - val_tf_pmse_DA: 740.2091 - val_tf_pmse_5HT: 605.2174 - val_tf_pmse_pH: 0.1936 - val_tf_pmse_NE: 835.0333\n",
      "Epoch 28/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0050 - tf_pmse_DA: 73.1989 - tf_pmse_5HT: 62.4419 - tf_pmse_pH: 0.0126 - tf_pmse_NE: 87.2035 - val_loss: 1.3960 - val_tf_pmse_DA: 771.8712 - val_tf_pmse_5HT: 614.1868 - val_tf_pmse_pH: 0.1987 - val_tf_pmse_NE: 869.9456\n",
      "Epoch 29/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0049 - tf_pmse_DA: 73.0366 - tf_pmse_5HT: 62.0551 - tf_pmse_pH: 0.0124 - tf_pmse_NE: 86.0970 - val_loss: 1.3703 - val_tf_pmse_DA: 788.0694 - val_tf_pmse_5HT: 620.3659 - val_tf_pmse_pH: 0.1991 - val_tf_pmse_NE: 872.8435\n",
      "Epoch 30/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0047 - tf_pmse_DA: 70.7549 - tf_pmse_5HT: 60.8870 - tf_pmse_pH: 0.0120 - tf_pmse_NE: 85.6451 - val_loss: 1.3403 - val_tf_pmse_DA: 771.2425 - val_tf_pmse_5HT: 609.9276 - val_tf_pmse_pH: 0.1933 - val_tf_pmse_NE: 869.9833\n",
      "Epoch 31/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0045 - tf_pmse_DA: 70.6281 - tf_pmse_5HT: 60.2193 - tf_pmse_pH: 0.0117 - tf_pmse_NE: 84.4601 - val_loss: 1.3781 - val_tf_pmse_DA: 769.5065 - val_tf_pmse_5HT: 654.1518 - val_tf_pmse_pH: 0.1994 - val_tf_pmse_NE: 880.9964\n",
      "Epoch 32/100\n",
      "369900/369900 [==============================] - 322s 872us/step - loss: 0.0044 - tf_pmse_DA: 69.2992 - tf_pmse_5HT: 59.9978 - tf_pmse_pH: 0.0117 - tf_pmse_NE: 82.9065 - val_loss: 1.3024 - val_tf_pmse_DA: 765.2101 - val_tf_pmse_5HT: 601.1430 - val_tf_pmse_pH: 0.1954 - val_tf_pmse_NE: 862.9267\n",
      "Epoch 33/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0044 - tf_pmse_DA: 69.1640 - tf_pmse_5HT: 60.2182 - tf_pmse_pH: 0.0116 - tf_pmse_NE: 82.8123 - val_loss: 1.3614 - val_tf_pmse_DA: 774.1298 - val_tf_pmse_5HT: 617.8718 - val_tf_pmse_pH: 0.1960 - val_tf_pmse_NE: 865.2598\n",
      "Epoch 34/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0044 - tf_pmse_DA: 69.1734 - tf_pmse_5HT: 59.1084 - tf_pmse_pH: 0.0115 - tf_pmse_NE: 81.7043 - val_loss: 1.3612 - val_tf_pmse_DA: 781.7529 - val_tf_pmse_5HT: 597.9789 - val_tf_pmse_pH: 0.1980 - val_tf_pmse_NE: 859.5692\n",
      "Epoch 35/100\n",
      "369900/369900 [==============================] - 322s 872us/step - loss: 0.0042 - tf_pmse_DA: 67.4364 - tf_pmse_5HT: 58.6921 - tf_pmse_pH: 0.0113 - tf_pmse_NE: 80.7810 - val_loss: 1.3727 - val_tf_pmse_DA: 757.9046 - val_tf_pmse_5HT: 611.7076 - val_tf_pmse_pH: 0.1961 - val_tf_pmse_NE: 904.8223\n",
      "Epoch 36/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0040 - tf_pmse_DA: 67.1239 - tf_pmse_5HT: 57.5315 - tf_pmse_pH: 0.0110 - tf_pmse_NE: 79.2382 - val_loss: 1.2890 - val_tf_pmse_DA: 750.4713 - val_tf_pmse_5HT: 649.6630 - val_tf_pmse_pH: 0.1941 - val_tf_pmse_NE: 837.8141\n",
      "Epoch 37/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0040 - tf_pmse_DA: 66.6122 - tf_pmse_5HT: 56.6544 - tf_pmse_pH: 0.0111 - tf_pmse_NE: 78.3432 - val_loss: 1.2990 - val_tf_pmse_DA: 781.1524 - val_tf_pmse_5HT: 661.2433 - val_tf_pmse_pH: 0.1928 - val_tf_pmse_NE: 846.3624\n",
      "Epoch 38/100\n",
      "369900/369900 [==============================] - 322s 870us/step - loss: 0.0039 - tf_pmse_DA: 65.7332 - tf_pmse_5HT: 57.1821 - tf_pmse_pH: 0.0109 - tf_pmse_NE: 77.5297 - val_loss: 1.3258 - val_tf_pmse_DA: 818.1932 - val_tf_pmse_5HT: 631.1935 - val_tf_pmse_pH: 0.1918 - val_tf_pmse_NE: 856.8915\n",
      "Epoch 39/100\n",
      "369900/369900 [==============================] - 324s 876us/step - loss: 0.0039 - tf_pmse_DA: 65.7373 - tf_pmse_5HT: 56.5179 - tf_pmse_pH: 0.0107 - tf_pmse_NE: 77.6088 - val_loss: 1.4558 - val_tf_pmse_DA: 798.2714 - val_tf_pmse_5HT: 609.5713 - val_tf_pmse_pH: 0.2066 - val_tf_pmse_NE: 896.9893\n",
      "Epoch 40/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0037 - tf_pmse_DA: 64.4024 - tf_pmse_5HT: 55.7825 - tf_pmse_pH: 0.0105 - tf_pmse_NE: 77.2717 - val_loss: 1.3373 - val_tf_pmse_DA: 827.8371 - val_tf_pmse_5HT: 641.8555 - val_tf_pmse_pH: 0.1913 - val_tf_pmse_NE: 877.4907\n",
      "Epoch 41/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0037 - tf_pmse_DA: 63.8370 - tf_pmse_5HT: 55.0270 - tf_pmse_pH: 0.0105 - tf_pmse_NE: 75.8564 - val_loss: 1.4003 - val_tf_pmse_DA: 761.0175 - val_tf_pmse_5HT: 604.2801 - val_tf_pmse_pH: 0.2023 - val_tf_pmse_NE: 859.2624\n",
      "Epoch 42/100\n",
      "369900/369900 [==============================] - 324s 877us/step - loss: 0.0035 - tf_pmse_DA: 63.0057 - tf_pmse_5HT: 54.1939 - tf_pmse_pH: 0.0102 - tf_pmse_NE: 75.2570 - val_loss: 1.2352 - val_tf_pmse_DA: 735.8373 - val_tf_pmse_5HT: 604.4770 - val_tf_pmse_pH: 0.1814 - val_tf_pmse_NE: 870.5850\n",
      "Epoch 43/100\n",
      "369900/369900 [==============================] - 325s 880us/step - loss: 0.0035 - tf_pmse_DA: 62.9144 - tf_pmse_5HT: 54.1292 - tf_pmse_pH: 0.0101 - tf_pmse_NE: 74.9128 - val_loss: 1.2791 - val_tf_pmse_DA: 792.8113 - val_tf_pmse_5HT: 618.5826 - val_tf_pmse_pH: 0.1887 - val_tf_pmse_NE: 861.1287\n",
      "Epoch 44/100\n",
      "369900/369900 [==============================] - 326s 880us/step - loss: 0.0034 - tf_pmse_DA: 62.3046 - tf_pmse_5HT: 53.8318 - tf_pmse_pH: 0.0101 - tf_pmse_NE: 73.8765 - val_loss: 1.2553 - val_tf_pmse_DA: 789.6063 - val_tf_pmse_5HT: 660.7384 - val_tf_pmse_pH: 0.1844 - val_tf_pmse_NE: 856.4095\n",
      "Epoch 45/100\n",
      "369900/369900 [==============================] - 324s 876us/step - loss: 0.0034 - tf_pmse_DA: 61.8020 - tf_pmse_5HT: 53.5020 - tf_pmse_pH: 0.0100 - tf_pmse_NE: 73.7209 - val_loss: 1.3226 - val_tf_pmse_DA: 797.5944 - val_tf_pmse_5HT: 609.1129 - val_tf_pmse_pH: 0.1917 - val_tf_pmse_NE: 861.4326\n",
      "Epoch 46/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0033 - tf_pmse_DA: 62.2448 - tf_pmse_5HT: 53.1808 - tf_pmse_pH: 0.0098 - tf_pmse_NE: 73.7385 - val_loss: 1.3585 - val_tf_pmse_DA: 807.4105 - val_tf_pmse_5HT: 629.0007 - val_tf_pmse_pH: 0.1947 - val_tf_pmse_NE: 869.5365\n",
      "Epoch 47/100\n",
      "369900/369900 [==============================] - 322s 872us/step - loss: 0.0033 - tf_pmse_DA: 61.7276 - tf_pmse_5HT: 52.7573 - tf_pmse_pH: 0.0099 - tf_pmse_NE: 72.7820 - val_loss: 1.3908 - val_tf_pmse_DA: 777.7795 - val_tf_pmse_5HT: 607.6235 - val_tf_pmse_pH: 0.2029 - val_tf_pmse_NE: 860.4365\n",
      "Epoch 48/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0032 - tf_pmse_DA: 60.9299 - tf_pmse_5HT: 52.5821 - tf_pmse_pH: 0.0097 - tf_pmse_NE: 71.8322 - val_loss: 1.4053 - val_tf_pmse_DA: 854.5391 - val_tf_pmse_5HT: 638.0877 - val_tf_pmse_pH: 0.2004 - val_tf_pmse_NE: 884.3910\n",
      "Epoch 49/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0032 - tf_pmse_DA: 59.3938 - tf_pmse_5HT: 52.4996 - tf_pmse_pH: 0.0096 - tf_pmse_NE: 70.8808 - val_loss: 1.3165 - val_tf_pmse_DA: 781.9684 - val_tf_pmse_5HT: 603.4450 - val_tf_pmse_pH: 0.1940 - val_tf_pmse_NE: 872.5940\n",
      "Epoch 50/100\n",
      "369900/369900 [==============================] - 322s 872us/step - loss: 0.0031 - tf_pmse_DA: 59.4921 - tf_pmse_5HT: 51.7103 - tf_pmse_pH: 0.0095 - tf_pmse_NE: 70.7427 - val_loss: 1.2991 - val_tf_pmse_DA: 767.1748 - val_tf_pmse_5HT: 632.8322 - val_tf_pmse_pH: 0.1952 - val_tf_pmse_NE: 853.6526\n",
      "Epoch 51/100\n",
      "369900/369900 [==============================] - 322s 870us/step - loss: 0.0031 - tf_pmse_DA: 59.0917 - tf_pmse_5HT: 51.6939 - tf_pmse_pH: 0.0095 - tf_pmse_NE: 70.9458 - val_loss: 1.2395 - val_tf_pmse_DA: 788.5277 - val_tf_pmse_5HT: 609.0637 - val_tf_pmse_pH: 0.1863 - val_tf_pmse_NE: 855.0919\n",
      "Epoch 52/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0030 - tf_pmse_DA: 58.1780 - tf_pmse_5HT: 50.3773 - tf_pmse_pH: 0.0092 - tf_pmse_NE: 70.0368 - val_loss: 1.3222 - val_tf_pmse_DA: 746.8762 - val_tf_pmse_5HT: 633.4947 - val_tf_pmse_pH: 0.1982 - val_tf_pmse_NE: 863.6793\n",
      "Epoch 53/100\n",
      "369900/369900 [==============================] - 325s 878us/step - loss: 0.0030 - tf_pmse_DA: 58.6753 - tf_pmse_5HT: 50.6209 - tf_pmse_pH: 0.0092 - tf_pmse_NE: 69.3459 - val_loss: 1.2591 - val_tf_pmse_DA: 770.2798 - val_tf_pmse_5HT: 640.2190 - val_tf_pmse_pH: 0.1884 - val_tf_pmse_NE: 846.7944\n",
      "Epoch 54/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0029 - tf_pmse_DA: 58.2385 - tf_pmse_5HT: 50.5326 - tf_pmse_pH: 0.0091 - tf_pmse_NE: 68.7012 - val_loss: 1.2461 - val_tf_pmse_DA: 829.7557 - val_tf_pmse_5HT: 606.9213 - val_tf_pmse_pH: 0.1822 - val_tf_pmse_NE: 857.8579\n",
      "Epoch 55/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0029 - tf_pmse_DA: 57.5917 - tf_pmse_5HT: 49.9765 - tf_pmse_pH: 0.0091 - tf_pmse_NE: 68.5685 - val_loss: 1.2938 - val_tf_pmse_DA: 794.2836 - val_tf_pmse_5HT: 609.8352 - val_tf_pmse_pH: 0.1887 - val_tf_pmse_NE: 864.9956\n",
      "Epoch 56/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0028 - tf_pmse_DA: 57.5190 - tf_pmse_5HT: 49.8519 - tf_pmse_pH: 0.0090 - tf_pmse_NE: 67.9427 - val_loss: 1.2112 - val_tf_pmse_DA: 756.9025 - val_tf_pmse_5HT: 634.4427 - val_tf_pmse_pH: 0.1823 - val_tf_pmse_NE: 838.9918\n",
      "Epoch 57/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0028 - tf_pmse_DA: 56.6854 - tf_pmse_5HT: 49.8636 - tf_pmse_pH: 0.0089 - tf_pmse_NE: 68.0373 - val_loss: 1.3122 - val_tf_pmse_DA: 803.1379 - val_tf_pmse_5HT: 624.3336 - val_tf_pmse_pH: 0.1906 - val_tf_pmse_NE: 856.8041\n",
      "Epoch 58/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0028 - tf_pmse_DA: 57.2473 - tf_pmse_5HT: 48.7444 - tf_pmse_pH: 0.0088 - tf_pmse_NE: 67.4446 - val_loss: 1.2538 - val_tf_pmse_DA: 847.9904 - val_tf_pmse_5HT: 615.8898 - val_tf_pmse_pH: 0.1788 - val_tf_pmse_NE: 881.6845\n",
      "Epoch 59/100\n",
      "369900/369900 [==============================] - 325s 879us/step - loss: 0.0027 - tf_pmse_DA: 56.0602 - tf_pmse_5HT: 49.3166 - tf_pmse_pH: 0.0088 - tf_pmse_NE: 66.7887 - val_loss: 1.3162 - val_tf_pmse_DA: 816.0187 - val_tf_pmse_5HT: 648.2582 - val_tf_pmse_pH: 0.1915 - val_tf_pmse_NE: 866.4742\n",
      "Epoch 60/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0027 - tf_pmse_DA: 56.0338 - tf_pmse_5HT: 48.9258 - tf_pmse_pH: 0.0087 - tf_pmse_NE: 65.5273 - val_loss: 1.4736 - val_tf_pmse_DA: 814.2694 - val_tf_pmse_5HT: 660.1129 - val_tf_pmse_pH: 0.2075 - val_tf_pmse_NE: 871.4918\n",
      "Epoch 61/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0027 - tf_pmse_DA: 56.0066 - tf_pmse_5HT: 48.2514 - tf_pmse_pH: 0.0086 - tf_pmse_NE: 66.2559 - val_loss: 1.2336 - val_tf_pmse_DA: 771.4984 - val_tf_pmse_5HT: 622.1778 - val_tf_pmse_pH: 0.1824 - val_tf_pmse_NE: 859.2058\n",
      "Epoch 62/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0026 - tf_pmse_DA: 55.1386 - tf_pmse_5HT: 48.1782 - tf_pmse_pH: 0.0086 - tf_pmse_NE: 65.7266 - val_loss: 1.2719 - val_tf_pmse_DA: 805.6755 - val_tf_pmse_5HT: 614.3715 - val_tf_pmse_pH: 0.1857 - val_tf_pmse_NE: 858.1152\n",
      "Epoch 63/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0025 - tf_pmse_DA: 54.5068 - tf_pmse_5HT: 47.6154 - tf_pmse_pH: 0.0084 - tf_pmse_NE: 65.0099 - val_loss: 1.3423 - val_tf_pmse_DA: 797.3979 - val_tf_pmse_5HT: 600.1902 - val_tf_pmse_pH: 0.1935 - val_tf_pmse_NE: 870.1804\n",
      "Epoch 64/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0025 - tf_pmse_DA: 54.9753 - tf_pmse_5HT: 47.6568 - tf_pmse_pH: 0.0084 - tf_pmse_NE: 64.8544 - val_loss: 1.3400 - val_tf_pmse_DA: 776.1773 - val_tf_pmse_5HT: 621.0704 - val_tf_pmse_pH: 0.1983 - val_tf_pmse_NE: 852.6681\n",
      "Epoch 65/100\n",
      "369900/369900 [==============================] - 328s 886us/step - loss: 0.0026 - tf_pmse_DA: 54.5684 - tf_pmse_5HT: 47.3539 - tf_pmse_pH: 0.0085 - tf_pmse_NE: 64.4471 - val_loss: 1.3090 - val_tf_pmse_DA: 817.1237 - val_tf_pmse_5HT: 625.3543 - val_tf_pmse_pH: 0.1924 - val_tf_pmse_NE: 853.2102\n",
      "Epoch 66/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0025 - tf_pmse_DA: 53.8786 - tf_pmse_5HT: 47.3102 - tf_pmse_pH: 0.0084 - tf_pmse_NE: 64.3620 - val_loss: 1.2761 - val_tf_pmse_DA: 786.8018 - val_tf_pmse_5HT: 606.1946 - val_tf_pmse_pH: 0.1883 - val_tf_pmse_NE: 865.9521\n",
      "Epoch 67/100\n",
      "369900/369900 [==============================] - 326s 882us/step - loss: 0.0024 - tf_pmse_DA: 53.3082 - tf_pmse_5HT: 47.2233 - tf_pmse_pH: 0.0083 - tf_pmse_NE: 63.3450 - val_loss: 1.2743 - val_tf_pmse_DA: 818.1774 - val_tf_pmse_5HT: 637.4025 - val_tf_pmse_pH: 0.1878 - val_tf_pmse_NE: 858.8430\n",
      "Epoch 68/100\n",
      "369900/369900 [==============================] - 326s 880us/step - loss: 0.0024 - tf_pmse_DA: 53.9200 - tf_pmse_5HT: 46.3499 - tf_pmse_pH: 0.0082 - tf_pmse_NE: 63.2024 - val_loss: 1.2481 - val_tf_pmse_DA: 785.7686 - val_tf_pmse_5HT: 607.8903 - val_tf_pmse_pH: 0.1858 - val_tf_pmse_NE: 856.2959\n",
      "Epoch 69/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0024 - tf_pmse_DA: 53.2149 - tf_pmse_5HT: 46.3824 - tf_pmse_pH: 0.0082 - tf_pmse_NE: 62.9477 - val_loss: 1.3008 - val_tf_pmse_DA: 887.0174 - val_tf_pmse_5HT: 630.9259 - val_tf_pmse_pH: 0.1836 - val_tf_pmse_NE: 874.9494\n",
      "Epoch 70/100\n",
      "369900/369900 [==============================] - 326s 882us/step - loss: 0.0024 - tf_pmse_DA: 53.2497 - tf_pmse_5HT: 45.9231 - tf_pmse_pH: 0.0081 - tf_pmse_NE: 62.6582 - val_loss: 1.3781 - val_tf_pmse_DA: 818.7591 - val_tf_pmse_5HT: 643.7957 - val_tf_pmse_pH: 0.2003 - val_tf_pmse_NE: 856.3445\n",
      "Epoch 71/100\n",
      "369900/369900 [==============================] - 325s 880us/step - loss: 0.0024 - tf_pmse_DA: 52.8481 - tf_pmse_5HT: 45.6885 - tf_pmse_pH: 0.0081 - tf_pmse_NE: 62.5106 - val_loss: 1.3526 - val_tf_pmse_DA: 807.6877 - val_tf_pmse_5HT: 639.4807 - val_tf_pmse_pH: 0.1987 - val_tf_pmse_NE: 849.9659\n",
      "Epoch 72/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0023 - tf_pmse_DA: 52.7990 - tf_pmse_5HT: 45.6838 - tf_pmse_pH: 0.0080 - tf_pmse_NE: 62.3800 - val_loss: 1.3044 - val_tf_pmse_DA: 834.8901 - val_tf_pmse_5HT: 614.2432 - val_tf_pmse_pH: 0.1860 - val_tf_pmse_NE: 889.3006\n",
      "Epoch 73/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0023 - tf_pmse_DA: 52.3767 - tf_pmse_5HT: 45.1236 - tf_pmse_pH: 0.0079 - tf_pmse_NE: 61.6326 - val_loss: 1.1887 - val_tf_pmse_DA: 808.6383 - val_tf_pmse_5HT: 608.2735 - val_tf_pmse_pH: 0.1775 - val_tf_pmse_NE: 846.6753\n",
      "Epoch 74/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0023 - tf_pmse_DA: 52.0918 - tf_pmse_5HT: 44.9822 - tf_pmse_pH: 0.0079 - tf_pmse_NE: 61.6702 - val_loss: 1.3119 - val_tf_pmse_DA: 872.4928 - val_tf_pmse_5HT: 655.4343 - val_tf_pmse_pH: 0.1854 - val_tf_pmse_NE: 891.6078\n",
      "Epoch 75/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0022 - tf_pmse_DA: 52.3527 - tf_pmse_5HT: 44.7181 - tf_pmse_pH: 0.0079 - tf_pmse_NE: 60.9918 - val_loss: 1.2546 - val_tf_pmse_DA: 808.2229 - val_tf_pmse_5HT: 646.9735 - val_tf_pmse_pH: 0.1815 - val_tf_pmse_NE: 863.3541\n",
      "Epoch 76/100\n",
      "369900/369900 [==============================] - 326s 880us/step - loss: 0.0022 - tf_pmse_DA: 51.3797 - tf_pmse_5HT: 45.2681 - tf_pmse_pH: 0.0078 - tf_pmse_NE: 60.7530 - val_loss: 1.2089 - val_tf_pmse_DA: 799.3678 - val_tf_pmse_5HT: 653.6422 - val_tf_pmse_pH: 0.1794 - val_tf_pmse_NE: 850.6018\n",
      "Epoch 77/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0022 - tf_pmse_DA: 51.5505 - tf_pmse_5HT: 44.6386 - tf_pmse_pH: 0.0077 - tf_pmse_NE: 60.2695 - val_loss: 1.3160 - val_tf_pmse_DA: 834.1480 - val_tf_pmse_5HT: 608.3249 - val_tf_pmse_pH: 0.1899 - val_tf_pmse_NE: 859.3279\n",
      "Epoch 78/100\n",
      "369900/369900 [==============================] - 326s 881us/step - loss: 0.0022 - tf_pmse_DA: 51.2716 - tf_pmse_5HT: 44.3324 - tf_pmse_pH: 0.0078 - tf_pmse_NE: 60.3576 - val_loss: 1.2050 - val_tf_pmse_DA: 806.7504 - val_tf_pmse_5HT: 663.2420 - val_tf_pmse_pH: 0.1772 - val_tf_pmse_NE: 858.6832\n",
      "Epoch 79/100\n",
      "369900/369900 [==============================] - 327s 883us/step - loss: 0.0022 - tf_pmse_DA: 51.1666 - tf_pmse_5HT: 44.4857 - tf_pmse_pH: 0.0077 - tf_pmse_NE: 59.8429 - val_loss: 1.2585 - val_tf_pmse_DA: 802.0411 - val_tf_pmse_5HT: 622.3374 - val_tf_pmse_pH: 0.1855 - val_tf_pmse_NE: 862.3451\n",
      "Epoch 80/100\n",
      "369900/369900 [==============================] - 326s 882us/step - loss: 0.0022 - tf_pmse_DA: 51.2989 - tf_pmse_5HT: 43.9080 - tf_pmse_pH: 0.0077 - tf_pmse_NE: 59.6215 - val_loss: 1.1650 - val_tf_pmse_DA: 756.1986 - val_tf_pmse_5HT: 629.4549 - val_tf_pmse_pH: 0.1745 - val_tf_pmse_NE: 850.4369\n",
      "Epoch 81/100\n",
      "369900/369900 [==============================] - 325s 880us/step - loss: 0.0021 - tf_pmse_DA: 50.2352 - tf_pmse_5HT: 44.0739 - tf_pmse_pH: 0.0077 - tf_pmse_NE: 59.1615 - val_loss: 1.2621 - val_tf_pmse_DA: 799.8955 - val_tf_pmse_5HT: 629.4689 - val_tf_pmse_pH: 0.1862 - val_tf_pmse_NE: 859.5826\n",
      "Epoch 82/100\n",
      "369900/369900 [==============================] - 325s 880us/step - loss: 0.0021 - tf_pmse_DA: 50.4092 - tf_pmse_5HT: 43.8523 - tf_pmse_pH: 0.0075 - tf_pmse_NE: 59.3623 - val_loss: 1.2604 - val_tf_pmse_DA: 815.5567 - val_tf_pmse_5HT: 608.6820 - val_tf_pmse_pH: 0.1834 - val_tf_pmse_NE: 872.3663\n",
      "Epoch 83/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0021 - tf_pmse_DA: 50.0073 - tf_pmse_5HT: 43.7154 - tf_pmse_pH: 0.0075 - tf_pmse_NE: 59.2996 - val_loss: 1.2237 - val_tf_pmse_DA: 760.6840 - val_tf_pmse_5HT: 624.8590 - val_tf_pmse_pH: 0.1843 - val_tf_pmse_NE: 845.8744\n",
      "Epoch 84/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0021 - tf_pmse_DA: 49.5990 - tf_pmse_5HT: 43.2733 - tf_pmse_pH: 0.0075 - tf_pmse_NE: 58.8849 - val_loss: 1.2434 - val_tf_pmse_DA: 776.3786 - val_tf_pmse_5HT: 607.1239 - val_tf_pmse_pH: 0.1864 - val_tf_pmse_NE: 848.4867\n",
      "Epoch 85/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0020 - tf_pmse_DA: 49.1669 - tf_pmse_5HT: 43.5991 - tf_pmse_pH: 0.0075 - tf_pmse_NE: 58.5334 - val_loss: 1.2092 - val_tf_pmse_DA: 778.9261 - val_tf_pmse_5HT: 621.6347 - val_tf_pmse_pH: 0.1790 - val_tf_pmse_NE: 857.8477\n",
      "Epoch 86/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0020 - tf_pmse_DA: 49.0461 - tf_pmse_5HT: 42.9976 - tf_pmse_pH: 0.0074 - tf_pmse_NE: 58.2785 - val_loss: 1.2892 - val_tf_pmse_DA: 771.0718 - val_tf_pmse_5HT: 617.2551 - val_tf_pmse_pH: 0.1913 - val_tf_pmse_NE: 842.6849\n",
      "Epoch 87/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0020 - tf_pmse_DA: 49.0639 - tf_pmse_5HT: 43.2132 - tf_pmse_pH: 0.0075 - tf_pmse_NE: 58.0112 - val_loss: 1.2673 - val_tf_pmse_DA: 758.8494 - val_tf_pmse_5HT: 620.4981 - val_tf_pmse_pH: 0.1872 - val_tf_pmse_NE: 871.3770\n",
      "Epoch 88/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0020 - tf_pmse_DA: 49.0951 - tf_pmse_5HT: 43.0162 - tf_pmse_pH: 0.0074 - tf_pmse_NE: 58.1077 - val_loss: 1.1982 - val_tf_pmse_DA: 804.5680 - val_tf_pmse_5HT: 621.3721 - val_tf_pmse_pH: 0.1776 - val_tf_pmse_NE: 853.5294\n",
      "Epoch 89/100\n",
      "369900/369900 [==============================] - 322s 871us/step - loss: 0.0020 - tf_pmse_DA: 48.7836 - tf_pmse_5HT: 42.4348 - tf_pmse_pH: 0.0073 - tf_pmse_NE: 57.5033 - val_loss: 1.2212 - val_tf_pmse_DA: 808.5168 - val_tf_pmse_5HT: 651.0667 - val_tf_pmse_pH: 0.1819 - val_tf_pmse_NE: 834.4794\n",
      "Epoch 90/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0020 - tf_pmse_DA: 48.5540 - tf_pmse_5HT: 42.5335 - tf_pmse_pH: 0.0074 - tf_pmse_NE: 57.3460 - val_loss: 1.2208 - val_tf_pmse_DA: 763.6516 - val_tf_pmse_5HT: 657.8372 - val_tf_pmse_pH: 0.1842 - val_tf_pmse_NE: 839.6377\n",
      "Epoch 91/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0019 - tf_pmse_DA: 48.5824 - tf_pmse_5HT: 41.8317 - tf_pmse_pH: 0.0073 - tf_pmse_NE: 56.8174 - val_loss: 1.2077 - val_tf_pmse_DA: 811.2071 - val_tf_pmse_5HT: 638.1904 - val_tf_pmse_pH: 0.1789 - val_tf_pmse_NE: 857.9321\n",
      "Epoch 92/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0019 - tf_pmse_DA: 48.4519 - tf_pmse_5HT: 41.6888 - tf_pmse_pH: 0.0072 - tf_pmse_NE: 57.2785 - val_loss: 1.2653 - val_tf_pmse_DA: 793.6651 - val_tf_pmse_5HT: 613.7545 - val_tf_pmse_pH: 0.1850 - val_tf_pmse_NE: 870.2490\n",
      "Epoch 93/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0019 - tf_pmse_DA: 48.1867 - tf_pmse_5HT: 41.9459 - tf_pmse_pH: 0.0072 - tf_pmse_NE: 56.7900 - val_loss: 1.2759 - val_tf_pmse_DA: 795.4787 - val_tf_pmse_5HT: 638.8995 - val_tf_pmse_pH: 0.1864 - val_tf_pmse_NE: 855.8191\n",
      "Epoch 94/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0019 - tf_pmse_DA: 48.4123 - tf_pmse_5HT: 41.9128 - tf_pmse_pH: 0.0071 - tf_pmse_NE: 56.9292 - val_loss: 1.1801 - val_tf_pmse_DA: 812.2851 - val_tf_pmse_5HT: 649.7690 - val_tf_pmse_pH: 0.1762 - val_tf_pmse_NE: 856.8010\n",
      "Epoch 95/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0019 - tf_pmse_DA: 47.4865 - tf_pmse_5HT: 41.2890 - tf_pmse_pH: 0.0071 - tf_pmse_NE: 56.1268 - val_loss: 1.2138 - val_tf_pmse_DA: 786.1161 - val_tf_pmse_5HT: 658.9626 - val_tf_pmse_pH: 0.1785 - val_tf_pmse_NE: 859.7958\n",
      "Epoch 96/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0019 - tf_pmse_DA: 47.7013 - tf_pmse_5HT: 41.3631 - tf_pmse_pH: 0.0071 - tf_pmse_NE: 55.5839 - val_loss: 1.2871 - val_tf_pmse_DA: 786.5667 - val_tf_pmse_5HT: 653.9102 - val_tf_pmse_pH: 0.1878 - val_tf_pmse_NE: 858.3916\n",
      "Epoch 97/100\n",
      "369900/369900 [==============================] - 323s 873us/step - loss: 0.0018 - tf_pmse_DA: 46.9993 - tf_pmse_5HT: 41.3429 - tf_pmse_pH: 0.0070 - tf_pmse_NE: 55.7959 - val_loss: 1.2668 - val_tf_pmse_DA: 753.8596 - val_tf_pmse_5HT: 609.0463 - val_tf_pmse_pH: 0.1863 - val_tf_pmse_NE: 869.8977\n",
      "Epoch 98/100\n",
      "369900/369900 [==============================] - 324s 875us/step - loss: 0.0018 - tf_pmse_DA: 47.0485 - tf_pmse_5HT: 41.2799 - tf_pmse_pH: 0.0070 - tf_pmse_NE: 55.7640 - val_loss: 1.2357 - val_tf_pmse_DA: 771.1546 - val_tf_pmse_5HT: 646.5693 - val_tf_pmse_pH: 0.1805 - val_tf_pmse_NE: 869.8647\n",
      "Epoch 99/100\n",
      "369900/369900 [==============================] - 323s 872us/step - loss: 0.0018 - tf_pmse_DA: 47.3667 - tf_pmse_5HT: 41.6965 - tf_pmse_pH: 0.0070 - tf_pmse_NE: 55.7177 - val_loss: 1.2395 - val_tf_pmse_DA: 793.2001 - val_tf_pmse_5HT: 644.8479 - val_tf_pmse_pH: 0.1810 - val_tf_pmse_NE: 863.8570\n",
      "Epoch 100/100\n",
      "369900/369900 [==============================] - 323s 874us/step - loss: 0.0018 - tf_pmse_DA: 47.4932 - tf_pmse_5HT: 40.8311 - tf_pmse_pH: 0.0070 - tf_pmse_NE: 55.0215 - val_loss: 1.2367 - val_tf_pmse_DA: 732.7946 - val_tf_pmse_5HT: 625.0711 - val_tf_pmse_pH: 0.1857 - val_tf_pmse_NE: 848.2422\n",
      "predicting validation set... done.\n",
      "using val_loss to find best metrics\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n",
      "original backend module://ipympl.backend_nbagg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>949.028118</td>\n",
       "      <td>841.281954</td>\n",
       "      <td>0.230345</td>\n",
       "      <td>1212.151813</td>\n",
       "      <td>32391.831578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit inception time the model\n",
    "\n",
    "if best_model is None:\n",
    "    print('Fitting new model...')\n",
    "    metrics = classifier.fit(x_train, y_train, x_val, y_val, plot_test_acc=True)\n",
    "    best_model = classifier.get_best_model()\n",
    "else:\n",
    "    print('Model alread fit, computing prediction of validation data')\n",
    "    metrics = classifier.predict(x_val, y_val, x_train, y_train, return_df_metrics=True)\n",
    "\n",
    "display(HTML(metrics.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold CF082, validation CF025, all data, 100 epochs\n",
    "# Epoch 1/100\n",
    "# 369900/369900 [==============================] - 332s 897us/step - loss: 0.3839 - tf_pmse_DA: 488.6883 - tf_pmse_5HT: 418.8771 - tf_pmse_pH: 0.0728 - tf_pmse_NE: 545.8939 - val_loss: 0.9853 - val_tf_pmse_DA: 879.1813 - val_tf_pmse_5HT: 389.8340 - val_tf_pmse_pH: 0.1891 - val_tf_pmse_NE: 1166.5785\n",
    "# Epoch 10/100\n",
    "# 369900/369900 [==============================] - 324s 875us/step - loss: 0.0139 - tf_pmse_DA: 132.5645 - tf_pmse_5HT: 111.5507 - tf_pmse_pH: 0.0200 - tf_pmse_NE: 139.9987 - val_loss: 0.1967 - val_tf_pmse_DA: 340.3430 - val_tf_pmse_5HT: 337.9328 - val_tf_pmse_pH: 0.0613 - val_tf_pmse_NE: 453.8609\n",
    "# Epoch 97/100\n",
    "# 369900/369900 [==============================] - 323s 872us/step - loss: 0.0021 - tf_pmse_DA: 50.4458 - tf_pmse_5HT: 46.5694 - tf_pmse_pH: 0.0077 - tf_pmse_NE: 54.5813 - val_loss: 0.1685 - val_tf_pmse_DA: 356.7854 - val_tf_pmse_5HT: 305.9508 - val_tf_pmse_pH: 0.0534 - val_tf_pmse_NE: 400.9060\n",
    "# Epoch 100/100\n",
    "# 369900/369900 [==============================] - 322s 871us/step - loss: 0.0020 - tf_pmse_DA: 49.6475 - tf_pmse_5HT: 46.6628 - tf_pmse_pH: 0.0076 - tf_pmse_NE: 53.9088 - val_loss: 0.2012 - val_tf_pmse_DA: 375.4945 - val_tf_pmse_5HT: 356.6755 - val_tf_pmse_pH: 0.0558 - val_tf_pmse_NE: 441.8727\n",
    "# predicting validation set... \n",
    "# \trmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 0 \t483.575696 \t504.289784 \t0.072682 \t604.31947 \t32320.917521\n",
    "# Epoch 70/100\n",
    "# 369900/369900 [==============================] - 321s 868us/step - loss: 0.0026 - tf_pmse_DA: 55.4761 - tf_pmse_5HT: 51.8563 - tf_pmse_pH: 0.0084 - tf_pmse_NE: 63.0837 - val_loss: 0.2494 - val_tf_pmse_DA: 403.2530 - val_tf_pmse_5HT: 277.9370 - val_tf_pmse_pH: 0.0658 - val_tf_pmse_NE: 549.2294\n",
    "# Epoch 100/100\n",
    "# 369900/369900 [==============================] - 321s 868us/step - loss: 0.0019 - tf_pmse_DA: 49.0351 - tf_pmse_5HT: 46.0001 - tf_pmse_pH: 0.0072 - tf_pmse_NE: 55.4475 - val_loss: 0.2707 - val_tf_pmse_DA: 410.6053 - val_tf_pmse_5HT: 278.3472 - val_tf_pmse_pH: 0.0673 - val_tf_pmse_NE: 557.2681\n",
    "# rmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 0 \t466.478029 \t344.97594 \t0.094177 \t716.697981 \t32189.755459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239.411615</td>\n",
       "      <td>105.820226</td>\n",
       "      <td>0.051913</td>\n",
       "      <td>240.430734</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = classifier.predict(x_test, y_test, x_train, y_train, return_df_metrics=True)\n",
    "display(HTML(metrics.to_html()))\n",
    "\n",
    "# Hold CF082, validation CF025, all data, 100 epochs\n",
    "# rmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 289.592247 \t148.701677 \t0.082032 \t416.473678 \t0.0\n",
    "# rmse_DA \trmse_5HT \trmse_pH \trmse_NE \tduration\n",
    "# 0 \t259.638304 \t150.975943 \t0.082163 \t304.965429 \t0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/CF078/last_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209.422598</td>\n",
       "      <td>123.683341</td>\n",
       "      <td>0.044416</td>\n",
       "      <td>232.114421</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# model_path = os.path.join(classifier.output_directory, 'best_model.hdf5')\n",
    "model_path = os.path.join(classifier.output_directory, 'last_model.hdf5')\n",
    "# model_path = os.path.join(classifier.output_directory, 'model_init.hdf5')\n",
    "\n",
    "print(model_path)\n",
    "\n",
    "model = keras.models.load_model(model_path, custom_objects={\"tf_pmse_DA\": tf_pmse_DA, \"tf_pmse_5HT\": tf_pmse_5HT, \"tf_pmse_pH\": tf_pmse_pH, \"tf_pmse_NE\": tf_pmse_NE})\n",
    "\n",
    "xt, yt = x_test, y_test\n",
    "# xt, yt = x_val, y_val\n",
    "\n",
    "yp = model.predict(xt, batch_size=64)\n",
    "\n",
    "yp = np.apply_along_axis(revert_data, axis=1, arr=yp) \n",
    "yt = np.apply_along_axis(revert_data, axis=1, arr=yt) \n",
    "\n",
    "rmse4 = rmse(yt, yp)\n",
    "\n",
    "metrics2 = pd.DataFrame(data=np.zeros((1, 5), dtype=np.float), index=[0], columns=['rmse_DA', 'rmse_5HT', 'rmse_pH', 'rmse_NE', 'duration'])\n",
    "metrics2['rmse_DA'] = rmse4[0]\n",
    "metrics2['rmse_5HT'] = rmse4[1]\n",
    "metrics2['rmse_pH'] = rmse4[2]\n",
    "metrics2['rmse_NE'] = rmse4[3]\n",
    "metrics2['duration'] = 0.0\n",
    "        \n",
    "display(HTML(metrics2.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e90f8f8e9c24766b14ceee45becaf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def plot_concentrations(y):\n",
    "#     fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True)\n",
    "#     for ip in range(0,4):\n",
    "#         axs[np.unravel_index(ip, axs.shape)].hist(y[:,ip])\n",
    "# plot_concentrations(y_test)\n",
    "# plot_concentrations(y_pred)\n",
    "\n",
    "def plot_compare_test_pred(yt, yp):\n",
    "    fig, axs = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "    for ip in range(0,8):\n",
    "        axsidx = np.unravel_index(ip, axs.shape)\n",
    "        if ip < 4:\n",
    "            axs[axsidx].hist(yt[:,ip])\n",
    "        else:\n",
    "            axs[axsidx].hist(yp[:,ip-4])\n",
    "\n",
    "plot_compare_test_pred(yt, yp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233.358811</td>\n",
       "      <td>105.901987</td>\n",
       "      <td>0.051871</td>\n",
       "      <td>231.041324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 999, 128)\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "\n",
    "idxs = np.random.permutation(x_val.shape[0])\n",
    "# x_cam = x_val[idxs[:1000],:,:]\n",
    "# y_cam = y_val[idxs[:1000], :]\n",
    "\n",
    "x_cam = x_test[idxs[:1000],:,:]\n",
    "y_cam = y_test[idxs[:1000], :]\n",
    "\n",
    "w_k_c = model.layers[-1].get_weights()[0] # weights for each filter k for each class c \n",
    "\n",
    "new_input_layer = model.inputs # same input of the original model\n",
    "\n",
    "new_outpu_layer = [model.get_layer(\"conv1d_31\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "# new_outpu_layer = [model.get_layer(\"activation_8\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "\n",
    "new_function = keras.backend.function(new_input_layer,new_outpu_layer)\n",
    "\n",
    "new_feed_forward = new_function\n",
    "\n",
    "[conv_out, y_pred] = new_feed_forward((x_cam,))\n",
    "\n",
    "metrics = classifier._calculate_metrics(y_cam, y_pred, 0.0)\n",
    "display(HTML(metrics.to_html()))\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n",
      "(1000, 999, 128)\n",
      "(1000, 999, 1)\n"
     ]
    }
   ],
   "source": [
    "print(w_k_c.shape)\n",
    "print(conv_out.shape)\n",
    "print(x_cam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data = []\n",
    "# for isample in range(conv_out.shape[0]):\n",
    "#     conv_out_i = conv_out[isample,:,:]\n",
    "#     one_plot_data = []\n",
    "#     for j in range(y_val.shape[1]):\n",
    "\n",
    "#         axsidx = np.unravel_index(j, axs.shape)\n",
    "\n",
    "#         cas = np.zeros(dtype=np.float, shape = (conv_out.shape[1]))\n",
    "#         for k,w in enumerate(w_k_c[:,j]):\n",
    "#             cas += w * conv_out_i[:,k]\n",
    "#         minimum = np.min(cas)\n",
    "#         cas = cas - minimum\n",
    "#         cas = cas/max(cas)\n",
    "#         cas = cas * 100\n",
    "#         cas = cas.astype(int)\n",
    "\n",
    "#     #     axs[axsidx].plot(cas)\n",
    "\n",
    "#         one_plot_data.append( (np.squeeze(x_cam[isample,:,:]), np.array(range(y.shape[0])), cas) )\n",
    "#     plot_data.append(one_plot_data)\n",
    "\n",
    "# import ipywidgets as widgets\n",
    "# from matplotlib.collections import LineCollection\n",
    "# from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# plt.ioff()\n",
    "# fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "# plt.ion()\n",
    "\n",
    "# def show_image(one_plot_data):\n",
    "#     for j in range(y_val.shape[1]):\n",
    "\n",
    "#         axsidx = np.unravel_index(j, axs.shape)\n",
    "# #         axs[axsidx].clear()\n",
    "\n",
    "#         y = one_plot_data[j][0]\n",
    "#         x = one_plot_data[j][1]\n",
    "#         dydx = one_plot_data[j][2]\n",
    "\n",
    "#         # def plot_line_multicolor(x, y, dydx):\n",
    "#         # Create a set of line segments so that we can color them individually\n",
    "#         # This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "#         # together easily to get the segments. The segments array for line collection\n",
    "#         # needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "#         points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "#         segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "#         # Create a continuous norm to map from data points to colors\n",
    "#         norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "#         lc = LineCollection(segments, cmap='jet', norm=norm)\n",
    "#         # Set the values used for colormapping\n",
    "#         lc.set_array(dydx)\n",
    "#         lc.set_linewidth(4)\n",
    "#         line = axs[axsidx].add_collection(lc)\n",
    "# #         fig.colorbar(line, ax=axs[axsidx])\n",
    "        \n",
    "#         axs[axsidx].set_xlim(x.min(), x.max())\n",
    "#         axs[axsidx].set_ylim(y.min(), y.max())\n",
    "#         axs[axsidx].set_title(names[j])\n",
    "\n",
    "# show_image(plot_data[0])\n",
    "\n",
    "\n",
    "\n",
    "# def update(change):\n",
    "#     idx = change['new']\n",
    "#     show_image(plot_data[idx])\n",
    "#     fig.canvas.draw_idle()\n",
    "    \n",
    "# slider = widgets.IntSlider(value=0, min=0, max=conv_out.shape[0]-1)\n",
    "# slider.observe(update, names='value')\n",
    "# widgets.VBox([slider, fig.canvas])\n",
    "\n",
    "# # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1657c2c81a49c6b332d2c94bc4252b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# print(\"original_label: \"+str(encoder.inverse_transform(np.argmax(original_binary_class))))\n",
    "# print(\"original_shape: \"+str(time_series_original.shape))\n",
    "# print(\"predicted_label:\"+str(encoder.inverse_transform(np.argmax(predicted))))\n",
    "# print(\"predicted_shape:\"+str(conv_out.shape))\n",
    "\n",
    "# print(w_k_c.shape)\n",
    "# print(conv_out.shape)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "\n",
    "ix = np.random.randint(0,conv_out.shape[0]-1)\n",
    "conv_out_0 = conv_out[ix,:,:]\n",
    "# conv_out_avg = np.squeeze(np.mean(conv_out, axis=0))\n",
    "\n",
    "for j in range(y_val.shape[1]):\n",
    "\n",
    "    axsidx = np.unravel_index(j, axs.shape)\n",
    "\n",
    "    cas = np.zeros(dtype=np.float, shape = (conv_out.shape[1]))\n",
    "    for k,w in enumerate(w_k_c[:,j]):\n",
    "        cas += w * conv_out_0[:,k]\n",
    "    minimum = np.min(cas)\n",
    "    cas = cas - minimum\n",
    "    cas = cas/max(cas)\n",
    "    cas = cas * 100\n",
    "    cas = cas.astype(int)\n",
    "\n",
    "#     axs[axsidx].plot(cas)\n",
    "\n",
    "    y = np.squeeze(x_cam[ix,:,:])\n",
    "    x = np.array(range(y.shape[0]))\n",
    "    dydx = cas\n",
    "\n",
    "    # Create a set of line segments so that we can color them individually\n",
    "    # This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "    # together easily to get the segments. The segments array for line collection\n",
    "    # needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Create a continuous norm to map from data points to colors\n",
    "    norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "    lc = LineCollection(segments, cmap='jet', norm=norm)\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(dydx)\n",
    "    lc.set_linewidth(4)\n",
    "    line = axs[axsidx].add_collection(lc)\n",
    "    fig.colorbar(line, ax=axs[axsidx])\n",
    "\n",
    "    # # Use a boundary norm instead\n",
    "    # cmap = ListedColormap(['r', 'g', 'b'])\n",
    "    # norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "    # lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    # lc.set_array(dydx)\n",
    "    # lc.set_linewidth(2)\n",
    "    # line = axs[1].add_collection(lc)\n",
    "    # fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "    axs[axsidx].set_xlim(x.min(), x.max())\n",
    "    axs[axsidx].set_ylim(y.min(), y.max())\n",
    "    axs[axsidx].set_title(names[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
