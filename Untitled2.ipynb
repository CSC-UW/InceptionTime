{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/apps/software/TensorFlow/2.2.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "#sys.path = [p for p in sys.path if p.find('/opt/apps/software/') == -1]\n",
    "from glob import glob\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
    "from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
    "from utils.utils import read_all_datasets, transform_labels, create_directory, run_length_xps, generate_results_csv, plot_epochs_metric\n",
    "from utils.data_loading import get_multiple_data_cf, predict, shifted_zscore_cf, zscore, print_metric, tf_rmse, tf_pmse_cf, rmse\n",
    "import utils\n",
    "from classifiers import inception\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "# keras.backend.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def tf_pmse_DA(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=0)\n",
    "\n",
    "def tf_pmse_5HT(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=1)\n",
    "\n",
    "def tf_pmse_pH(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=2)\n",
    "\n",
    "def tf_pmse_NE(y_true, y_pred):\n",
    "    return tf_pmse_cf(y_true, y_pred, idx=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving out probe CF078\n",
      "Validation probe CF025\n",
      "Loading data\n",
      "loading probe CF025\n",
      "loading probe CF027\n",
      "loading probe CF057\n",
      "loading probe CF064\n",
      "loading probe CF066\n",
      "loading probe CF078\n",
      "loading probe CF081\n",
      "loading probe CF082\n",
      "Shuffling training dataset\n",
      "Data loaded\n",
      "adding singleton\n"
     ]
    }
   ],
   "source": [
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "speed = 'slow'\n",
    "data_prefix = '/mnt/nfs/proj/in-vitro/Leonardo/cf_data'\n",
    "\n",
    "probes = [\n",
    "    'CF025', 'CF027', 'CF057', 'CF064', 'CF066', 'CF078', 'CF081', 'CF082'\n",
    "]\n",
    "\n",
    "hold_probe = probes[5]\n",
    "output_directory = f'/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/{hold_probe}/'\n",
    "\n",
    "if not (os.path.exists(output_directory)):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# val_probe=None\n",
    "val_probe=probes[0]\n",
    "\n",
    "print(f'Leaving out probe {hold_probe}', flush=True)\n",
    "print(f'Validation probe {val_probe}', flush=True)\n",
    "print(f'Loading data', flush=True)\n",
    "\n",
    "# normalize_data = minmax\n",
    "# revert_data = lambda x: minmax(x, inverse=True)\n",
    "\n",
    "normalize_data = shifted_zscore_cf\n",
    "revert_data = lambda x: shifted_zscore_cf(x, inverse=True)\n",
    "\n",
    "# normalize_data = lambda x: x\n",
    "# revert_data = lambda x: x\n",
    "\n",
    "# this is actually the number of records per UNIQUE CONCENTRATIONS per probe\n",
    "n_records_per_probe = -1 # all\n",
    "# n_records_per_probe = 1\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_multiple_data_cf(data_prefix,\n",
    "                                                                      probes=probes,\n",
    "                                                                      hold_probe=hold_probe,\n",
    "                                                                      val_probe=val_probe,\n",
    "                                                                      normalize_data=normalize_data,\n",
    "                                                                      n_records_per_probe=n_records_per_probe)\n",
    "\n",
    "print('Data loaded')\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    print('adding singleton')\n",
    "    # add a dimension to make it multivariate with one dimension\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "output_shape = y_train.shape[1]\n",
    "input_shape = x_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534.718528</td>\n",
       "      <td>351.660892</td>\n",
       "      <td>0.093729</td>\n",
       "      <td>810.758559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 999, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.load_model('/mnt/nfs/proj/in-vitro/Leonardo/inception/results/cf/CF078/last_model.hdf5', \n",
    "                                custom_objects={\"tf_pmse_DA\": tf_pmse_DA, \"tf_pmse_5HT\": tf_pmse_5HT, \"tf_pmse_pH\": tf_pmse_pH, \"tf_pmse_NE\": tf_pmse_NE})\n",
    "idxs = np.random.permutation(x_val.shape[0])\n",
    "x_cam = x_val[idxs[:1000],:,:]\n",
    "y_cam = y_val[idxs[:1000], :]\n",
    "\n",
    "w_k_c = model.layers[-1].get_weights()[0] # weights for each filter k for each class c \n",
    "\n",
    "new_input_layer = model.inputs # same input of the original model\n",
    "\n",
    "new_outpu_layer = [model.get_layer(\"conv1d_31\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "# new_outpu_layer = [model.get_layer(\"activation_8\").output, model.layers[-1].output] # output is both the original as well as the before last layer \n",
    "\n",
    "new_function = keras.backend.function(new_input_layer,new_outpu_layer)\n",
    "\n",
    "new_feed_forward = new_function\n",
    "\n",
    "[conv_out, y_pred] = new_feed_forward((x_cam,))\n",
    "\n",
    "metrics = pd.DataFrame(data=np.zeros((1, 4), dtype=np.float), index=[0],\n",
    "                   columns=['rmse_DA', 'rmse_5HT', 'rmse_pH', 'rmse_NE'])\n",
    "y_pred = np.apply_along_axis(revert_data, axis=1, arr=y_pred) \n",
    "y_true = np.apply_along_axis(revert_data, axis=1, arr=y_cam) \n",
    "rmse4 = rmse(y_true, y_pred)\n",
    "metrics['rmse_DA'] = rmse4[0]\n",
    "metrics['rmse_5HT'] = rmse4[1]\n",
    "metrics['rmse_pH'] = rmse4[2]\n",
    "metrics['rmse_NE'] = rmse4[3]\n",
    "display(HTML(metrics.to_html()))\n",
    "print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_k_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n",
      "(1000, 999, 128)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# print(\"original_label: \"+str(encoder.inverse_transform(np.argmax(original_binary_class))))\n",
    "# print(\"original_shape: \"+str(time_series_original.shape))\n",
    "# print(\"predicted_label:\"+str(encoder.inverse_transform(np.argmax(predicted))))\n",
    "# print(\"predicted_shape:\"+str(conv_out.shape))\n",
    "\n",
    "print(w_k_c.shape)\n",
    "print(conv_out.shape)\n",
    "\n",
    "# conv_out_0 = conv_out[0,:,:]\n",
    "conv_out_0 = np.squeeze(np.mean(conv_out, axis=0))\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "for j in range(y_val.shape[1]):\n",
    "    \n",
    "    print(j)\n",
    "    \n",
    "    axsidx = np.unravel_index(j, axs.shape)\n",
    "    \n",
    "    cas = np.zeros(dtype=np.float, shape = (conv_out.shape[1]))\n",
    "    for k,w in enumerate(w_k_c[:,j]):\n",
    "        cas += w * conv_out_0[:,k]\n",
    "    minimum = np.min(cas)\n",
    "    cas = cas - minimum\n",
    "    cas = cas/max(cas)\n",
    "    cas = cas * 100\n",
    "    cas = cas.astype(int)\n",
    "    \n",
    "#     axs[axsidx].plot(cas)\n",
    "\n",
    "    y = np.squeeze(np.mean(x_cam, axis=0))\n",
    "    x = np.array(range(y.shape[0]))\n",
    "    dydx = cas\n",
    "\n",
    "    # Create a set of line segments so that we can color them individually\n",
    "    # This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "    # together easily to get the segments. The segments array for line collection\n",
    "    # needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Create a continuous norm to map from data points to colors\n",
    "    norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "    lc = LineCollection(segments, cmap='jet', norm=norm)\n",
    "    # Set the values used for colormapping\n",
    "    lc.set_array(dydx)\n",
    "    lc.set_linewidth(2)\n",
    "    line = axs[axsidx].add_collection(lc)\n",
    "    fig.colorbar(line, ax=axs[axsidx])\n",
    "\n",
    "    # # Use a boundary norm instead\n",
    "    # cmap = ListedColormap(['r', 'g', 'b'])\n",
    "    # norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "    # lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    # lc.set_array(dydx)\n",
    "    # lc.set_linewidth(2)\n",
    "    # line = axs[1].add_collection(lc)\n",
    "    # fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "    axs[axsidx].set_xlim(x.min(), x.max())\n",
    "    axs[axsidx].set_ylim(y.min(), y.max())\n",
    "    axs[axsidx].set_title(names[j])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
