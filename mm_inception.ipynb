{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/apps/software/TensorFlow/2.2.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "#sys.path = [p for p in sys.path if p.find('/opt/apps/software/') == -1]\n",
    "from glob import glob\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.constants import UNIVARIATE_ARCHIVE_NAMES as ARCHIVE_NAMES\n",
    "from utils.constants import UNIVARIATE_DATASET_NAMES as DATASET_NAMES\n",
    "from utils.utils import read_all_datasets, transform_labels, create_directory, run_length_xps, generate_results_csv, plot_epochs_metric\n",
    "from utils.data_loading import get_multiple_data, predict, shifted_zscore, zscore, print_metric, tf_rmse, tf_pmse, rmse\n",
    "import utils\n",
    "from classifiers import inception\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "def tf_pmse_DA(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=0)\n",
    "\n",
    "def tf_pmse_5HT(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=1)\n",
    "\n",
    "def tf_pmse_pH(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=2)\n",
    "\n",
    "def tf_pmse_NE(y_true, y_pred):\n",
    "    return tf_pmse(y_true, y_pred, idx=3)\n",
    "\n",
    "# import keras\n",
    "# keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hold probe : MMA025W01R04\n",
      "validation probe : MMA003W01R04\n",
      "Leaving out probe MMA025W01R04\n",
      "Validation probe MMA003W01R04\n",
      "Loading data\n",
      "No 500ohms\n",
      "number of voltammograms files 36\n",
      "after filter 36\n",
      "after removing bad probes 36\n",
      "number of holdout files 4\n",
      "(52800, 999)\n",
      "(52800, 4)\n",
      "validation probe: MMA003W01R04\n",
      "number of validation files 4\n",
      "(52800, 999)\n",
      "(52800, 4)\n",
      "number of train files 28\n",
      "(369600, 999)\n",
      "(369600, 4)\n",
      "Data loaded\n",
      "adding singleton\n"
     ]
    }
   ],
   "source": [
    "# data_prefix = '/mnt/nfs/proj/in-vitro/iterate/results_014/model_style_008/training-A-RBE-97Hz/'\n",
    "data_prefix = '/mnt/nfs/proj/in-vitro/iterate/results_014/model_style_008/training-B-RBE025-97Hz/'\n",
    "voltammograms = glob(data_prefix + '/*MMA*/voltammograms.mat')\n",
    "probes = ['MMA003W01R04', 'MMA004W01R04', 'MMA013W01R04', 'MMA018W01R04', 'MMA019W01R04', 'MMA022W01R04', 'MMA023W01R04', 'MMA024W01R04', 'MMA025W01R04']\n",
    "good_probes = probes\n",
    "\n",
    "hold_probe = probes[1]\n",
    "# hold_probe=None\n",
    "print('hold probe :', hold_probe)\n",
    "\n",
    "output_directory = f'/mnt/nfs/proj/in-vitro/Leonardo/inception/results/mm/{hold_probe}/'\n",
    "\n",
    "if not (os.path.exists(output_directory)):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# val_probe=None\n",
    "val_probe=probes[5]\n",
    "print('validation probe :', val_probe)\n",
    "\n",
    "print(f'Leaving out probe {hold_probe}', flush=True)\n",
    "print(f'Validation probe {val_probe}', flush=True)\n",
    "print(f'Loading data', flush=True)\n",
    "\n",
    "filter_files = lambda x : x.find('500kohm') == -1\n",
    "print('No 500ohms')\n",
    "\n",
    "# filter_files = lambda x : x.find('500kohm') > -1\n",
    "# print('ONLY 500ohms')\n",
    "\n",
    "# normalize_data = minmax\n",
    "# revert_data = lambda x: minmax(x, inverse=True)\n",
    "\n",
    "normalize_data = shifted_zscore\n",
    "revert_data = lambda x: shifted_zscore(x, inverse=True)\n",
    "\n",
    "# normalize_data = zscore\n",
    "# revert_data = lambda x: zscore(x, inverse=True)\n",
    "\n",
    "# normalize_data = lambda x: x\n",
    "# revert_data = lambda x: x\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_multiple_data(data_prefix,\n",
    "                                                                    probes=good_probes,\n",
    "                                                                    holdout=hold_probe,\n",
    "                                                                    val_probe=val_probe,\n",
    "                                                                    number_of_minibatches=20,\n",
    "                                                                    normalize_data=normalize_data,\n",
    "                                                                    filter_files=filter_files,\n",
    "                                                                    nrecords_per_session=400)\n",
    "print('Data loaded')\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    print('adding singleton')\n",
    "    # add a dimension to make it multivariate with one dimension\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "output_shape = y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch size: 64\n",
      "Train on 369600 samples, validate on 52800 samples\n",
      "Epoch 1/100\n",
      "369600/369600 [==============================] - 336s 909us/step - loss: 1.0213 - tf_pmse_DA: 935.3340 - tf_pmse_5HT: 942.5300 - tf_pmse_pH: 0.2288 - tf_pmse_NE: 864.1198 - val_loss: 4.5814 - val_tf_pmse_DA: 866.5776 - val_tf_pmse_5HT: 1234.1121 - val_tf_pmse_pH: 1.1679 - val_tf_pmse_NE: 835.1944\n",
      "Epoch 2/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.4181 - tf_pmse_DA: 765.3237 - tf_pmse_5HT: 752.4347 - tf_pmse_pH: 0.1347 - tf_pmse_NE: 657.3793 - val_loss: 1.5835 - val_tf_pmse_DA: 882.1802 - val_tf_pmse_5HT: 1315.3749 - val_tf_pmse_pH: 0.3107 - val_tf_pmse_NE: 945.7693\n",
      "Epoch 3/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.2943 - tf_pmse_DA: 654.9942 - tf_pmse_5HT: 625.4911 - tf_pmse_pH: 0.1113 - tf_pmse_NE: 544.2216 - val_loss: 1.7133 - val_tf_pmse_DA: 1408.0268 - val_tf_pmse_5HT: 970.8600 - val_tf_pmse_pH: 0.2861 - val_tf_pmse_NE: 1117.2593\n",
      "Epoch 4/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.2342 - tf_pmse_DA: 580.8922 - tf_pmse_5HT: 560.3508 - tf_pmse_pH: 0.0987 - tf_pmse_NE: 486.2472 - val_loss: 4.3446 - val_tf_pmse_DA: 2193.5868 - val_tf_pmse_5HT: 1498.8150 - val_tf_pmse_pH: 0.7684 - val_tf_pmse_NE: 1113.6922\n",
      "Epoch 5/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.1991 - tf_pmse_DA: 533.7174 - tf_pmse_5HT: 518.4457 - tf_pmse_pH: 0.0905 - tf_pmse_NE: 447.1804 - val_loss: 1.7581 - val_tf_pmse_DA: 1177.8542 - val_tf_pmse_5HT: 1115.1085 - val_tf_pmse_pH: 0.3068 - val_tf_pmse_NE: 1097.5590\n",
      "Epoch 6/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.1746 - tf_pmse_DA: 496.7355 - tf_pmse_5HT: 486.7607 - tf_pmse_pH: 0.0846 - tf_pmse_NE: 418.7798 - val_loss: 1.7934 - val_tf_pmse_DA: 1101.9446 - val_tf_pmse_5HT: 999.8726 - val_tf_pmse_pH: 0.3724 - val_tf_pmse_NE: 1221.6796\n",
      "Epoch 7/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.1564 - tf_pmse_DA: 467.9256 - tf_pmse_5HT: 461.2534 - tf_pmse_pH: 0.0801 - tf_pmse_NE: 397.1922 - val_loss: 2.2970 - val_tf_pmse_DA: 1306.8800 - val_tf_pmse_5HT: 1352.0240 - val_tf_pmse_pH: 0.4538 - val_tf_pmse_NE: 961.3530\n",
      "Epoch 8/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.1416 - tf_pmse_DA: 442.2649 - tf_pmse_5HT: 439.7024 - tf_pmse_pH: 0.0768 - tf_pmse_NE: 377.2067 - val_loss: 1.9923 - val_tf_pmse_DA: 1015.9554 - val_tf_pmse_5HT: 1667.2888 - val_tf_pmse_pH: 0.2713 - val_tf_pmse_NE: 1102.0121\n",
      "Epoch 9/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.1302 - tf_pmse_DA: 423.0267 - tf_pmse_5HT: 422.5772 - tf_pmse_pH: 0.0736 - tf_pmse_NE: 359.7454 - val_loss: 3.8598 - val_tf_pmse_DA: 1014.3686 - val_tf_pmse_5HT: 1491.5784 - val_tf_pmse_pH: 0.8693 - val_tf_pmse_NE: 1254.1545\n",
      "Epoch 10/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.1205 - tf_pmse_DA: 405.7009 - tf_pmse_5HT: 407.0996 - tf_pmse_pH: 0.0705 - tf_pmse_NE: 346.9223 - val_loss: 1.4305 - val_tf_pmse_DA: 968.2606 - val_tf_pmse_5HT: 1035.1890 - val_tf_pmse_pH: 0.2743 - val_tf_pmse_NE: 1017.4377\n",
      "Epoch 11/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.1126 - tf_pmse_DA: 391.3778 - tf_pmse_5HT: 394.4647 - tf_pmse_pH: 0.0684 - tf_pmse_NE: 333.6081 - val_loss: 2.3022 - val_tf_pmse_DA: 1321.9954 - val_tf_pmse_5HT: 1000.1650 - val_tf_pmse_pH: 0.5156 - val_tf_pmse_NE: 1006.1029\n",
      "Epoch 12/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.1051 - tf_pmse_DA: 375.7983 - tf_pmse_5HT: 381.6678 - tf_pmse_pH: 0.0663 - tf_pmse_NE: 321.9758 - val_loss: 2.6952 - val_tf_pmse_DA: 1012.8133 - val_tf_pmse_5HT: 1539.5589 - val_tf_pmse_pH: 0.5514 - val_tf_pmse_NE: 1270.7008\n",
      "Epoch 13/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0995 - tf_pmse_DA: 364.0539 - tf_pmse_5HT: 371.6197 - tf_pmse_pH: 0.0652 - tf_pmse_NE: 312.2697 - val_loss: 1.6523 - val_tf_pmse_DA: 1001.1267 - val_tf_pmse_5HT: 951.0825 - val_tf_pmse_pH: 0.3902 - val_tf_pmse_NE: 1031.7180\n",
      "Epoch 14/100\n",
      "369600/369600 [==============================] - 324s 876us/step - loss: 0.0942 - tf_pmse_DA: 353.0764 - tf_pmse_5HT: 362.9750 - tf_pmse_pH: 0.0633 - tf_pmse_NE: 302.9275 - val_loss: 1.6968 - val_tf_pmse_DA: 1172.6989 - val_tf_pmse_5HT: 1035.4942 - val_tf_pmse_pH: 0.2577 - val_tf_pmse_NE: 1348.6119\n",
      "Epoch 15/100\n",
      "369600/369600 [==============================] - 323s 875us/step - loss: 0.0896 - tf_pmse_DA: 344.8205 - tf_pmse_5HT: 353.8775 - tf_pmse_pH: 0.0618 - tf_pmse_NE: 294.4792 - val_loss: 1.7706 - val_tf_pmse_DA: 1019.3672 - val_tf_pmse_5HT: 1227.8502 - val_tf_pmse_pH: 0.3775 - val_tf_pmse_NE: 949.1692\n",
      "Epoch 16/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0854 - tf_pmse_DA: 335.5659 - tf_pmse_5HT: 344.8410 - tf_pmse_pH: 0.0605 - tf_pmse_NE: 287.6931 - val_loss: 1.3496 - val_tf_pmse_DA: 981.5885 - val_tf_pmse_5HT: 936.5296 - val_tf_pmse_pH: 0.2679 - val_tf_pmse_NE: 969.3150\n",
      "Epoch 17/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0821 - tf_pmse_DA: 328.3022 - tf_pmse_5HT: 337.8514 - tf_pmse_pH: 0.0600 - tf_pmse_NE: 281.0056 - val_loss: 1.5427 - val_tf_pmse_DA: 1012.3409 - val_tf_pmse_5HT: 1355.6252 - val_tf_pmse_pH: 0.2492 - val_tf_pmse_NE: 903.0459\n",
      "Epoch 18/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0780 - tf_pmse_DA: 319.7792 - tf_pmse_5HT: 329.6881 - tf_pmse_pH: 0.0585 - tf_pmse_NE: 273.0373 - val_loss: 1.8507 - val_tf_pmse_DA: 981.5240 - val_tf_pmse_5HT: 1039.5342 - val_tf_pmse_pH: 0.4734 - val_tf_pmse_NE: 897.3053\n",
      "Epoch 19/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0755 - tf_pmse_DA: 314.0610 - tf_pmse_5HT: 325.2811 - tf_pmse_pH: 0.0572 - tf_pmse_NE: 268.2590 - val_loss: 1.4129 - val_tf_pmse_DA: 1027.1509 - val_tf_pmse_5HT: 1080.5118 - val_tf_pmse_pH: 0.2449 - val_tf_pmse_NE: 978.0863\n",
      "Epoch 20/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0726 - tf_pmse_DA: 308.2208 - tf_pmse_5HT: 318.7225 - tf_pmse_pH: 0.0561 - tf_pmse_NE: 262.2768 - val_loss: 1.6067 - val_tf_pmse_DA: 1059.9570 - val_tf_pmse_5HT: 1197.2285 - val_tf_pmse_pH: 0.2493 - val_tf_pmse_NE: 1200.9312\n",
      "Epoch 21/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0702 - tf_pmse_DA: 301.3499 - tf_pmse_5HT: 313.7214 - tf_pmse_pH: 0.0555 - tf_pmse_NE: 258.1547 - val_loss: 1.4275 - val_tf_pmse_DA: 1141.5530 - val_tf_pmse_5HT: 1104.1664 - val_tf_pmse_pH: 0.2671 - val_tf_pmse_NE: 902.8370\n",
      "Epoch 22/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0673 - tf_pmse_DA: 296.3995 - tf_pmse_5HT: 306.1256 - tf_pmse_pH: 0.0543 - tf_pmse_NE: 251.1151 - val_loss: 1.7681 - val_tf_pmse_DA: 1190.7297 - val_tf_pmse_5HT: 1342.1049 - val_tf_pmse_pH: 0.2835 - val_tf_pmse_NE: 1111.3625\n",
      "Epoch 23/100\n",
      "369600/369600 [==============================] - 325s 881us/step - loss: 0.0656 - tf_pmse_DA: 291.2106 - tf_pmse_5HT: 303.4694 - tf_pmse_pH: 0.0538 - tf_pmse_NE: 247.9261 - val_loss: 1.6104 - val_tf_pmse_DA: 1075.7234 - val_tf_pmse_5HT: 1082.9228 - val_tf_pmse_pH: 0.3834 - val_tf_pmse_NE: 942.8087\n",
      "Epoch 24/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0632 - tf_pmse_DA: 287.4063 - tf_pmse_5HT: 297.1874 - tf_pmse_pH: 0.0522 - tf_pmse_NE: 242.6572 - val_loss: 2.0221 - val_tf_pmse_DA: 1016.4123 - val_tf_pmse_5HT: 1115.3664 - val_tf_pmse_pH: 0.5407 - val_tf_pmse_NE: 878.9329\n",
      "Epoch 25/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0615 - tf_pmse_DA: 282.2936 - tf_pmse_5HT: 292.9481 - tf_pmse_pH: 0.0521 - tf_pmse_NE: 239.6624 - val_loss: 1.6034 - val_tf_pmse_DA: 991.6484 - val_tf_pmse_5HT: 1140.1664 - val_tf_pmse_pH: 0.3687 - val_tf_pmse_NE: 914.8181\n",
      "Epoch 26/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0594 - tf_pmse_DA: 277.5039 - tf_pmse_5HT: 288.7016 - tf_pmse_pH: 0.0508 - tf_pmse_NE: 235.0430 - val_loss: 1.7058 - val_tf_pmse_DA: 1111.6239 - val_tf_pmse_5HT: 1313.5484 - val_tf_pmse_pH: 0.3095 - val_tf_pmse_NE: 961.7520\n",
      "Epoch 27/100\n",
      "369600/369600 [==============================] - 324s 876us/step - loss: 0.0580 - tf_pmse_DA: 274.9442 - tf_pmse_5HT: 284.3664 - tf_pmse_pH: 0.0503 - tf_pmse_NE: 232.3046 - val_loss: 1.6320 - val_tf_pmse_DA: 1158.5030 - val_tf_pmse_5HT: 1417.5779 - val_tf_pmse_pH: 0.2585 - val_tf_pmse_NE: 897.8575\n",
      "Epoch 28/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0569 - tf_pmse_DA: 272.7315 - tf_pmse_5HT: 282.0476 - tf_pmse_pH: 0.0496 - tf_pmse_NE: 228.3443 - val_loss: 1.7025 - val_tf_pmse_DA: 1012.8651 - val_tf_pmse_5HT: 1344.6153 - val_tf_pmse_pH: 0.3346 - val_tf_pmse_NE: 970.9925\n",
      "Epoch 29/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0552 - tf_pmse_DA: 267.5331 - tf_pmse_5HT: 278.5400 - tf_pmse_pH: 0.0490 - tf_pmse_NE: 225.5498 - val_loss: 1.2857 - val_tf_pmse_DA: 1051.4122 - val_tf_pmse_5HT: 938.7220 - val_tf_pmse_pH: 0.2715 - val_tf_pmse_NE: 935.9832\n",
      "Epoch 30/100\n",
      "369600/369600 [==============================] - 325s 881us/step - loss: 0.0536 - tf_pmse_DA: 264.8098 - tf_pmse_5HT: 273.8766 - tf_pmse_pH: 0.0483 - tf_pmse_NE: 221.0586 - val_loss: 1.5410 - val_tf_pmse_DA: 980.0376 - val_tf_pmse_5HT: 1158.4297 - val_tf_pmse_pH: 0.3352 - val_tf_pmse_NE: 898.6566\n",
      "Epoch 31/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0524 - tf_pmse_DA: 261.4581 - tf_pmse_5HT: 271.1876 - tf_pmse_pH: 0.0481 - tf_pmse_NE: 217.7207 - val_loss: 1.5467 - val_tf_pmse_DA: 1198.0027 - val_tf_pmse_5HT: 1186.5006 - val_tf_pmse_pH: 0.2817 - val_tf_pmse_NE: 1002.3678\n",
      "Epoch 32/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0507 - tf_pmse_DA: 256.7011 - tf_pmse_5HT: 266.9186 - tf_pmse_pH: 0.0469 - tf_pmse_NE: 215.1099 - val_loss: 1.7694 - val_tf_pmse_DA: 1033.7678 - val_tf_pmse_5HT: 1470.4376 - val_tf_pmse_pH: 0.2924 - val_tf_pmse_NE: 1058.0277\n",
      "Epoch 33/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0500 - tf_pmse_DA: 255.1251 - tf_pmse_5HT: 265.0979 - tf_pmse_pH: 0.0462 - tf_pmse_NE: 212.8766 - val_loss: 1.3573 - val_tf_pmse_DA: 1087.4554 - val_tf_pmse_5HT: 1036.2163 - val_tf_pmse_pH: 0.2441 - val_tf_pmse_NE: 994.3941\n",
      "Epoch 34/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0488 - tf_pmse_DA: 251.5989 - tf_pmse_5HT: 261.5853 - tf_pmse_pH: 0.0459 - tf_pmse_NE: 210.5910 - val_loss: 1.5599 - val_tf_pmse_DA: 987.1853 - val_tf_pmse_5HT: 1024.1832 - val_tf_pmse_pH: 0.3514 - val_tf_pmse_NE: 1011.6947\n",
      "Epoch 35/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0476 - tf_pmse_DA: 249.3866 - tf_pmse_5HT: 258.0616 - tf_pmse_pH: 0.0450 - tf_pmse_NE: 207.8312 - val_loss: 1.4574 - val_tf_pmse_DA: 995.9317 - val_tf_pmse_5HT: 1076.1385 - val_tf_pmse_pH: 0.3244 - val_tf_pmse_NE: 901.2753\n",
      "Epoch 36/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0470 - tf_pmse_DA: 248.0325 - tf_pmse_5HT: 256.5001 - tf_pmse_pH: 0.0444 - tf_pmse_NE: 206.7797 - val_loss: 1.1380 - val_tf_pmse_DA: 917.1253 - val_tf_pmse_5HT: 919.5848 - val_tf_pmse_pH: 0.2323 - val_tf_pmse_NE: 844.0716\n",
      "Epoch 37/100\n",
      "369600/369600 [==============================] - 325s 881us/step - loss: 0.0454 - tf_pmse_DA: 243.5228 - tf_pmse_5HT: 252.8990 - tf_pmse_pH: 0.0439 - tf_pmse_NE: 202.0825 - val_loss: 1.5332 - val_tf_pmse_DA: 1087.3142 - val_tf_pmse_5HT: 1094.9348 - val_tf_pmse_pH: 0.3361 - val_tf_pmse_NE: 921.9941\n",
      "Epoch 38/100\n",
      "369600/369600 [==============================] - 326s 882us/step - loss: 0.0450 - tf_pmse_DA: 242.3135 - tf_pmse_5HT: 251.2839 - tf_pmse_pH: 0.0437 - tf_pmse_NE: 200.9306 - val_loss: 1.4463 - val_tf_pmse_DA: 1212.1041 - val_tf_pmse_5HT: 1148.7826 - val_tf_pmse_pH: 0.2431 - val_tf_pmse_NE: 979.0283\n",
      "Epoch 39/100\n",
      "369600/369600 [==============================] - 326s 882us/step - loss: 0.0438 - tf_pmse_DA: 240.0668 - tf_pmse_5HT: 247.7708 - tf_pmse_pH: 0.0429 - tf_pmse_NE: 198.0471 - val_loss: 2.2004 - val_tf_pmse_DA: 1202.3517 - val_tf_pmse_5HT: 1765.7108 - val_tf_pmse_pH: 0.3581 - val_tf_pmse_NE: 1040.6558\n",
      "Epoch 40/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0429 - tf_pmse_DA: 237.0901 - tf_pmse_5HT: 245.7777 - tf_pmse_pH: 0.0421 - tf_pmse_NE: 196.5609 - val_loss: 1.6280 - val_tf_pmse_DA: 1268.2019 - val_tf_pmse_5HT: 1272.1295 - val_tf_pmse_pH: 0.2574 - val_tf_pmse_NE: 1044.9052\n",
      "Epoch 41/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0421 - tf_pmse_DA: 235.0258 - tf_pmse_5HT: 242.8606 - tf_pmse_pH: 0.0421 - tf_pmse_NE: 193.7589 - val_loss: 1.5749 - val_tf_pmse_DA: 1065.1148 - val_tf_pmse_5HT: 1325.9541 - val_tf_pmse_pH: 0.2579 - val_tf_pmse_NE: 1067.3825\n",
      "Epoch 42/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0415 - tf_pmse_DA: 233.1494 - tf_pmse_5HT: 241.3514 - tf_pmse_pH: 0.0414 - tf_pmse_NE: 192.3305 - val_loss: 1.3687 - val_tf_pmse_DA: 1070.7803 - val_tf_pmse_5HT: 1033.7659 - val_tf_pmse_pH: 0.2944 - val_tf_pmse_NE: 880.5153\n",
      "Epoch 43/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0407 - tf_pmse_DA: 231.4434 - tf_pmse_5HT: 239.5075 - tf_pmse_pH: 0.0404 - tf_pmse_NE: 190.3782 - val_loss: 1.4870 - val_tf_pmse_DA: 1093.1966 - val_tf_pmse_5HT: 1172.1057 - val_tf_pmse_pH: 0.2756 - val_tf_pmse_NE: 1002.2982\n",
      "Epoch 44/100\n",
      "369600/369600 [==============================] - 324s 875us/step - loss: 0.0400 - tf_pmse_DA: 230.1136 - tf_pmse_5HT: 236.4253 - tf_pmse_pH: 0.0404 - tf_pmse_NE: 188.2189 - val_loss: 1.4364 - val_tf_pmse_DA: 1114.9323 - val_tf_pmse_5HT: 1052.4710 - val_tf_pmse_pH: 0.2561 - val_tf_pmse_NE: 1136.6001\n",
      "Epoch 45/100\n",
      "369600/369600 [==============================] - 324s 876us/step - loss: 0.0392 - tf_pmse_DA: 226.6419 - tf_pmse_5HT: 234.5286 - tf_pmse_pH: 0.0402 - tf_pmse_NE: 186.4581 - val_loss: 1.4028 - val_tf_pmse_DA: 980.8680 - val_tf_pmse_5HT: 1152.5604 - val_tf_pmse_pH: 0.2598 - val_tf_pmse_NE: 956.3666\n",
      "Epoch 46/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0384 - tf_pmse_DA: 224.8697 - tf_pmse_5HT: 231.9746 - tf_pmse_pH: 0.0394 - tf_pmse_NE: 184.8363 - val_loss: 1.2061 - val_tf_pmse_DA: 1029.6686 - val_tf_pmse_5HT: 926.8631 - val_tf_pmse_pH: 0.2484 - val_tf_pmse_NE: 848.7364\n",
      "Epoch 47/100\n",
      "369600/369600 [==============================] - 326s 882us/step - loss: 0.0381 - tf_pmse_DA: 224.6827 - tf_pmse_5HT: 230.6004 - tf_pmse_pH: 0.0392 - tf_pmse_NE: 184.2107 - val_loss: 1.4607 - val_tf_pmse_DA: 1062.7389 - val_tf_pmse_5HT: 1176.4345 - val_tf_pmse_pH: 0.2578 - val_tf_pmse_NE: 1069.6800\n",
      "Epoch 48/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0377 - tf_pmse_DA: 222.9608 - tf_pmse_5HT: 229.9874 - tf_pmse_pH: 0.0389 - tf_pmse_NE: 182.2458 - val_loss: 1.4615 - val_tf_pmse_DA: 1080.9407 - val_tf_pmse_5HT: 1248.8238 - val_tf_pmse_pH: 0.2688 - val_tf_pmse_NE: 903.3931\n",
      "Epoch 49/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0369 - tf_pmse_DA: 221.0628 - tf_pmse_5HT: 226.5674 - tf_pmse_pH: 0.0386 - tf_pmse_NE: 181.4303 - val_loss: 1.4067 - val_tf_pmse_DA: 979.2424 - val_tf_pmse_5HT: 1127.2497 - val_tf_pmse_pH: 0.2642 - val_tf_pmse_NE: 986.8581\n",
      "Epoch 50/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0364 - tf_pmse_DA: 219.9728 - tf_pmse_5HT: 225.7536 - tf_pmse_pH: 0.0383 - tf_pmse_NE: 178.8258 - val_loss: 1.3452 - val_tf_pmse_DA: 983.7604 - val_tf_pmse_5HT: 928.5744 - val_tf_pmse_pH: 0.3250 - val_tf_pmse_NE: 884.0962\n",
      "Epoch 51/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0359 - tf_pmse_DA: 217.7428 - tf_pmse_5HT: 224.3956 - tf_pmse_pH: 0.0379 - tf_pmse_NE: 178.0952 - val_loss: 1.4576 - val_tf_pmse_DA: 1118.1223 - val_tf_pmse_5HT: 1251.4656 - val_tf_pmse_pH: 0.2527 - val_tf_pmse_NE: 916.2064\n",
      "Epoch 52/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0350 - tf_pmse_DA: 215.6844 - tf_pmse_5HT: 221.1365 - tf_pmse_pH: 0.0374 - tf_pmse_NE: 176.0517 - val_loss: 1.2370 - val_tf_pmse_DA: 929.3153 - val_tf_pmse_5HT: 954.7829 - val_tf_pmse_pH: 0.2605 - val_tf_pmse_NE: 832.7605\n",
      "Epoch 53/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0346 - tf_pmse_DA: 214.1297 - tf_pmse_5HT: 219.7832 - tf_pmse_pH: 0.0371 - tf_pmse_NE: 174.3686 - val_loss: 1.4493 - val_tf_pmse_DA: 931.1872 - val_tf_pmse_5HT: 1092.2841 - val_tf_pmse_pH: 0.3364 - val_tf_pmse_NE: 852.6038\n",
      "Epoch 54/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0341 - tf_pmse_DA: 212.3967 - tf_pmse_5HT: 218.5881 - tf_pmse_pH: 0.0366 - tf_pmse_NE: 173.4273 - val_loss: 1.3660 - val_tf_pmse_DA: 1024.9818 - val_tf_pmse_5HT: 1070.6759 - val_tf_pmse_pH: 0.2761 - val_tf_pmse_NE: 967.1628\n",
      "Epoch 55/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0340 - tf_pmse_DA: 211.9756 - tf_pmse_5HT: 217.8035 - tf_pmse_pH: 0.0366 - tf_pmse_NE: 172.9097 - val_loss: 1.6101 - val_tf_pmse_DA: 1058.8895 - val_tf_pmse_5HT: 1185.1966 - val_tf_pmse_pH: 0.3461 - val_tf_pmse_NE: 975.8549\n",
      "Epoch 56/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0329 - tf_pmse_DA: 209.1391 - tf_pmse_5HT: 215.2835 - tf_pmse_pH: 0.0358 - tf_pmse_NE: 169.2227 - val_loss: 1.5834 - val_tf_pmse_DA: 1051.3432 - val_tf_pmse_5HT: 1212.0005 - val_tf_pmse_pH: 0.3443 - val_tf_pmse_NE: 893.6658\n",
      "Epoch 57/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0327 - tf_pmse_DA: 207.9359 - tf_pmse_5HT: 213.8371 - tf_pmse_pH: 0.0359 - tf_pmse_NE: 170.0588 - val_loss: 1.5960 - val_tf_pmse_DA: 1049.2000 - val_tf_pmse_5HT: 1013.2353 - val_tf_pmse_pH: 0.3984 - val_tf_pmse_NE: 912.0291\n",
      "Epoch 58/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0328 - tf_pmse_DA: 208.4779 - tf_pmse_5HT: 214.2452 - tf_pmse_pH: 0.0354 - tf_pmse_NE: 169.3927 - val_loss: 1.3296 - val_tf_pmse_DA: 1049.6682 - val_tf_pmse_5HT: 943.1271 - val_tf_pmse_pH: 0.2990 - val_tf_pmse_NE: 845.7041\n",
      "Epoch 59/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0322 - tf_pmse_DA: 207.6275 - tf_pmse_5HT: 212.0663 - tf_pmse_pH: 0.0350 - tf_pmse_NE: 167.7543 - val_loss: 1.4609 - val_tf_pmse_DA: 1128.8447 - val_tf_pmse_5HT: 1190.8537 - val_tf_pmse_pH: 0.2848 - val_tf_pmse_NE: 933.8828\n",
      "Epoch 60/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0319 - tf_pmse_DA: 205.8996 - tf_pmse_5HT: 210.8043 - tf_pmse_pH: 0.0350 - tf_pmse_NE: 167.2522 - val_loss: 1.4176 - val_tf_pmse_DA: 1062.7587 - val_tf_pmse_5HT: 1143.5485 - val_tf_pmse_pH: 0.2960 - val_tf_pmse_NE: 875.4452\n",
      "Epoch 61/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0310 - tf_pmse_DA: 202.5376 - tf_pmse_5HT: 208.4451 - tf_pmse_pH: 0.0344 - tf_pmse_NE: 164.7849 - val_loss: 1.2820 - val_tf_pmse_DA: 941.1351 - val_tf_pmse_5HT: 1065.0273 - val_tf_pmse_pH: 0.2636 - val_tf_pmse_NE: 894.5230\n",
      "Epoch 62/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0309 - tf_pmse_DA: 202.8174 - tf_pmse_5HT: 208.2762 - tf_pmse_pH: 0.0342 - tf_pmse_NE: 164.5829 - val_loss: 1.4680 - val_tf_pmse_DA: 1034.5475 - val_tf_pmse_5HT: 1084.8456 - val_tf_pmse_pH: 0.3211 - val_tf_pmse_NE: 913.5837\n",
      "Epoch 63/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0303 - tf_pmse_DA: 200.3379 - tf_pmse_5HT: 205.5137 - tf_pmse_pH: 0.0341 - tf_pmse_NE: 163.4528 - val_loss: 1.2731 - val_tf_pmse_DA: 975.2014 - val_tf_pmse_5HT: 1015.3189 - val_tf_pmse_pH: 0.2644 - val_tf_pmse_NE: 902.1464\n",
      "Epoch 64/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0301 - tf_pmse_DA: 199.9970 - tf_pmse_5HT: 205.1754 - tf_pmse_pH: 0.0338 - tf_pmse_NE: 162.5373 - val_loss: 1.6806 - val_tf_pmse_DA: 1096.0267 - val_tf_pmse_5HT: 1366.6684 - val_tf_pmse_pH: 0.3149 - val_tf_pmse_NE: 997.8626\n",
      "Epoch 65/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0299 - tf_pmse_DA: 199.1327 - tf_pmse_5HT: 204.0408 - tf_pmse_pH: 0.0336 - tf_pmse_NE: 162.2787 - val_loss: 1.3099 - val_tf_pmse_DA: 999.0967 - val_tf_pmse_5HT: 921.7762 - val_tf_pmse_pH: 0.2858 - val_tf_pmse_NE: 855.8203\n",
      "Epoch 66/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0295 - tf_pmse_DA: 197.8247 - tf_pmse_5HT: 203.0867 - tf_pmse_pH: 0.0332 - tf_pmse_NE: 160.4138 - val_loss: 1.4060 - val_tf_pmse_DA: 1037.4663 - val_tf_pmse_5HT: 1077.2004 - val_tf_pmse_pH: 0.2971 - val_tf_pmse_NE: 908.7250\n",
      "Epoch 67/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0293 - tf_pmse_DA: 196.8030 - tf_pmse_5HT: 202.5551 - tf_pmse_pH: 0.0333 - tf_pmse_NE: 159.5277 - val_loss: 1.3822 - val_tf_pmse_DA: 947.0171 - val_tf_pmse_5HT: 1002.1673 - val_tf_pmse_pH: 0.3002 - val_tf_pmse_NE: 900.8992\n",
      "Epoch 68/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0291 - tf_pmse_DA: 196.5973 - tf_pmse_5HT: 201.8508 - tf_pmse_pH: 0.0330 - tf_pmse_NE: 158.4216 - val_loss: 1.3486 - val_tf_pmse_DA: 970.6814 - val_tf_pmse_5HT: 1045.8515 - val_tf_pmse_pH: 0.2881 - val_tf_pmse_NE: 887.7268\n",
      "Epoch 69/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0283 - tf_pmse_DA: 193.9599 - tf_pmse_5HT: 199.1251 - tf_pmse_pH: 0.0326 - tf_pmse_NE: 156.8089 - val_loss: 1.3422 - val_tf_pmse_DA: 1095.0224 - val_tf_pmse_5HT: 1083.4389 - val_tf_pmse_pH: 0.2593 - val_tf_pmse_NE: 913.0562\n",
      "Epoch 70/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0281 - tf_pmse_DA: 193.3715 - tf_pmse_5HT: 197.6837 - tf_pmse_pH: 0.0326 - tf_pmse_NE: 156.4097 - val_loss: 1.2442 - val_tf_pmse_DA: 985.2819 - val_tf_pmse_5HT: 992.7867 - val_tf_pmse_pH: 0.2633 - val_tf_pmse_NE: 862.3361\n",
      "Epoch 71/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0276 - tf_pmse_DA: 191.5258 - tf_pmse_5HT: 196.6250 - tf_pmse_pH: 0.0319 - tf_pmse_NE: 155.4671 - val_loss: 1.3696 - val_tf_pmse_DA: 1043.3359 - val_tf_pmse_5HT: 1077.4603 - val_tf_pmse_pH: 0.2837 - val_tf_pmse_NE: 936.7509\n",
      "Epoch 72/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0277 - tf_pmse_DA: 192.6918 - tf_pmse_5HT: 196.3489 - tf_pmse_pH: 0.0320 - tf_pmse_NE: 154.9566 - val_loss: 1.3401 - val_tf_pmse_DA: 1039.2781 - val_tf_pmse_5HT: 1120.1036 - val_tf_pmse_pH: 0.2564 - val_tf_pmse_NE: 937.5344\n",
      "Epoch 73/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0272 - tf_pmse_DA: 190.5731 - tf_pmse_5HT: 194.8231 - tf_pmse_pH: 0.0318 - tf_pmse_NE: 153.4551 - val_loss: 1.2317 - val_tf_pmse_DA: 1013.9189 - val_tf_pmse_5HT: 953.9490 - val_tf_pmse_pH: 0.2476 - val_tf_pmse_NE: 893.0938\n",
      "Epoch 74/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0273 - tf_pmse_DA: 190.6968 - tf_pmse_5HT: 195.0514 - tf_pmse_pH: 0.0317 - tf_pmse_NE: 154.1017 - val_loss: 1.3884 - val_tf_pmse_DA: 949.4200 - val_tf_pmse_5HT: 1104.2601 - val_tf_pmse_pH: 0.2807 - val_tf_pmse_NE: 919.0039\n",
      "Epoch 75/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0270 - tf_pmse_DA: 189.5303 - tf_pmse_5HT: 193.6866 - tf_pmse_pH: 0.0315 - tf_pmse_NE: 153.6967 - val_loss: 1.6520 - val_tf_pmse_DA: 1121.4419 - val_tf_pmse_5HT: 1391.3656 - val_tf_pmse_pH: 0.2619 - val_tf_pmse_NE: 1106.3254\n",
      "Epoch 76/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0266 - tf_pmse_DA: 187.9541 - tf_pmse_5HT: 192.7286 - tf_pmse_pH: 0.0314 - tf_pmse_NE: 151.3778 - val_loss: 1.4319 - val_tf_pmse_DA: 1036.0582 - val_tf_pmse_5HT: 1169.7936 - val_tf_pmse_pH: 0.2773 - val_tf_pmse_NE: 1004.4105\n",
      "Epoch 77/100\n",
      "369600/369600 [==============================] - 324s 876us/step - loss: 0.0262 - tf_pmse_DA: 187.4717 - tf_pmse_5HT: 191.5917 - tf_pmse_pH: 0.0308 - tf_pmse_NE: 150.5651 - val_loss: 1.2414 - val_tf_pmse_DA: 1011.5571 - val_tf_pmse_5HT: 989.4543 - val_tf_pmse_pH: 0.2548 - val_tf_pmse_NE: 904.1884\n",
      "Epoch 78/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0259 - tf_pmse_DA: 185.9522 - tf_pmse_5HT: 190.6507 - tf_pmse_pH: 0.0306 - tf_pmse_NE: 149.0136 - val_loss: 1.4611 - val_tf_pmse_DA: 1037.5318 - val_tf_pmse_5HT: 1089.3896 - val_tf_pmse_pH: 0.3087 - val_tf_pmse_NE: 945.1425\n",
      "Epoch 79/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0258 - tf_pmse_DA: 186.0053 - tf_pmse_5HT: 190.4316 - tf_pmse_pH: 0.0304 - tf_pmse_NE: 148.7823 - val_loss: 1.3017 - val_tf_pmse_DA: 1099.4000 - val_tf_pmse_5HT: 993.9689 - val_tf_pmse_pH: 0.2851 - val_tf_pmse_NE: 851.4906\n",
      "Epoch 80/100\n",
      "369600/369600 [==============================] - 323s 875us/step - loss: 0.0255 - tf_pmse_DA: 184.5000 - tf_pmse_5HT: 189.2779 - tf_pmse_pH: 0.0303 - tf_pmse_NE: 147.8615 - val_loss: 1.3570 - val_tf_pmse_DA: 1095.4433 - val_tf_pmse_5HT: 990.7719 - val_tf_pmse_pH: 0.2867 - val_tf_pmse_NE: 916.3923\n",
      "Epoch 81/100\n",
      "369600/369600 [==============================] - 325s 880us/step - loss: 0.0253 - tf_pmse_DA: 183.1510 - tf_pmse_5HT: 188.1626 - tf_pmse_pH: 0.0302 - tf_pmse_NE: 148.0277 - val_loss: 1.4895 - val_tf_pmse_DA: 1052.6173 - val_tf_pmse_5HT: 1160.8018 - val_tf_pmse_pH: 0.2983 - val_tf_pmse_NE: 996.8968\n",
      "Epoch 82/100\n",
      "369600/369600 [==============================] - 326s 881us/step - loss: 0.0250 - tf_pmse_DA: 182.2404 - tf_pmse_5HT: 186.3528 - tf_pmse_pH: 0.0301 - tf_pmse_NE: 146.6936 - val_loss: 1.5407 - val_tf_pmse_DA: 1068.9547 - val_tf_pmse_5HT: 1247.5026 - val_tf_pmse_pH: 0.3033 - val_tf_pmse_NE: 954.5112\n",
      "Epoch 83/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0247 - tf_pmse_DA: 181.6720 - tf_pmse_5HT: 186.3794 - tf_pmse_pH: 0.0296 - tf_pmse_NE: 146.3108 - val_loss: 1.2765 - val_tf_pmse_DA: 1003.6953 - val_tf_pmse_5HT: 998.5724 - val_tf_pmse_pH: 0.2658 - val_tf_pmse_NE: 948.5203\n",
      "Epoch 84/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0248 - tf_pmse_DA: 182.2700 - tf_pmse_5HT: 185.8719 - tf_pmse_pH: 0.0299 - tf_pmse_NE: 146.1969 - val_loss: 1.5361 - val_tf_pmse_DA: 991.7863 - val_tf_pmse_5HT: 1245.7005 - val_tf_pmse_pH: 0.3167 - val_tf_pmse_NE: 917.5236\n",
      "Epoch 85/100\n",
      "369600/369600 [==============================] - 324s 877us/step - loss: 0.0243 - tf_pmse_DA: 180.6075 - tf_pmse_5HT: 183.6653 - tf_pmse_pH: 0.0293 - tf_pmse_NE: 145.0057 - val_loss: 1.3104 - val_tf_pmse_DA: 1056.8988 - val_tf_pmse_5HT: 1025.7024 - val_tf_pmse_pH: 0.2705 - val_tf_pmse_NE: 929.1673\n",
      "Epoch 86/100\n",
      "369600/369600 [==============================] - 324s 878us/step - loss: 0.0240 - tf_pmse_DA: 178.9757 - tf_pmse_5HT: 182.8000 - tf_pmse_pH: 0.0296 - tf_pmse_NE: 143.8210 - val_loss: 1.1690 - val_tf_pmse_DA: 919.7458 - val_tf_pmse_5HT: 952.3446 - val_tf_pmse_pH: 0.2584 - val_tf_pmse_NE: 863.2393\n",
      "Epoch 87/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0241 - tf_pmse_DA: 179.2104 - tf_pmse_5HT: 183.7391 - tf_pmse_pH: 0.0293 - tf_pmse_NE: 143.8437 - val_loss: 1.3455 - val_tf_pmse_DA: 1121.1884 - val_tf_pmse_5HT: 992.3081 - val_tf_pmse_pH: 0.2845 - val_tf_pmse_NE: 912.4283\n",
      "Epoch 88/100\n",
      "369600/369600 [==============================] - 325s 879us/step - loss: 0.0237 - tf_pmse_DA: 177.7901 - tf_pmse_5HT: 181.7326 - tf_pmse_pH: 0.0292 - tf_pmse_NE: 142.2259 - val_loss: 1.3495 - val_tf_pmse_DA: 1019.1648 - val_tf_pmse_5HT: 1012.6320 - val_tf_pmse_pH: 0.2996 - val_tf_pmse_NE: 911.5340\n",
      "Epoch 89/100\n",
      "369600/369600 [==============================] - 326s 882us/step - loss: 0.0239 - tf_pmse_DA: 178.8289 - tf_pmse_5HT: 182.1242 - tf_pmse_pH: 0.0290 - tf_pmse_NE: 143.2586 - val_loss: 1.3859 - val_tf_pmse_DA: 1026.1277 - val_tf_pmse_5HT: 1114.5014 - val_tf_pmse_pH: 0.2862 - val_tf_pmse_NE: 925.5442\n",
      "Epoch 90/100\n",
      "369600/369600 [==============================] - 325s 878us/step - loss: 0.0235 - tf_pmse_DA: 177.0965 - tf_pmse_5HT: 181.1136 - tf_pmse_pH: 0.0286 - tf_pmse_NE: 141.6557 - val_loss: 1.3302 - val_tf_pmse_DA: 990.2604 - val_tf_pmse_5HT: 1007.9259 - val_tf_pmse_pH: 0.3025 - val_tf_pmse_NE: 911.3781\n",
      "Epoch 91/100\n",
      "369600/369600 [==============================] - 323s 873us/step - loss: 0.0230 - tf_pmse_DA: 174.7547 - tf_pmse_5HT: 178.0420 - tf_pmse_pH: 0.0287 - tf_pmse_NE: 140.9316 - val_loss: 1.3090 - val_tf_pmse_DA: 1021.7778 - val_tf_pmse_5HT: 1059.4290 - val_tf_pmse_pH: 0.2794 - val_tf_pmse_NE: 895.1280\n",
      "Epoch 92/100\n",
      "369600/369600 [==============================] - 319s 864us/step - loss: 0.0230 - tf_pmse_DA: 175.6781 - tf_pmse_5HT: 179.7830 - tf_pmse_pH: 0.0284 - tf_pmse_NE: 140.2643 - val_loss: 1.3488 - val_tf_pmse_DA: 999.8030 - val_tf_pmse_5HT: 1037.1346 - val_tf_pmse_pH: 0.2963 - val_tf_pmse_NE: 918.7089\n",
      "Epoch 93/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0227 - tf_pmse_DA: 173.5504 - tf_pmse_5HT: 177.5429 - tf_pmse_pH: 0.0284 - tf_pmse_NE: 140.1417 - val_loss: 1.2446 - val_tf_pmse_DA: 1008.3029 - val_tf_pmse_5HT: 1036.2328 - val_tf_pmse_pH: 0.2519 - val_tf_pmse_NE: 948.7093\n",
      "Epoch 94/100\n",
      "369600/369600 [==============================] - 320s 865us/step - loss: 0.0229 - tf_pmse_DA: 174.7396 - tf_pmse_5HT: 179.2679 - tf_pmse_pH: 0.0283 - tf_pmse_NE: 139.8187 - val_loss: 1.3165 - val_tf_pmse_DA: 976.1509 - val_tf_pmse_5HT: 1084.4029 - val_tf_pmse_pH: 0.2722 - val_tf_pmse_NE: 899.7415\n",
      "Epoch 95/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0225 - tf_pmse_DA: 173.5169 - tf_pmse_5HT: 177.2941 - tf_pmse_pH: 0.0281 - tf_pmse_NE: 139.0555 - val_loss: 1.2818 - val_tf_pmse_DA: 1013.7037 - val_tf_pmse_5HT: 992.7991 - val_tf_pmse_pH: 0.2860 - val_tf_pmse_NE: 849.9636\n",
      "Epoch 96/100\n",
      "369600/369600 [==============================] - 319s 863us/step - loss: 0.0223 - tf_pmse_DA: 173.1448 - tf_pmse_5HT: 176.4893 - tf_pmse_pH: 0.0276 - tf_pmse_NE: 138.1127 - val_loss: 1.2843 - val_tf_pmse_DA: 1021.9036 - val_tf_pmse_5HT: 1057.2036 - val_tf_pmse_pH: 0.2674 - val_tf_pmse_NE: 907.2209\n",
      "Epoch 97/100\n",
      "369600/369600 [==============================] - 320s 866us/step - loss: 0.0219 - tf_pmse_DA: 170.5446 - tf_pmse_5HT: 175.2380 - tf_pmse_pH: 0.0275 - tf_pmse_NE: 137.5867 - val_loss: 1.3125 - val_tf_pmse_DA: 1034.5900 - val_tf_pmse_5HT: 991.9279 - val_tf_pmse_pH: 0.2969 - val_tf_pmse_NE: 879.3937\n",
      "Epoch 98/100\n",
      "369600/369600 [==============================] - 321s 867us/step - loss: 0.0218 - tf_pmse_DA: 170.9457 - tf_pmse_5HT: 174.8924 - tf_pmse_pH: 0.0275 - tf_pmse_NE: 136.0863 - val_loss: 1.3271 - val_tf_pmse_DA: 971.9469 - val_tf_pmse_5HT: 1087.1333 - val_tf_pmse_pH: 0.2859 - val_tf_pmse_NE: 900.3170\n",
      "Epoch 99/100\n",
      "369600/369600 [==============================] - 320s 866us/step - loss: 0.0216 - tf_pmse_DA: 170.1282 - tf_pmse_5HT: 173.9601 - tf_pmse_pH: 0.0275 - tf_pmse_NE: 135.6202 - val_loss: 1.2250 - val_tf_pmse_DA: 945.8854 - val_tf_pmse_5HT: 986.6634 - val_tf_pmse_pH: 0.2620 - val_tf_pmse_NE: 859.9197\n",
      "Epoch 100/100\n",
      "369600/369600 [==============================] - 320s 866us/step - loss: 0.0216 - tf_pmse_DA: 169.6853 - tf_pmse_5HT: 173.0056 - tf_pmse_pH: 0.0273 - tf_pmse_NE: 135.6608 - val_loss: 1.2705 - val_tf_pmse_DA: 941.9353 - val_tf_pmse_5HT: 1036.0969 - val_tf_pmse_pH: 0.2756 - val_tf_pmse_NE: 892.0408\n",
      "predicting test set... done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1265.930014</td>\n",
       "      <td>1245.923786</td>\n",
       "      <td>0.322998</td>\n",
       "      <td>1109.621645</td>\n",
       "      <td>32467.59564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "classifier = inception.Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=100, \n",
    "                                            metrics=[tf_pmse_DA, tf_pmse_5HT, tf_pmse_pH, tf_pmse_NE])\n",
    "# classifier = Regression_INCEPTION(output_directory, input_shape, output_shape, verbose=1, build=True, nb_epochs=100)\n",
    "\n",
    "metrics = classifier.fit(x_train, y_train, x_val, y_val, plot_test_acc=True)\n",
    "\n",
    "display(HTML(metrics.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1162.706101</td>\n",
       "      <td>1138.727825</td>\n",
       "      <td>0.334436</td>\n",
       "      <td>1091.193107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = classifier.predict(x_test, y_test, x_train, y_train, return_df_metrics=True)\n",
    "display(HTML(metrics.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/proj/in-vitro/Leonardo/inception/results/mm/MMA025W01R04/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_DA</th>\n",
       "      <th>rmse_5HT</th>\n",
       "      <th>rmse_pH</th>\n",
       "      <th>rmse_NE</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10449.314065</td>\n",
       "      <td>10449.408678</td>\n",
       "      <td>7.61867</td>\n",
       "      <td>34504.139931</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classifier.output_directory)\n",
    "\n",
    "# model_path = os.path.join(classifier.output_directory, 'best_model.hdf5')\n",
    "model_path = os.path.join(classifier.output_directory, 'last_model.hdf5')\n",
    "# model_path = os.path.join(classifier.output_directory, 'model_init.hdf5')\n",
    "\n",
    "model = keras.models.load_model(model_path, custom_objects={\"tf_pmse_DA\": tf_pmse_DA, \"tf_pmse_5HT\": tf_pmse_5HT, \"tf_pmse_pH\": tf_pmse_pH, \"tf_pmse_NE\": tf_pmse_NE})\n",
    "\n",
    "xt, yt = x_test, y_test\n",
    "# xt, yt = x_val, y_val\n",
    "\n",
    "yp = model.predict(xt, batch_size=64)\n",
    "\n",
    "yp = np.apply_along_axis(revert_data, axis=1, arr=yp) \n",
    "yt = np.apply_along_axis(revert_data, axis=1, arr=yt) \n",
    "\n",
    "rmse4 = rmse(yt, yp)\n",
    "\n",
    "metrics2 = pd.DataFrame(data=np.zeros((1, 5), dtype=np.float), index=[0], columns=['rmse_DA', 'rmse_5HT', 'rmse_pH', 'rmse_NE', 'duration'])\n",
    "metrics2['rmse_DA'] = rmse4[0]\n",
    "metrics2['rmse_5HT'] = rmse4[1]\n",
    "metrics2['rmse_pH'] = rmse4[2]\n",
    "metrics2['rmse_NE'] = rmse4[3]\n",
    "metrics2['duration'] = 0.0\n",
    "        \n",
    "display(HTML(metrics2.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd813f32b414275b1eb6a353e1e2172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def plot_concentrations(y):\n",
    "#     fig, axs = plt.subplots(2, 2, sharey=False, tight_layout=True)\n",
    "#     for ip in range(0,4):\n",
    "#         axs[np.unravel_index(ip, axs.shape)].hist(y[:,ip])\n",
    "# plot_concentrations(y_test)\n",
    "# plot_concentrations(y_pred)\n",
    "\n",
    "def plot_compare_test_pred(yt, yp):\n",
    "    fig, axs = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(12, 5))\n",
    "    for ip in range(0,8):\n",
    "        axsidx = np.unravel_index(ip, axs.shape)\n",
    "        if ip < 4:\n",
    "            axs[axsidx].hist(yt[:,ip])\n",
    "        else:\n",
    "            axs[axsidx].hist(yp[:,ip-4])\n",
    "\n",
    "plot_compare_test_pred(yt, yp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
