#!/bin/bash
#SBATCH --partition=gpuq
#SBATCH --nodes=1
#SBATCH --exclusive
#SBATCH --gres=gpu:2
#SBATCH --time=96:00:00
#  #SBATCH --mem=128G
#SBATCH --mail-user=leonardo.barbosa@wisc.edu
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
# #SBATCH --array=0-6%2
#SBATCH --error=out/mma_conv_holdout.%A_%a.err
#SBATCH --output=out/mma_conv_holdout.%A_%a.out

cd $SLURM_SUBMIT_DIR

source ~/.bashrc

python pyscripts/macromicro_conv_holdout.py --batch_size 8192 --force_reload --probe $SLURM_ARRAY_TASK_ID --epochs 500 --optimizer Adadelta --learning_rate 0.85 --weight_samples

