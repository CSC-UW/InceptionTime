{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path = [p for p in sys.path if p.find('/opt/apps/software/') == -1]\n",
    "from glob import glob\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf2\n",
    "import numpy as np\n",
    "npdt = np.float32\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import re\n",
    "\n",
    "\n",
    "# import keras\n",
    "# keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shifted_zscore_cf(x, inverse=False):\n",
    "    # without zeros shifted by 10 std to avoid negative values\n",
    "    mean = [-10410.677490234375, -10414.565185546875, 6.00097793340683, -10413.194091796875]\n",
    "    std = [1266.3062, 1266.7249, 0.13912384, 1266.6195]\n",
    "\n",
    "    if inverse:\n",
    "        x = (x*std)+mean\n",
    "    else:\n",
    "        x = (x-mean)/std\n",
    "    \n",
    "    return x\n",
    "\n",
    "def preprocess(serialized_example):\n",
    "    \n",
    "    features = tf2.io.parse_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'gram': tf2.io.FixedLenFeature([], tf2.string),\n",
    "            'label': tf2.io.FixedLenFeature([], tf2.string)\n",
    "        })\n",
    "    data = tf2.io.decode_raw(features['gram'], tf2.float32)\n",
    "    label = tf2.io.decode_raw(features['label'], tf2.float32)\n",
    "    data.set_shape((None, 999))\n",
    "    label.set_shape((None, 4))\n",
    "    return data, label\n",
    "\n",
    "def merge_datasets(vfiles, batch_size, prep):\n",
    "\n",
    "    yv = []\n",
    "    yl = []\n",
    "    for filename in vfiles:\n",
    "        ds = tf2.data.TFRecordDataset(filename)\n",
    "        ds = ds.batch(batch_size=batch_size)\n",
    "        ds = ds.map(map_func=preprocess)\n",
    "        for v,l in ds:\n",
    "            v = np.array(v).astype(npdt)\n",
    "            l = np.array(l).astype(npdt)\n",
    "            yv.append(v)\n",
    "            l = np.apply_along_axis(prep, axis=1, arr=l) \n",
    "            yl.append(l)\n",
    "        \n",
    "    x = np.vstack(yv)\n",
    "    y = np.vstack(yl)\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to numpy\n",
      "\n",
      "converting probe CF025 to numpy file...\n",
      "converting probe CF027 to numpy file...\n",
      "converting probe CF057 to numpy file...\n",
      "converting probe CF064 to numpy file...\n",
      "converting probe CF066 to numpy file...\n",
      "converting probe CF078 to numpy file...\n",
      "converting probe CF081 to numpy file...\n",
      "converting probe CF082 to numpy file...\n",
      " done.\n"
     ]
    }
   ],
   "source": [
    "names = ['DA', '5HT', 'pH', 'NE']\n",
    "speed = 'slow'\n",
    "data_prefix = os.path.join('/mnt/nfs/proj/in-vitro/Mark/four_analyte/', speed, 'allin')\n",
    "output_prefix = '/mnt/nfs/proj/in-vitro/Leonardo/cf_data'\n",
    "if not (os.path.exists(output_prefix)):\n",
    "    os.makedirs(output_prefix, exist_ok=True)\n",
    "\n",
    "probes = [\n",
    "    'CF025', 'CF027', 'CF057', 'CF064', 'CF066', 'CF078', 'CF081', 'CF082'\n",
    "]\n",
    "\n",
    "print(f'Converting data to numpy')\n",
    "print()\n",
    "\n",
    "normalize_data = lambda x: x\n",
    "revert_data = lambda x: x\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]\n",
    "\n",
    "for probe in probes:\n",
    "    print(f'converting probe {probe} to numpy file...')\n",
    "        \n",
    "    probe_list = sum([\n",
    "        sorted(tf2.io.gfile.glob(os.path.join(data_prefix, x, 'total_records', '*')),\n",
    "               key=natural_keys) for x in [probe]\n",
    "    ], [])\n",
    "\n",
    "    x_probe, y_probe = merge_datasets(probe_list, batch_size, normalize_data)\n",
    "    \n",
    "    probe_file = os.path.join(output_prefix, f'{probe}.npz')\n",
    "    np.savez(probe_file, x=x_probe, y=y_probe)\n",
    "    \n",
    "print(' done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369900, 999, 1)\n",
      "(369900, 4)\n",
      "(61650, 999, 1)\n",
      "(61650, 4)\n",
      "(61650, 999, 1)\n",
      "(61650, 4)\n"
     ]
    }
   ],
   "source": [
    "for x in [x_train, y_train, x_val, y_val, x_test, y_test]:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
